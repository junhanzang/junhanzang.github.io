---
title: "Real-Time Object Detection Meets DINOv3"
date: 2026-01-25 21:30:02
categories:
  - 인공지능
---

<https://intellindust-ai-lab.github.io/projects/DEIMv2/>

[DEIMv2](https://intellindust-ai-lab.github.io/projects/DEIMv2/)

**Real-Time Object Detection Meets DINOv3**  
Shihua Huang¹⋆, Yongjie Hou¹²⋆, Longfei Liu¹⋆, Xuanlong Yu¹, Xi Shen¹†

¹ Intellindust AI Lab; ² 샤먼대학교(Xiamen University)  
⋆ 공동 1저자(Equal Contribution);  
† 교신 저자(Corresponding Author)

프로젝트 페이지: <https://intellindust-ai-lab.github.io/projects/DEIMv2>  
코드 및 가중치: <https://github.com/Intellindust-AI-Lab/DEIMv2>

[GitHub - Intellindust-AI-Lab/DEIMv2: [DEIMv2] Real Time Object Detection Meets DINOv3](https://github.com/Intellindust-AI-Lab/DEIMv2)

### 초록(Abstract)

단순하면서도 효과적인 Dense O2O에 기반하여, DEIM은 더 빠른 수렴과 향상된 성능을 보여주었다. 본 연구에서는 여기에 DINOv3 특징을 결합하여 **DEIMv2**를 제안한다. DEIMv2는 X부터 Atto까지 총 8가지 모델 규모를 포괄하며, GPU, 엣지, 모바일 환경을 모두 아우르는 배포를 지원한다.

X, L, M, S 변형에서는 DINOv3로 사전학습(pretrained) 또는 증류(distilled)된 백본을 채택하고, **공간 튜닝 어댑터(Spatial Tuning Adapter, STA)**를 도입하였다. STA는 DINOv3의 단일 스케일 출력을 효율적으로 다중 스케일 특징으로 변환하며, 강력한 의미적 표현에 세밀한 디테일을 보완함으로써 검출 성능을 향상시킨다.

초경량 모델(Nano, Pico, Femto, Atto)의 경우, 엄격한 자원 제약을 충족하기 위해 깊이와 너비 가지치기를 적용한 HGNetv2를 사용한다. 여기에 단순화된 디코더와 개선된 Dense O2O를 결합함으로써, DEIMv2는 다양한 시나리오 전반에서 성능과 비용 간의 우수한 균형을 달성하며 새로운 최신(state-of-the-art) 성능을 확립한다.

특히 가장 큰 모델인 **DEIMv2-X**는 파라미터 수가 50.3M에 불과함에도 57.8 AP를 달성하여, 56.5 AP를 얻기 위해 60M 이상의 파라미터가 필요했던 기존 X-스케일 모델들을 능가한다. 경량 모델 측면에서는 **DEIMv2-S**가 9.71M 파라미터로 COCO에서 50 AP를 최초로 돌파한 서브-10M 모델이며, 50.9 AP를 기록하였다. 더 나아가 단 1.5M 파라미터를 사용하는 초경량 **DEIMv2-Pico**조차도 38.5 AP를 달성하여, 약 50% 더 많은 파라미터(2.3M)를 사용하는 YOLOv10-Nano와 동등한 성능을 보인다.

![](/assets/images/posts/624/img.png)

(a) COCO 성능 vs. 파라미터 수

![](/assets/images/posts/624/img_1.png)

(b) COCO 성능 vs. FLOPs

**그림 0:** COCO [12] 데이터셋에서 최신 실시간 객체 검출기들과 비교했을 때, 제안하는 DEIMv2의 모든 변형(S, M, L, X)은 유사한 파라미터 수와 더 적은 연산 비용을 유지하면서도 평균 정밀도(AP) 측면에서 우수한 성능을 달성한다.

## 1. 서론(Introduction)

**표 1:** DEIMv2 변형들의 아키텍처 세부 사항과 주요 성능 결과. 서로 다른 변형들의 설정(configuration)과 COCO 벤치마크에서의 최종 평균 정밀도(Average Precision, AP)를 보고한다.

![](/assets/images/posts/624/img_2.png)

실시간 객체 검출(real-time object detection) [18, 6, 22, 29]은 자율 주행 [11], 로보틱스 [16], 산업 결함 검출 [8] 등 다양한 실제 응용 분야에서 핵심적인 구성 요소이다. 특히 엣지 및 모바일 디바이스에 적합한 경량 모델의 경우, 검출 성능과 계산 효율성 간의 균형을 달성하는 것은 여전히 중요한 도전 과제로 남아 있다.

현재 널리 사용되는 실시간 검출기들 가운데, **DETR 기반 방법**은 end-to-end 구조라는 장점으로 인해 점점 더 선호되고 있다. 다양한 환경에서 강건한 특징 표현을 제공하는 **DINOv3** [21]의 성능에도 불구하고, 이를 DETR 기반 모델에 통합하는 것이 실제로 얼마나 실현 가능하며 효과적인지에 대해서는 아직 충분히 연구되지 않았다.

본 연구에서는 기존 **DEIM** [7] 파이프라인을 기반으로 하여 **DINOv3** [21] 특징을 결합한 실시간 객체 검출기 **DEIMv2**를 제안한다. DEIMv2는 가장 큰 변형(L 및 X 크기)에서는 특징 표현의 풍부함을 극대화하기 위해 공식 DINOv3 사전학습(pretrained) 백본인 **ViT-Small**과 **ViT-Small+**를 사용한다. 반면 S 및 M 변형에서는 DINOv3로부터 증류(distilled)된 **ViT-Tiny**와 **ViT-Tiny+** 백본을 활용하여 성능과 효율성 간의 균형을 정교하게 맞춘다. 또한 초경량 환경을 고려하여 **Nano, Pico, Femto, Atto**의 네 가지 특화된 변형을 추가로 도입함으로써, DEIMv2의 확장성을 매우 넓은 연산 자원 범위로 확장한다.

대규모 데이터로 사전학습된 DINOv3의 강력한 특징 표현을 실시간 제약 하에서 효과적으로 활용하기 위해, 우리는 **공간 튜닝 어댑터(Spatial Tuning Adapter, STA)**를 설계하였다. STA는 DINOv3와 병렬로 동작하며, DINOv3의 단일 스케일 출력을 객체 검출에 필요한 다중 스케일 특징으로 파라미터 추가 없이 효율적으로 변환한다. 동시에 입력 이미지를 빠르게 다운샘플링하여 매우 작은 수용 영역(receptive field)을 갖는 세밀한 다중 스케일 디테일 특징을 제공함으로써, DINOv3가 제공하는 강한 의미적 정보(semantics)를 보완한다.

아울러 Transformer 커뮤니티의 최근 발전을 바탕으로 디코더 구조를 단순화하였다. 구체적으로, 기존의 FFN과 LayerNorm을 **SwishFFN** [20]과 **RMSNorm** [27]으로 대체하였으며, 이는 성능 저하 없이 효율성을 높이는 것으로 알려져 있다. 또한 반복적 정제(iterative refinement) 과정 동안 객체 쿼리의 위치가 크게 변하지 않는다는 점에 착안하여, 모든 디코더 레이어에서 쿼리 위치 임베딩을 공유하도록 설계하였다. 더 나아가 **Dense O2O**를 확장하여 객체 수준의 **Copy-Blend 증강(object-level Copy-Blend augmentation)**을 도입함으로써, 유효한 감독 신호를 증가시키고 모델 성능을 추가로 향상시켰다.

![](/assets/images/posts/624/img_3.png)

**그림 1:** ViT 기반 변형들의 백본 설계. 제안하는 **공간 튜닝 어댑터(Spatial Tuning Adapter, STA)**와 함께 **DINOv3**를 통합하였다.

COCO [12]에 대한 광범위한 실험을 통해, **DEIMv2**가 여러 모델 스케일 전반에서 최신(state-of-the-art) 성능을 달성함을 확인하였다. 이는 그림 0에서 확인할 수 있다. COCO [12]에서 최신 실시간 객체 검출기들과 비교했을 때, 제안하는 DEIMv2의 모든 변형(S, M, L, X)은 유사한 파라미터 수를 유지하면서도 더 적은 연산 비용으로 평균 정밀도(AP) 측면에서 우수한 성능을 보인다.

구조가 단순함에도 불구하고, DEIMv2 계열은 매우 강력한 성능을 보여준다. 예를 들어, 가장 큰 변형인 **DEIMv2-X**는 단 50.3M 파라미터만으로 COCO에서 57.6 AP를 달성하여, 60M 이상의 파라미터를 필요로 하면서도 56.5 AP에 그쳤던 기존 최고 성능의 X-스케일 검출기 **DEIM-X**를 능가한다. 더 작은 규모에서는 **DEIMv2-S**가 10M 미만의 파라미터로 50 AP를 최초로 돌파한 모델이라는 중요한 이정표를 세우며, 소형 스케일에서도 본 설계의 효과성을 입증한다.

더 나아가, 파라미터 수가 단 1.5M에 불과한 초경량 **DEIMv2-Pico**는 38.5 AP를 달성하여, 2.3M 파라미터를 사용하는 **YOLOv10-Nano**와 동등한 성능을 보이면서도 파라미터 수를 약 50% 줄였다. 이는 극단적인 초경량 영역에서 효율성과 정확도 간의 새로운 경계를 제시한다.

본 연구는 **DINOv3** [21] 특징을 실시간 객체 검출에 효과적으로 적용할 수 있음을 보여주며, 초경량 모델부터 고성능 모델까지 아우르는 범용적인 프레임워크를 제시한다. 우리가 아는 한, 이렇게 넓은 배포 시나리오 범위를 동시에 다루는 실시간 객체 검출 연구는 본 연구가 최초이다.

본 연구의 주요 기여는 다음과 같이 요약할 수 있다.

- GPU, 엣지, 모바일 배포를 모두 포괄하는 8가지 모델 크기를 제공하는 **DEIMv2**를 제안한다.
- 대형 모델의 경우, 강력한 의미적 특징을 위해 **DINOv3**를 활용하고, 이를 실시간 객체 검출에 효율적으로 통합하기 위해 **STA**를 도입한다.
- 초경량 모델의 경우, 전문가 지식을 바탕으로 **HGNetv2-B0**의 깊이와 너비를 효과적으로 가지치기하여 엄격한 연산 제약을 충족한다.
- 백본을 넘어 디코더를 추가로 단순화하고 **Dense O2O**를 개선하여 성능 한계를 더욱 확장한다.
- 마지막으로, COCO 벤치마크에서 모든 자원 설정 전반에 걸쳐 기존 최신 방법들을 능가하는 성능을 달성함으로써 새로운 SOTA 결과를 확립한다.

## 2. 방법(Method)

### 전체 아키텍처(Overall architecture)

전체 아키텍처는 **RT-DETR** [14]의 설계를 따르며, 백본(backbone), 하이브리드 인코더(hybrid encoder), 디코더(decoder)로 구성된다. 표 1에 나타난 바와 같이, 주요 변형인 X, L, M, S에서는 제안하는 **공간 튜닝 어댑터(Spatial Tuning Adapter, STA)**가 결합된 **DINOv3** 기반 백본을 사용하며, 나머지 변형들은 **HGNetv2** [1]를 사용한다. 백본에서 추출된 다중 스케일 특징은 먼저 인코더를 거쳐 초기 검출 결과를 생성하고 상위 K개의 후보 바운딩 박스를 선택한다. 이후 디코더는 이 후보들을 반복적으로 정제(iterative refinement)하여 최종 예측을 생성한다.

### ViT 기반 변형(ViT-based variants)

보다 큰 DEIMv2 변형(S, M, L, X)을 위해, 우리는 모델 용량과 효율성 간의 균형을 고려하여 **Vision Transformer(ViT)** [3] 계열을 중심으로 백본을 정교하게 설계하였다. L과 X 변형에서는 공개된 두 가지 **DINOv3** 모델 [21], 즉 **ViT-Small**과 **ViT-Small+**를 활용하며, 이들은 12개 레이어와 384차원 히든 크기를 갖는 강력한 의미적 표현을 제공한다. 더 가벼운 S와 M 변형의 경우, ViT-Small DINOv3로부터 직접 증류(distillation)한 **ViT-Tiny**와 **ViT-Tiny+** 백본을 사용한다. 이때 12-레이어 깊이는 유지하면서 히든 차원을 각각 192와 256으로 축소하였다. 이러한 설계는 S → M → L → X로 이어지는 매끄러운 스케일링 경로를 제공하며, 각 변형이 서로 다른 효율성 요구에 맞추어 경쟁력 있는 정확도를 유지하도록 한다.

### HGNetv2 기반 변형(HGNetv2-based variants)

**HGNetv2** [1]는 바이두 PaddlePaddle 팀이 개발한 모델로, 높은 효율성 덕분에 실시간 DETR 프레임워크에서 널리 사용된다. 예를 들어 **D-FINE** [17]은 HGNetv2 전체 계열을 백본으로 채택하고 있다. 초경량 DEIMv2 모델(Nano, Pico, Femto, Atto)에서도 HGNetv2-B0를 기반으로 하되, 서로 다른 파라미터 예산을 충족하기 위해 깊이와 너비를 점진적으로 가지치기(pruning)한다. 구체적으로, **Pico** 백본은 B0의 네 번째 스테이지를 제거하여 1/16 스케일까지만 출력을 유지한다. **Femto**는 Pico의 마지막 스테이지에서 블록 수를 두 개에서 하나로 줄인다. **Atto**는 한 단계 더 나아가, 해당 마지막 블록의 채널 수를 512에서 256으로 축소한다.

### 공간 튜닝 어댑터(Spatial Tuning Adapter)

DINOv3 특징을 실시간 객체 검출에 보다 효과적으로 적용하기 위해, 그림 1에 나타낸 **공간 튜닝 어댑터(STA)**를 제안한다. STA는 완전 합성곱 네트워크(fully convolutional network)로, 세밀한 다중 스케일 디테일을 추출하기 위한 초경량 피드포워드 네트워크를 통합하고, **Bi-Fusion** 연산자를 통해 DINOv3로부터 얻은 특징 표현을 추가로 강화한다.

**표 2:** DEIMv2에서 사용한 상세 학습 하이퍼파라미터. \*Back.\*은 백본(Backbone)을 의미한다. Local Loss는 D-FINE [17]에서 제안된 **세밀 위치 정합 손실(Fine-Grained Localization, FGL) 손실**과 **분리된 증류 포컬 손실(Decoupled Distillation Focal, DDF) 손실**을 함께 사용함을 나타낸다.

![](/assets/images/posts/624/img_4.png)

**DINOv3**는 ViT 백본을 기반으로 하며, 구조적으로 단일 스케일(1/16) 밀집 특징을 자연스럽게 생성한다. 그러나 객체 검출에서는 객체 크기의 분포가 매우 다양하므로, 다중 스케일 특징은 성능을 향상시키는 가장 효과적인 방법 중 하나이다. 이를 위해 **ViTDet** [10]는 디컨볼루션을 사용하여 최종 ViT 출력을 다중 스케일 특징으로 변환하는 **Feature2Pyramid** 모듈을 도입하였다.

이에 비해, 본 연구의 **STA**는 더욱 단순한 접근을 취한다. ViT의 여러 블록(예: 5번째, 8번째, 11번째)에서 얻은 1/16 스케일 특징을 **파라미터가 없는 이중선형 보간(bilinear interpolation)**을 통해 직접 여러 스케일로 리사이즈한다. 이렇게 생성된 다중 스케일 특징은, 세밀한 디테일을 추출하고 DINOv3의 출력 특징을 보완하도록 설계된 초경량 CNN과 **1×1 컨볼루션**으로 구성된 **Bi-Fusion 연산자**를 통해 추가로 강화된다.

이러한 설계는 효율성과 정확도 사이에서 매우 우수한 균형을 달성하며, 실시간 객체 검출에 특히 적합하다.

**표 3:** COCO [12] val2017에서 실시간 객체 검출기들과의 비교. 파라미터 수 기준으로 정렬됨.

![](/assets/images/posts/624/img_5.png)

![](/assets/images/posts/624/img_6.png)

![](/assets/images/posts/624/img_7.png)

**표 4:** COCO [12] val2017에서 초경량(ultra-light) 모델을 대상으로 한 실시간 객체 검출기 비교.

![](/assets/images/posts/624/img_8.png)

### 효율적인 디코더(Efficient Decoder)

우리는 표준 **변형 가능한 어텐션 디코더(deformable attention decoder)** [31]를 기반으로, Transformer 커뮤니티에서 널리 채택된 여러 효율 중심 기법을 도입하여 성능과 비용 간의 유리한 균형을 달성하였다. 구체적으로, 비선형 표현 능력을 강화하기 위해 **SwiGLUFFN** [20]을 통합하였고, 효율적으로 학습을 안정화하고 가속하기 위해 **RMSNorm** [27]을 적용하였다.

또한 반복적 정제(iterative refinement) 과정 동안 객체 쿼리의 위치가 거의 변하지 않는다는 점에 주목하여, 모든 디코더 레이어에서 **단일 위치 임베딩(position embedding)**을 공유하도록 제안하였다. 이를 통해 중복 계산을 제거하고 추가적인 연산 효율 향상을 달성한다.

### 향상된 Dense O2O(Enhanced Dense O2O)

이전 연구인 **DEIM** [7]에서 우리는 **Dense O2O**를 제안하였으며, 이는 학습 이미지당 객체 수를 증가시켜 더 강한 감독 신호를 제공함으로써 수렴 속도와 성능을 모두 향상시킨다. 초기에는 **Mosaic**과 **MixUp** [28]과 같은 이미지 수준 증강을 통해 그 효과를 입증하였다. **DEIMv2**에서는 이를 한 단계 더 확장하여, 배경 없이 새로운 객체를 추가하는 **Copy-Blend**를 활용한 객체 수준의 Dense O2O를 탐구한다.

**Copy-Paste** [4]가 대상 영역을 완전히 덮어쓰는 방식인 것과 달리, **Copy-Blend**는 새로운 객체를 이미지와 자연스럽게 혼합(blending)한다. 이러한 특성은 본 연구의 설정에 더 적합하며, 실험 전반에 걸쳐 일관된 성능 향상을 가져온다.

### 학습 설정 및 손실 함수(Training setting and loss)

전체 최적화 목표는 다섯 가지 손실 항의 가중합으로 구성된다. 즉, **매칭 가능성 인지 손실(Matchability-Aware Loss, MAL)** [7], **세밀 위치 정합 손실(Fine-Grained Localization, FGL) 손실** [17], **분리된 증류 포컬 손실(Decoupled Distillation Focal, DDF) 손실** [17], **바운딩 박스 손실(BBox Loss, L1)**, 그리고 **GIoU 손실** [19]이다. 전체 손실은 다음과 같이 정의된다.

![](/assets/images/posts/624/img_9.png)

학습에 사용한 하이퍼파라미터는 입력 해상도, 학습률, 학습 에폭 수, 그리고 Dense O2O 설정을 포함하여 표 2에 요약되어 있다. 흥미로운 관찰 결과로, **초경량 모델**에 FGL 및 DDF 손실을 적용할 경우 오히려 성능이 저하됨을 확인하였다. 이는 이들 모델의 제한된 표현 용량과 본질적으로 낮은 기본 정확도로 인해 **자기 증류(self-distillation)**의 효과가 감소하기 때문으로 해석된다. 이에 따라 **Pico, Femto, Atto** 변형의 학습에서는 이 두 손실 항(즉, local loss)을 제외하였다.

## 3. 실험(Experiments)

### 최신 실시간 객체 검출기와의 비교

표 3은 **DEIMv2**의 S, M, L, X 변형 전반에 걸친 성능을 요약하며, 기존 최신(state-of-the-art) 검출기들 대비 상당한 성능 향상을 보여준다. 예를 들어, 가장 큰 변형인 **DEIMv2-X**는 약 50M 파라미터와 151 GFLOPs만으로 **57.8 AP**를 달성하여, 62M 파라미터와 202 GFLOPs로 56.5 AP를 기록한 기존 최고 성능 모델 **DEIM-X**를 능가한다. 이는 DEIMv2가 더 적은 파라미터와 더 낮은 연산 비용으로도 더 높은 정확도를 제공할 수 있음을 보여준다.

소형 모델 측면에서도 **DEIMv2-S**는 COCO에서 10M 미만의 파라미터로 50 AP를 최초로 돌파한 모델이라는 새로운 이정표를 세웠다. DEIMv2-S는 약 11M 파라미터와 26 GFLOPs로 **50.9 AP**를 달성하였으며, 거의 동일한 모델 크기에서 49.0 AP를 기록한 기존 **DEIM-S** 대비 명확한 성능 개선을 보인다. 일반적으로 CNN 기반 백본이 하드웨어 친화적인 것으로 알려져 있지만, 본 연구의 **ViT 기반 백본**은 더 적은 파라미터와 낮은 FLOPs로 경량 설계를 달성하면서도, 확장성과 배포 유연성 측면에서 이점을 제공한다.

한편, 본 논문에서 제안한 방법들의 **지연 시간(latency)**은 아직 최적화되지 않았다. **Yolov12** [22]에서 사용된 **Flash Attention** [2]과 같은 기법을 적용하면 추론 속도를 추가로 가속할 수 있을 것으로 보인다. 전반적으로 FLOPs 감소는 적절한 최적화가 수반될 경우, ViT 기반 백본이 저지연 성능을 달성할 수 있는 잠재력을 지님을 시사한다.

흥미롭게도, **DINOv3 기반 DEIMv2 모델**을 유사한 파라미터 수와 FLOPs를 갖는 기존 **DEIM** 모델들과 비교했을 때, 정확도 향상의 대부분은 **중간 크기(medium)** 및 **대형(large)** 객체에서 비롯되며, **소형 객체(small)** 성능은 거의 변하지 않는 것으로 나타났다. 예를 들어, **DEIMv2-S**는 **APM 55.3**, **APL 70.3**을 기록하여 **DEIM-S**의 APM 52.6, APL 65.7을 크게 상회하지만, 소형 객체 성능(APS)은 31.4 대 30.4로 거의 유사하다. 더 큰 모델에서도 동일한 경향이 관찰되는데, **DEIMv2-X**는 APM을 61.4에서 62.8로, APL을 74.2에서 75.9로 향상시켰지만, 소형 객체 AP(39.2)는 **DEIM-M**의 38.8과 큰 차이가 없다.

이러한 결과는 DEIMv2의 주요 강점이 **중·대형 객체에 대한 표현력과 검출 성능을 향상시키는 데** 있음을 보여주며, 소형 객체 검출은 스케일 전반에서 여전히 도전 과제로 남아 있음을 시사한다. 이는 **DINOv3**가 강력한 전역적 의미 정보(global semantics)를 포착하는 데는 뛰어나지만, 세밀한 디테일 표현에는 한계가 있음을 다시 한번 확인해준다. 따라서 DINOv3 특징을 실시간 검출기에 더욱 효과적으로 통합하는 방법을 탐구하는 것은 향후 연구에서 흥미로운 방향이 될 것이다.

### 경쟁력 있는 초경량 객체 검출기와의 비교

표 4에 요약된 바와 같이, **DEIMv2의 초경량 변형들** 역시 강력한 성능을 보인다. 단 0.49M 파라미터를 사용하는 **DEIMv2-Atto**는 훨씬 더 작은 모델임에도 불구하고 **NanoDet-M**과 유사한 성능을 달성한다. 또한 **DEIMv2-Pico**는 **YOLOv10-N** [23]과 동등한 성능을 보이면서도, 필요한 파라미터 수는 절반 이하에 불과하다. 이러한 결과는 극단적으로 경량화된 설정에서도 DEIMv2의 효과성을 입증하며, 자원이 제한된 엣지 디바이스 환경에 매우 적합함을 보여준다.

## 4. 결론(Conclusion)

본 논문에서는 **DINOv3**의 강력한 의미적 표현과 제안한 경량 **공간 튜닝 어댑터(Spatial Tuning Adapter, STA)**를 결합한 차세대 실시간 객체 검출기 **DEIMv2**를 소개하였다. 세심한 설계와 스케일링을 통해, DEIMv2는 모델 크기 전반에 걸쳐 최신(state-of-the-art) 성능을 달성하였다. 대형 모델 영역에서는 **DEIMv2-X**가 기존의 대규모 검출기들보다 훨씬 적은 파라미터 수로 **57.8 AP**를 달성하였다. 반면 소형 모델 영역에서는 **DEIMv2-S**가 해당 크기에서 최초로 **50 AP**를 돌파하였으며, 초경량 **DEIMv2-Pico**는 **YOLOv10-N**과 동등한 성능을 보이면서도 50% 이상 적은 파라미터를 사용한다.

이러한 결과들은 DEIMv2가 단순히 효율적인 모델에 그치지 않고, **높은 확장성**을 갖춘 구조임을 입증한다. 즉, 정확도와 효율성 간의 경계를 한 단계 끌어올리는 **통합 프레임워크**를 제시한 것이다. 이러한 범용성 덕분에 DEIMv2는 자원이 제한된 엣지 디바이스부터 고성능 검출 시스템에 이르기까지 다양한 환경에 적합하며, 실제 응용 분야에서 실시간 객체 검출의 보다 폭넓은 활용을 가능하게 할 것으로 기대된다.
