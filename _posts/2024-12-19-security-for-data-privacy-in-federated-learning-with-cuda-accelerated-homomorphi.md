---
title: "Security for Data Privacy in Federated Learning with CUDA-Accelerated Homomorphic Encryption in XGBoost"
date: 2024-12-19 21:10:10
categories:
  - Article
---

<https://developer.nvidia.com/blog/security-for-data-privacy-in-federated-learning-with-cuda-accelerated-homomorphic-encryption-in-xgboost/>

[Security for Data Privacy in Federated Learning with CUDA-Accelerated Homomorphic Encryption in XGBoost | NVIDIA Technical Blog](https://developer.nvidia.com/blog/security-for-data-privacy-in-federated-learning-with-cuda-accelerated-homomorphic-encryption-in-xgboost/)

**페더레이티드 러닝의 데이터 프라이버시 보안을 위한 CUDA 가속 동형 암호화를 활용한 XGBoost**  
2024년 12월 18일  
**Ziyue Xu, Zhihong Zhang, Yuan-Ting Hsieh, Yan Cheng**

---

![](/assets/images/posts/436/img.jpg)

XGBoost는 표 형식 데이터를 모델링하는 데 널리 사용되는 머신 러닝 알고리즘입니다. NVIDIA는 XGBoost 모델을 단일 사이트 학습에서 다중 사이트 협업 학습으로 확장하기 위해 Federated XGBoost라는 XGBoost 플러그인을 개발했습니다. 이 플러그인은 분산 데이터 소스 간의 XGBoost 모델을 공동 학습할 수 있도록 지원하며, 수직 협업 환경뿐만 아니라 히스토그램 기반 및 트리 기반의 수평 페더레이티드 러닝도 포함합니다.

- **수직 환경**에서는 각 참여자가 전체 인구의 일부 특성을 보유하고, 레이블은 단 하나의 참여자가 소유합니다. 레이블 소유자는 "활성 참여자(active party)"로 불리며, 다른 모든 참여자는 "수동 참여자(passive parties)"로 간주됩니다.
- **수평 환경**에서는 각 참여자가 모든 특성과 레이블 정보를 보유하지만, 이는 전체 인구의 일부에만 해당합니다.

또한 NVIDIA FLARE는 도메인 독립적이고 오픈소스 및 확장 가능한 페더레이티드 러닝 SDK로, 실제 페더레이티드 러닝 경험을 향상시켰습니다. FLARE는 통신 문제를 해결할 수 있는 기능을 제공하며, 여기에는 여러 동시 학습 작업과 네트워크 상태로 인한 작업 중단 가능성을 처리하는 기능이 포함됩니다.

현재 Federated XGBoost는 완전한 상호 신뢰를 가정하고 구축되어 있어, 어떠한 참여자도 모델 학습 외의 추가 정보를 얻으려 하지 않는다고 전제합니다. 하지만 실제로는 "정직하지만 호기심 많은(honest-but-curious)" 설정이 페더레이티드 협업에 더 현실적입니다. 예를 들어, 수직 페더레이티드 XGBoost에서 수동 참여자는 활성 참여자가 보낸 그래디언트에서 레이블 정보를 복구하려 할 수 있습니다. 수평 페더레이티드 러닝에서는 서버나 다른 클라이언트가 각 클라이언트의 그래디언트 히스토그램에 접근하여 데이터 특성을 학습할 가능성이 있습니다.

**NVIDIA Flare 2.5.2**와 **Federated-Secure XGBoost**는 이러한 잠재적 정보 노출 문제를 해결하며 Federated XGBoost의 범위를 확장합니다. 구체적으로:

1. **수평 및 수직 보안 페더레이티드 알고리즘**이 구현되어 XGBoost 라이브러리가 지원하는 페더레이티드 스킴에 추가되었습니다. 이를 통해 다양한 가정 하에서 데이터 보안 문제를 해결합니다.
2. **동형 암호화(Homomorphic Encryption, HE)** 기능이 보안 페더레이티드 XGBoost 파이프라인에 추가되었습니다. 플러그인 및 프로세서 인터페이스 시스템을 사용하여 XGBoost의 계산과 NVIDIA Flare의 통신을 적절한 암호화 및 복호화로 연결합니다.
3. **HE 플러그인**이 CPU 기반과 CUDA 가속 방식으로 개발되어, 하드웨어와 효율성 요구 사항에 따라 유연하게 적용됩니다. CUDA 플러그인은 기존 서드파티 솔루션보다 훨씬 빠른 성능을 제공합니다.
4. 동형 암호화를 통해 주요 페더레이티드 계산 단계를 암호문 상태로 수행하며, 관련 자산(그래디언트 및 부분 히스토그램)은 암호화되어 계산 중에 다른 참여자가 이를 학습할 수 없도록 합니다. 이는 페더레이티드 러닝의 핵심 이점인 데이터 보안 보장을 제공합니다.

이 글에서 설명된 바와 같이, CUDA 가속 동형 암호화를 활용한 Federated XGBoost는 데이터 프라이버시를 보호하면서 수직 XGBoost의 성능을 기존 서드파티 솔루션 대비 최대 **30배 향상**시킵니다.

**협업 모드와 보안 패턴**

**수직 XGBoost**에서는 활성 참여자가 레이블을 보유합니다. 레이블은 전체 과정에서 "가장 가치 있는 자산"으로 간주되며, 수동 참여자들이 접근할 수 없어야 합니다. 따라서 활성 참여자는 모델 학습 관점에서 "주요 기여자"로 볼 수 있지만, 이 정보가 수동 클라이언트에게 노출될 가능성을 우려해야 합니다. 이 경우 보안 보호는 주로 레이블 정보를 수동 클라이언트로부터 보호하는 데 초점이 맞춰져 있습니다.

수직 협업에서 레이블 정보를 보호하기 위해, 활성 참여자가 각 샘플에 대해 그래디언트를 계산한 후, 그래디언트를 수동 참여자에게 보내기 전에 암호화합니다(그림 1). 수동 참여자는 암호화된 그래디언트(암호문)를 수신한 후, 각 참여자가 가진 특정 특성 분포에 따라 누적합니다. 결과적으로 생성된 누적 히스토그램은 활성 참여자에게 반환되어 복호화된 후 트리 생성에 사용됩니다.

![](/assets/images/posts/436/img.png)

**그림 1**: 보안 암호화 환경에서 페더레이티드 수직 XGBoost 파이프라인의 학습 과정(4단계) 데이터 흐름 설명.

**수평 XGBoost**에서는 각 참여자가 "동등한 지위"를 가지며(전체 특성과 일부 인구에 대한 레이블 보유), 페더레이티드 서버는 데이터를 소유하지 않고 집계를 수행합니다. 따라서 이 경우 클라이언트는 서버와 다른 클라이언트에게 정보가 노출될 가능성을 우려합니다. 보호해야 할 정보는 각 클라이언트의 로컬 히스토그램입니다.

수평 협업에서 로컬 히스토그램을 보호하기 위해, 히스토그램은 페더레이티드 서버로 집계되기 전에 암호화됩니다. 집계는 암호문 상태에서 수행되며, 암호화된 글로벌 히스토그램이 클라이언트로 반환됩니다. 클라이언트는 이를 복호화하여 트리 생성에 사용합니다. 이 과정에서 서버는 평문 히스토그램에 접근할 수 없으며, 각 클라이언트는 집계 후 글로벌 히스토그램만 학습하고, 개별 로컬 히스토그램은 알 수 없습니다.

![](/assets/images/posts/436/img_1.png)

**그림 2**: 보안 암호화 환경에서 페더레이티드 수평 XGBoost 파이프라인의 학습 과정(3단계) 데이터 흐름 설명.

**적절한 동형 암호화(HE) 스킴 선택**

GPU 지원 여부와 상관없이 다양한 HE 스킴을 지원하는 여러 라이브러리가 존재하며, 특정 페더레이티드 XGBoost 설정의 요구 사항에 가장 적합한 스킴을 선택하는 것이 중요합니다. 예를 들어, **참여자 수 N=5, 데이터 샘플 총합 M=200,000, 특성 수 J=30, 각 특성 히스토그램 슬롯 K=256**이라고 가정해 보겠습니다. 페더레이티드 러닝 애플리케이션의 유형(수직 또는 수평)에 따라 다른 알고리즘이 필요합니다.

### **수직 애플리케이션**

- **암호화 대상**: 개별 g/h 값
- **계산 작업**: g/h 값을 히스토그램 슬롯에 따라 암호화된 값을 더하는 작업

g/h 값의 수는 샘플 수와 같으므로, 부스팅 라운드마다:

1. 총 암호화 작업은 M×2=400,000 (g와 h 각각)이며, 한 번에 단일 숫자를 암호화합니다.
2. 총 암호화된 덧셈 작업은 (M−K)×2×J≈12,000,000입니다.

이 경우, 단일 숫자 암호화에 최적화된 **Paillier 스킴**이 적합합니다. 벡터를 대상으로 하는 CKKS와 같은 스킴은 메모리 낭비가 심하기 때문입니다.

### **수평 애플리케이션**

- **암호화 대상**: 로컬 히스토그램 G/H
- **계산 작업**: 로컬 히스토그램을 더해 글로벌 히스토그램 생성

부스팅 라운드마다:

1. 총 암호화 작업은 N×2=10 (G와 H 각각)이며, 한 번에 길이 J×K=7680인 벡터를 암호화합니다.
2. 총 암호화된 덧셈 작업은 (N−1)×2=18입니다.

이 경우, 길이가 긴 히스토그램 벡터(예: 7680)를 한 번에 처리할 수 있는 **CKKS 스킴**이 적합합니다.

### **CPU 및 GPU 지원 암호화 솔루션 제공**

CPU 전용과 효율적인 GPU 가속 솔루션 모두를 지원하여 다양한 요구 사항에 적합한 구현이 가능합니다.

### **실험 결과**

XGBoost와 NVIDIA Flare를 활용한 위의 파이프라인을 구현하고, 신용카드 사기 탐지 데이터셋을 사용해 보안 페더레이티드 파이프라인을 테스트했습니다.

#### **수직 학습 AUC (보안 및 비보안):**

[0] eval-auc:0.90515 train-auc:0.92747

[1] eval-auc:0.90516 train-auc:0.92748

[2] eval-auc:0.90518 train-auc:0.92749

#### **수평 학습 AUC (보안 및 비보안):**

[0] eval-auc:0.89789 train-auc:0.92732

[1] eval-auc:0.89791 train-auc:0.92733

[2] eval-auc:0.89791 train-auc:0.92733

#### **중앙 집중식 모델과 비교한 관찰 결과:**

1. **수직 페더레이티드 러닝 (비보안):**
   - 중앙 집중식 모델과 동일한 트리 모델을 생성.
2. **수직 페더레이티드 러닝 (보안):**
   - 중앙 집중식 모델과 동일한 트리 구조를 생성.
   - 각 참여자가 서로 다른 특성 하위 집합을 보유하므로, 각 참여자 간에 특성의 분할 정보(cut information)는 학습되지 않음.
3. **수평 페더레이티드 러닝 (보안 및 비보안):**
   - 중앙 집중식 모델과 다른 트리 모델을 생성. 이는 글로벌 데이터(중앙 집중식)와 로컬 데이터(수평)의 초기 특성 분위(quantile) 계산 방식 차이 때문임.

더 자세한 내용은 **NVIDIA Flare Secure XGBoost 예제**를 참조하십시오.

### **암호화 방법의 효율성**

다양한 크기(소형~~대형)와 특성 차원(적은 수~~많은 수)의 데이터셋을 사용하여 솔루션을 벤치마킹했습니다. 이러한 벤치마크는 알고리즘의 강건성을 입증하고, 속도와 효율성 측면에서 큰 성능 향상을 강조합니다.

**데이터셋 및 데이터 분할**

세 가지 데이터셋을 사용하여 데이터 크기와 특성 크기가 암호화 방법의 효율성에 미치는 영향을 분석했습니다. 데이터셋의 특성은 표 1에 요약되어 있으며, 신용카드 사기 탐지 데이터셋은 **CreditCard**, Epsilon 데이터셋은 **Epsilon**, HIGGS 데이터셋의 하위집합은 **HIGGS**로 명명되었습니다.

![](/assets/images/posts/436/img_2.png)

**표 1. 실험에 사용된 세 데이터셋 크기 요약 (데이터 규모 및 특성 차이 포함)**

### **수직 페더레이티드 러닝 데이터 분할**

훈련 데이터셋을 두 개의 클라이언트로 나누었으며, 각 클라이언트는 동일한 데이터 레코드에 대해 서로 다른 특성을 보유합니다(표 2).

![](/assets/images/posts/436/img_3.png)

**표 2. 수직 페더레이티드 러닝의 데이터 분할 요약**

### **수평 페더레이티드 러닝 데이터 분할**

훈련 데이터셋을 세 개의 클라이언트로 균등하게 나누었습니다(표 3).

![](/assets/images/posts/436/img_4.png)

**표 3. 수평 페더레이티드 러닝의 데이터 분할 요약**

### **실험 결과**

XGBoost 학습은 다음과 같은 매개변수로 진행되었습니다:

- **num\_trees = 10**, **max\_depth = 5**, **max\_bin = 256**  
  테스트는 NVIDIA Tesla V100 GPU와 Intel E5-2698 v4 CPU에서 수행되었습니다. **그림 3**과 **그림 4**는 시간 비교 결과를 보여줍니다. 시뮬레이션은 동일한 머신에서 실행되었으므로 페더레이티드 통신 비용은 무시할 수 있습니다.

#### **보안 수직 페더레이티드 XGBoost**

NVIDIA Flare 파이프라인의 CUDA 가속 Paillier 플러그인(GPU 플러그인)과 기존 서드파티 오픈소스 솔루션의 시간 비용을 비교했습니다. 두 솔루션 모두 HE 암호화를 사용합니다. **그림 3**은 데이터 및 특성 크기 조합에 따라 GPU 플러그인이 4.6배에서 최대 36배 더 빠름을 보여줍니다. 서드파티 솔루션은 CPU만 지원합니다.

![](/assets/images/posts/436/img_5.png)

**그림 3. 수직 협업에서 보안 페더레이티드 XGBoost를 위한 HE 솔루션별 속도 비교**

#### **보안 수평 페더레이티드 XGBoost**

수평 페더레이티드 XGBoost에서는 서드파티 솔루션이 HE를 사용하는 보안 옵션을 제공하지 않습니다. 따라서 NVIDIA Flare 파이프라인의 암호화 없는 버전과 CKKS 암호화 플러그인(CPU 플러그인)의 시간 비용을 비교하여 암호화로 인한 추가 비용을 평가했습니다.

**그림 4**에서 볼 수 있듯이, 이 경우 계산 비용은 수직 시나리오보다 훨씬 낮으며(크게 차이 있음), 암호화 추가 비용도 상대적으로 합리적이어서 GPU 가속이 필요하지 않을 수 있습니다. 단, 특성 히스토그램이 매우 넓은 데이터셋(Epsilon 등)에서는 암호화 추가 비용이 더 클 수 있지만, 수직 설정 대비 여전히 약 5%에 불과합니다.

![](/assets/images/posts/436/img_6.png)

**그림 4. 수평 협업에서 보안 대비 비보안 페더레이티드 XGBoost 실행 시간 비교**

### **요약**

이 글에서는 GPU 가속 동형 암호화를 활용하여 Federated XGBoost의 보안을 강화하고, NVIDIA FLARE를 통해 데이터 프라이버시를 보장하는 수평 및 수직 페더레이티드 러닝을 구현하는 방법을 시연했습니다.

기존 Federated XGBoost 솔루션과 비교했을 때, 새로운 기능은 다음과 같은 장점을 제공합니다:

1. **알고리즘 수준에서 데이터 안전성을 보장하는 보안 페더레이티드 XGBoost 파이프라인**
2. **GPU 가속을 통해 시장의 기존 대안보다 훨씬 빠른 효율적인 솔루션**

이 솔루션은 특히 금융 산업의 사기 탐지 모델 학습과 같이 데이터 보안과 학습 효율성을 모두 요구하는 분야에서의 활용을 촉진할 것입니다.

더 많은 정보와 엔드 투 엔드 예제를 보려면 [NVIDIA/NVFlare GitHub](https://github.com/NVIDIA/NVFlare)를 방문하십시오. 질문이나 의견이 있으면 **[federatedlearning@nvidia.com](mailto:federatedlearning@nvidia.com)**으로 연락 주십시오.

### **관련 리소스**

- **GTC 세션**: 신뢰 환경에서의 분산 협업 AI를 통한 페더레이티드 러닝
- **GTC 세션**: 금융 분야에서의 프라이버시 보존 대형 모델 적용
- **GTC 세션**: 추천 시스템 101: 대규모 학습 가속화
- **SDK**: NVFLare
- **SDK**: RAPIDS Accelerator for Spark
- **SDK**: CV-CUDA
