---
title: "Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild"
date: 2024-07-04 21:04:11
categories:
  - 인공지능
---

<https://arxiv.org/abs/2401.13627>

[Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://arxiv.org/abs/2401.13627)

초록

우리는 SUPIR(Scaling-UP Image Restoration)을 소개합니다. 이는 생성적 사전(generative prior)과 모델 확장의 힘을 활용한 획기적인 이미지 복원 방법입니다. 다중 모드 기술과 고급 생성적 사전을 활용하여 SUPIR는 지능적이고 현실적인 이미지 복원에서 중요한 진전을 이룹니다. SUPIR의 핵심 촉매제로서 모델 확장은 그 능력을 극적으로 향상시키고 이미지 복원에 새로운 잠재력을 보여줍니다. 우리는 2천만 개의 고해상도, 고품질 이미지를 포함하는 데이터셋을 수집하여 모델을 훈련시키며, 각각의 이미지에는 설명 텍스트 주석이 추가되어 있습니다. SUPIR는 텍스트 프롬프트를 통해 이미지를 복원하는 기능을 제공하여 응용 범위와 잠재력을 확장합니다. 또한 지각 품질을 더욱 향상시키기 위해 부정 품질 프롬프트(negative-quality prompts)를 도입합니다. 우리는 생성 기반 복원에서 발생하는 충실도 문제를 억제하기 위해 복원 안내 샘플링 방법도 개발했습니다. 실험 결과 SUPIR의 뛰어난 복원 효과와 텍스트 프롬프트를 통한 복원 조작의 새로운 가능성을 입증했습니다.

![](/assets/images/posts/191/img.png)

그림 1. 우리의 SUPIR 모델은 실제 저품질 이미지에 대해 뛰어난 복원 효과를 보여주며, 이는 (a)에서 설명됩니다. 추가적으로, SUPIR는 텍스트 프롬프트에 의해 구동되는 목표 복원 기능을 제공합니다. 예를 들어, 멀리 있는 흐릿한 물체의 복원을 지정할 수 있으며(사례 1), 물체의 소재 질감을 정의하고(사례 2), 고수준 의미에 기반하여 복원을 조정할 수 있습니다(사례 3).

### 1. 서론

이미지 복원(IR)의 발전은 지각적 효과와 IR 결과의 지능에 대한 기대를 크게 높였습니다. 생성적 사전(generative priors) 기반의 IR 방법들은 강력한 사전 학습된 생성 모델을 활용하여 고품질 생성과 사전 지식을 IR에 도입함으로써 이러한 측면에서 상당한 진전을 이루었습니다. 생성적 사전의 능력을 지속적으로 향상시키는 것은 더 나은 IR 결과를 얻기 위한 핵심 요소이며, 모델 확장은 중요한 접근법입니다. SAM [44]과 대형 언어 모델(LLMs) [7, 73, 74]과 같은 많은 작업이 모델 확장을 통해 놀라운 발전을 이루었습니다. 이는 초고품질 이미지를 생성할 수 있는 대규모 지능형 IR 모델을 구축하려는 우리의 추구를 더욱 자극합니다. 그러나 컴퓨팅 자원, 모델 아키텍처, 훈련 데이터 및 생성 모델과 IR의 협력과 같은 엔지니어링 제약으로 인해 IR 모델을 확장하는 것은 도전적입니다.

이 작업에서 우리는 복원 시각 효과와 지능의 더 큰 잠재력을 탐구하기 위한 최대 규모의 IR 방법인 SUPIR(Scaling-UP IR)을 소개합니다. 구체적으로, SUPIR는 26억 개의 매개변수를 포함하는 강력한 생성적 사전인 StableDiffusion-XL(SDXL)을 사용합니다. 이 모델을 IR에 효과적으로 배포하기 위해, 우리는 ZeroSFT 커넥터라는 새로운 구성 요소를 포함하는 대규모 어댑터를 설계하고 훈련합니다. 모델 확장의 이점을 극대화하기 위해, 우리는 각 이미지에 상세한 설명 텍스트가 포함된 2천만 개 이상의 고품질, 고해상도 이미지를 수집합니다. 우리는 이미지 콘텐츠 프롬프트를 제공하기 위해 130억 개의 매개변수를 가진 다중 모드 언어 모델을 활용하여 우리의 방법의 정확성과 지능을 크게 향상시킵니다. 제안된 SUPIR 모델은 다양한 IR 작업에서 뛰어난 성능을 보여주며, 특히 복잡하고 도전적인 실제 시나리오에서 최고의 시각 품질을 달성합니다. 또한, 이 모델은 텍스트 프롬프트를 통해 복원 과정을 유연하게 제어할 수 있어 IR의 가능성을 크게 확장합니다. 그림 1은 우리 모델의 효과를 보여줍니다.

우리의 작업은 단순히 모델을 확장하는 것에 그치지 않습니다. 모델 규모를 증가시키는 동안 우리는 복잡한 일련의 도전에 직면합니다. 첫째, 기존의 어댑터 설계는 IR의 복잡한 요구를 충족하기에 너무 단순하거나 [59], SDXL과 함께 훈련하기에는 너무 큽니다 [95]. 이 문제를 해결하기 위해, 우리는 ControlNet을 다듬고 사전 학습된 SDXL과 함께 작동하도록 새로운 커넥터인 ZeroSFT를 설계하여 컴퓨팅 비용을 줄이면서 IR 작업을 효율적으로 구현하려고 합니다. 저품질 이미지의 내용을 정확하게 해석하는 모델의 능력을 향상시키기 위해, 우리는 이미지 인코더를 미세 조정하여 이미지 열화 변형에 대한 견고성을 높였습니다. 이러한 조치는 모델 확장을 가능하고 효과적으로 만들고 안정성을 크게 향상시킵니다. 둘째, 우리는 설명 텍스트 주석이 포함된 2천만 개의 고품질, 고해상도 이미지를 수집하여 모델 훈련의 견고한 기초를 제공합니다. 우리는 저품질 샘플을 훈련 과정에 통합하는 역설적인 접근법을 사용합니다. 이를 통해 프롬프트를 사용하여 모델이 부정적 품질을 피하도록 유도하여 시각적 효과를 향상시킵니다. 마지막으로, 강력한 생성적 사전은 양날의 검입니다. 통제되지 않은 생성은 복원 충실도를 떨어뜨려 IR이 입력 이미지에 충실하지 않게 만들 수 있습니다. 낮은 충실도 문제를 해결하기 위해 우리는 복원 안내 샘플링 개념을 도입했습니다. 이러한 전략들을 효율적인 엔지니어링 관행과 통합함으로써, 우리는 SUPIR의 확장을 촉진할 뿐만 아니라 고급 IR의 경계를 확장합니다.

### 2. 관련 연구

이미지 복원(IR). IR의 목표는 열화된 이미지를 고품질의 열화 없는 이미지로 변환하는 것입니다 [22, 26, 89, 91, 98, 99]. 초기에는 연구자들이 독립적으로 다양한 유형의 이미지 열화를 탐구했으며, 예를 들어 초해상도(SR) [13, 19, 20], 잡음 제거 [11, 90, 92], 및 흐림 제거 [14, 60, 72] 등이 있습니다. 그러나 이러한 방법들은 종종 특정 열화 가정에 기반하고 있어 [25, 50, 58] 다른 열화에 일반화하는 능력이 부족합니다 [29, 53, 97?]. 시간이 지나면서 특정 열화 가정에 기반하지 않는 블라인드 IR 방법의 필요성이 증가했습니다 [5, 10, 25, 34, 35, 46–48, 94]. 이러한 추세에서 일부 방법들은 [81, 93] 더 복잡한 열화 모델을 통해 실제 열화를 합성하여 단일 모델로 여러 열화를 처리하는 것으로 잘 알려져 있습니다. DiffBIR [49]은 다양한 복원 문제를 단일 모델로 통합합니다. 본 논문에서는 DiffBIR와 유사한 설정을 채택하여 단일 모델을 사용하여 다양한 심각한 열화를 효과적으로 처리합니다.

생성적 사전(Generative Prior). 생성적 사전은 이미지의 내재된 구조를 포착하여 자연 이미지 분포를 따르는 이미지를 생성하는 데 능숙합니다. GANs [23, 39, 40, 64]의 등장으로 IR에서 생성적 사전의 중요성이 강조되었습니다. 다양한 접근 방식이 생성적 사전을 사용하며, 여기에는 GAN 인버전 [2, 4, 27, 57, 62], GAN 인코더 [9, 103], 또는 GAN을 IR의 핵심 모듈로 사용하는 방법 [80, 87]이 포함됩니다. GAN 외에도 다른 생성 모델들도 사전으로 사용할 수 있습니다 [10, 36, 55, 75, 100–102]. 우리의 연구는 주로 확산 모델에서 파생된 생성적 사전에 초점을 맞추고 있으며 [31, 61, 65, 67, 70, 71], 이는 제어 가능한 생성 [15, 18, 32, 59, 95]과 모델 확장 [63, 66, 68]에서 뛰어납니다. 확산 모델은 또한 IR에서 생성적 사전으로 효과적으로 사용되었습니다 [42, 49, 67, 77, 82]. 그러나 이러한 확산 기반 IR 방법들의 성능은 사용된 생성 모델의 규모에 의해 제한되며, 이로 인해 그 효과를 더욱 향상시키는 데 어려움을 겪고 있습니다.

모델 확장(Model Scaling)은 딥러닝 모델의 능력을 더욱 향상시키기 위한 중요한 수단입니다. 가장 대표적인 예로는 언어 모델의 확장 [7, 73, 74], 텍스트-이미지 생성 모델 [12, 37, 63, 67, 68, 85], 및 이미지 분할 모델 [44]이 있습니다. 이러한 모델들의 규모와 복잡성은 급격히 증가하여 이제 수십억 개의 매개변수를 포함하게 되었습니다. 매개변수의 증가로 인해 성능도 크게 향상되어 모델 확장의 엄청난 잠재력을 보여주고 있습니다 [38]. 그러나 모델 확장은 모델 설계, 데이터 수집, 컴퓨팅 자원 등과 같은 제한을 포함하는 체계적인 문제입니다. 많은 다른 작업들은 아직 모델 확장으로 인한 성능 향상을 크게 누리지 못했습니다. IR도 그 중 하나입니다.

![](/assets/images/posts/191/img_1.png)

그림 2. 이 그림은 제안된 SUPIR 모델의 워크플로우를 간략히 보여줍니다.

### 3. 방법론

제안된 SUPIR 방법의 개요는 그림 2에 나와 있습니다. 우리는 방법론을 세 가지 측면에서 소개합니다: 3.1절에서는 네트워크 설계 및 훈련 방법을, 3.2절에서는 훈련 데이터 수집 및 텍스트 모달리티 도입을, 3.3절에서는 IR을 위한 확산 샘플링 방법을 소개합니다.

### 3.1 모델 확장

#### 생성적 사전(Generative Prior)

대규모 생성 모델에 대한 선택지는 많지 않습니다. 고려할 만한 것은 Imagen [68], IF [16], SDXL [63]뿐입니다. 우리는 다음과 같은 이유로 SDXL을 선택했습니다. Imagen과 IF는 텍스트-이미지 생성을 우선시하며, 계층적 접근 방식을 사용합니다. 이들은 먼저 저해상도 이미지를 생성한 후 이를 계층적으로 업샘플링합니다. SDXL은 계층적 설계 없이 직접 고해상도 이미지를 생성하여 우리의 목표에 부합하며, 텍스트 해석보다는 이미지 품질 향상에 매개변수를 효과적으로 사용합니다. 추가적으로, SDXL은 Base-Refine 전략을 사용합니다. Base 모델에서는 다양하지만 저품질의 이미지가 생성됩니다. 이후, Refine 모델은 Base 모델에서 사용된 것보다 다양성은 적지만 훨씬 더 높은 품질의 훈련 이미지를 활용하여 이미지 품질을 향상시킵니다. 우리는 고품질 이미지의 방대한 데이터셋을 사용하여 훈련하기 때문에, SDXL의 이중 단계 설계는 우리의 목표에 불필요합니다. 우리는 더 많은 매개변수를 가진 Base 모델을 선택하여 이를 이상적인 생성적 사전으로 활용합니다.

![](/assets/images/posts/191/img_2.png)

![](/assets/images/posts/191/img_3.png)

![](/assets/images/posts/191/img_4.png)

**대규모 어댑터 설계(Large-Scale Adaptor Design)**.

SDXL 모델을 생성적 사전으로 선택했기 때문에, 제공된 저품질 입력에 따라 이미지를 복원할 수 있도록 이를 조정할 어댑터가 필요합니다. 어댑터는 저품질 이미지의 콘텐츠를 식별하고 픽셀 수준에서 생성을 정밀하게 제어해야 합니다. LoRA [32], T2I 어댑터 [59], 그리고 ControlNet [95]과 같은 기존의 확산 모델 적응 방법들은 우리의 요구를 충족시키지 못합니다: LoRA는 생성을 제한하지만 저품질 이미지 제어에는 어려움을 겪고, T2I는 저품질 이미지 콘텐츠 식별 능력이 부족하며, ControlNet의 직접 복사는 SDXL 모델의 규모에 도전적입니다. 이를 해결하기 위해, 우리는 두 가지 주요 기능을 가진 새로운 어댑터를 설계했습니다. 그림 3(a)에 나와 있습니다.

첫째, 우리는 ControlNet의 고수준 설계를 유지하면서 네트워크 트리밍 [33]을 통해 학습 가능한 복사본 내의 일부 블록을 직접 트리밍하여 엔지니어링 가능한 구현을 달성합니다. SDXL의 인코더 모듈 내 각 블록은 주로 여러 Vision Transformer (ViT) [21] 블록으로 구성되어 있습니다. 우리는 ControlNet의 효과에 기여하는 두 가지 주요 요인을 확인했습니다: 큰 네트워크 용량과 학습 가능한 복사본의 효율적인 초기화입니다. 주목할 만하게도, 학습 가능한 복사본의 블록을 부분적으로 트리밍하더라도 어댑터의 중요한 특성은 유지됩니다. 따라서 우리는 각 인코더 블록에서 ViT 블록의 절반을 간단히 트리밍합니다. 그림 3(b)에 나와 있습니다.

둘째, 우리는 어댑터를 SDXL에 연결하는 커넥터를 재설계했습니다. SDXL의 생성 능력은 뛰어난 시각적 효과를 제공하지만, 픽셀 수준 제어를 어렵게 만듭니다. ControlNet은 생성을 안내하기 위해 제로 컨볼루션을 사용하지만, 잔여에만 의존하는 것은 IR에 필요한 제어에 충분하지 않습니다. 저품질 가이던스의 영향을 증폭시키기 위해, 우리는 ZeroSFT 모듈을 도입했습니다. 그림 3(c)에 나와 있습니다. 제로 컨볼루션을 기반으로 한 ZeroSFT는 추가적인 공간 특징 전이(SFT) [79] 연산과 그룹 정규화 [84]를 포함합니다.

### 3.2. 훈련 데이터 확장

**이미지 수집(Image Collection)**. 모델의 확장은 훈련 데이터의 확장을 필요로 합니다 [38]. 하지만 아직 IR을 위한 대규모 고품질 이미지 데이터셋은 존재하지 않습니다. 비록 DIV2K [3]와 LSDIR [1]이 높은 이미지 품질을 제공하지만, 양적으로는 제한적입니다. ImageNet (IN) [17], LAION-5B [69], SA-1B [44]와 같은 더 큰 데이터셋은 더 많은 이미지를 포함하고 있지만, 그들의 이미지 품질은 우리의 높은 기준을 충족하지 못합니다. 이를 위해, 우리는 2천만 개의 1024×1024 고해상도, 고품질의 텍스처가 풍부한 이미지를 포함하는 대규모 데이터셋을 수집했습니다. 수집된 데이터셋과 기존 데이터셋의 규모 비교는 그림 3에 나와 있습니다. 우리는 또한 모델의 얼굴 복원 성능을 향상시키기 위해 FFHQ-raw 데이터셋 [40]에서 70,000개의 정렬되지 않은 고해상도 얼굴 이미지를 추가로 포함시켰습니다. 그림 5(a)에서는 우리의 데이터 크기를 다른 잘 알려진 데이터셋과 비교하여 보여줍니다.

**다중 모달리티 언어 가이드(Multi-Modality Language Guidance)**. 확산 모델은 텍스트 프롬프트를 기반으로 이미지를 생성하는 능력으로 잘 알려져 있습니다. 우리는 텍스트 프롬프트가 IR에도 도움이 될 수 있다고 믿습니다: (1) 이미지 콘텐츠를 이해하는 것은 IR에 매우 중요합니다. 기존 프레임워크는 종종 이러한 이해를 간과하거나 암묵적으로 처리합니다 [24, 29]. 텍스트 프롬프트를 통합함으로써, 우리는 저품질 이미지에 대한 이해를 IR 모델에 명시적으로 전달하여 누락된 정보의 목표 복원을 용이하게 합니다. (2) 심각한 열화의 경우, 최고의 IR 모델조차도 완전히 손실된 정보를 복구하는 데 어려움을 겪습니다. 이러한 경우, 텍스트 프롬프트는 사용자 선호에 따라 누락된 정보를 목표로 완성할 수 있는 제어 메커니즘으로 작용할 수 있습니다. (3) 우리는 텍스트를 통해 원하는 이미지 품질을 설명할 수 있으며, 이는 출력물의 지각 품질을 더욱 향상시킵니다. 예시는 그림 1(b)에서 볼 수 있습니다. 이를 위해, 우리는 두 가지 주요 변경을 가합니다. 첫째, 우리는 전체 프레임워크를 수정하여 LLaVA 다중 모달 LLM [52]을 파이프라인에 통합합니다. 그림 2에 나와 있듯이, LLaVA는 열화-견고 처리가 된 저품질 이미지

![](/assets/images/posts/191/img_5.png)

를 입력으로 받아 이미지 내 콘텐츠를 명시적으로 이해하고 이를 텍스트 설명 형태로 출력합니다. 이러한 설명은 복원을 안내하는 프롬프트로 사용됩니다. 이 과정은 테스트 중 자동화될 수 있어 수동 개입이 필요 없습니다. 둘째, PixART [12]의 접근 방식을 따르며, 우리는 또한 모든 훈련 이미지에 대한 텍스트 주석을 수집하여 모델 훈련 중 텍스트 제어의 역할을 강화합니다. 이 두 가지 변화는 SUPIR가 이미지 콘텐츠를 이해하고 텍스트 프롬프트를 기반으로 이미지를 복원하는 능력을 부여합니다.

![](/assets/images/posts/191/img_6.png)

**그림 4.** CFG는 부정적 훈련 샘플 없이 아티팩트를 도입하여 시각적 품질 향상을 저해합니다. 부정적 샘플을 추가하면 CFG를 통해 품질을 더욱 향상시킬 수 있습니다.

![](/assets/images/posts/191/img_7.png)

![](/assets/images/posts/191/img_8.png)

알고리즘 1 복원 가이드 샘플링.

![](/assets/images/posts/191/img_9.png)

그림 5. (a) 잘 알려진 다른 데이터 세트와 비교한 우리 데이터의 상대적 크기를 보여줍니다. SA-1B [44]와 비교했을 때, 우리 데이터 세트는 더 높은 품질과 더 많은 이미지 다양성을 가지고 있습니다. (b) 복원 가이드 샘플링 메커니즘을 보여줍니다.

![](/assets/images/posts/191/img_10.png)

### 4. 실험

#### 4.1. 모델 훈련 및 샘플링 설정

훈련을 위해, 전체 훈련 데이터에는 텍스트 설명이 포함된 2천만 개의 고품질 이미지, 70,000개의 얼굴 이미지 및 100,000개의 부정적 품질 샘플과 해당 프롬프트가 포함됩니다. 더 큰 배치 크기를 가능하게 하기 위해, 우리는 훈련 중에 이미지를 512×512 패치로 자릅니다. 우리의 모델은 Real-ESRGAN [81]에서 사용된 설정을 따르는 합성 열화 모델을 사용하여 훈련되며, 유일한 차이점은 생성된 저품질(LQ) 이미지를 훈련을 위해 512×512로 크기를 조정하는 것입니다. 우리는 AdamW 옵티마이저 [54]를 학습률 0.00001로 사용합니다. 훈련 과정은 10일 동안 64개의 Nvidia A6000 GPU에서 배치 크기 256으로 진행됩니다. 테스트를 위해, 하이퍼파라미터는 T=100, λ\_cfg=7.5, τ\_r=4입니다. 우리의 방법은 1024×1024 크기의 이미지를 처리할 수 있습니다. 입력 이미지의 짧은 면을 1024로 크기를 조정하고, 1024×1024의 서브 이미지를 테스트를 위해 잘라낸 후, 복원 후 원래 크기로 다시 조정합니다. 별도의 언급이 없는 한, 프롬프트는 수동으로 제공되지 않으며, 처리는 전적으로 자동으로 진행됩니다.

![](/assets/images/posts/191/img_11.png)

**그림 6**. 다양한 방법과의 정성적 비교. 우리의 방법은 도전적인 열화에서도 해당 객체의 텍스처와 세부 사항을 정확하게 복원할 수 있습니다. 다른 방법들은 부러진 부리나 불규칙한 얼굴과 같은 의미적으로 올바른 세부 사항을 복구하지 못합니다.

#### 4.2. 기존 방법과의 비교

우리의 방법은 다양한 열화를 처리할 수 있으며, BSRGAN [93], Real-ESRGAN [81], StableSR [77], DiffBIR [49], PASD [88]와 같은 동일한 능력을 가진 최신 방법들과 비교합니다. 일부 방법들은 512×512 크기의 이미지만 생성할 수 있습니다. 비교에서는 테스트 이미지를 이 요구 사항에 맞추기 위해 잘라내고 우리의 결과를 다운샘플링합니다. 우리는 합성 데이터와 실제 데이터 모두에서 비교를 수행합니다.

**합성 데이터**. 테스트를 위해 LQ 이미지를 합성하기 위해, 우리는 이전 연구 [45, 97]를 따르고, 단일 열화 및 복합 열화를 포함한 여러 대표적인 열화에서 우리의 효과를 보여줍니다. 구체적인 세부 사항은 표 1에서 찾을 수 있습니다. 우리는 정량적 비교를 위해 다음 지표를 선택했습니다: 전참조 지표 PSNR, SSIM, LPIPS [96], 비참조 지표 ManIQA [86], ClipIQA [76], MUSIQ [43]. 우리의 방법이 모든 비참조 지표에서 최고의 결과를 달성함을 확인할 수 있으며, 이는 우리의 결과가 뛰어난 이미지 품질을 반영합니다. 동시에, 우리는 전참조 지표에서 우리의 방법의 단점을 지적합니다. 우리는 이러한 전참조 지표의 한계를 강조하는 간단한 실험을 제시합니다. 그림 7을 참조하세요. 우리의 결과가 더 나은 시각적 효과를 가지지만, 이러한 지표에서는 우위를 점하지 못함을 볼 수 있습니다. 이 현상은 많은 연구에서도 지적되었습니다 [6, 26, 28]. 우리는 IR의 품질이 향상됨에 따라 기존 지표의 참조 가치를 재고할 필요가 있으며, 고급 IR 방법을 평가하기 위한 보다 효과적인 방법을 제안합니다. 우리는 또한 그림 6에서 몇 가지 정성적 비교 결과를 보여줍니다. 심각한 열화에서도, 우리의 방법은 항상 저품질 이미지의 콘텐츠를 충실하게 나타내는 매우 합리적이고 고품질의 이미지를 생성합니다.

![](/assets/images/posts/191/img_12.png)

**그림 7**. 이러한 예시는 지표 평가와 인간 평가 간의 불일치를 보여줍니다. SUPIR은 고충실도 텍스처를 가진 이미지를 생성하지만, 낮은 지표 점수를 얻습니다.

![](/assets/images/posts/191/img_13.png)

**표 1.** 정량적 비교. 빨간색과 파란색은 각각 최고 및 두 번째로 좋은 성능을 나타냅니다. ↓는 작을수록 좋은 지표를 나타내며, 다른 지표는 클수록 좋습니다.

![](/assets/images/posts/191/img_14.png)

**표 2.** 실세계 비교 결과 및 소거 연구.

![](/assets/images/posts/191/img_15.png)

**그림 8.** (a) 이러한 플롯은 변수 τ\_r​의 함수로서 정량적 결과를 나타냅니다. "No τ\_r​"는 제안된 샘플링 방법을 사용하지 않음을 의미합니다. (b) 우리의 사용자 연구 결과.

![](/assets/images/posts/191/img_16.png)

**그림 9.** 제안된 ZeroSFT와 제로 컨볼루션을 비교합니다. 제로 컨볼루션을 직접 사용하는 것은 중복된 세부 정보를 초래합니다. ZeroSFT는 저충실도의 세부 정보를 효과적으로 완화할 수 있습니다.

### 4.4. 소거 연구(Ablation Study)

**커넥터(Connector)**. 우리는 제안된 ZeroSFT 커넥터와 제로 컨볼루션 [95]을 비교합니다. 정량적 결과는 표 2c에 나와 있습니다. ZeroSFT에 비해 제로 컨볼루션은 비참조 지표에서 비슷한 성능을 보이지만, 전참조 성능은 훨씬 낮습니다. 그림 9에서, 비참조 지표의 하락은 저충실도 콘텐츠 생성으로 인해 발생함을 발견했습니다. 따라서, IR 작업에서는 ZeroSFT가 지각 효과를 잃지 않으면서 충실도를 보장합니다.

**훈련 데이터 확장(Training data scaling)**. 우리는 대규모 모델을 두 개의 더 작은 IR 데이터셋인 DIV2K [3]와 LSDIR [1]에서 훈련했습니다. 정성적 결과는 그림 12에 나와 있으며, 이는 대규모 고품질 데이터로 훈련하는 것이 중요하고 필요함을 명확히 보여줍니다.

**부정적 품질 샘플과 프롬프트(Negative-quality samples and prompt)**. 표 2b는 다양한 설정 하에서의 정량적 결과를 보여줍니다. 여기서 우리는 이미지 품질을 설명하는 긍정적인 단어를 "긍정적 프롬프트"로 사용하고, 부정적 품질 단어와 3.2절에서 설명한 CFG 방법을 "부정적 프롬프트"로 사용합니다. 긍정적 프롬프트나 부정적 프롬프트를 각각 추가하는 것만으로도 이미지의 지각 품질을 향상시킬 수 있음을 알 수 있습니다. 둘을 동시에 사용하는 것이 최상의 지각 결과를 낳습니다. 부정적 샘플을 훈련에 포함시키지 않으면, 이 두 프롬프트는 지각 품질을 향상시킬 수 없습니다. 그림 4와 그림 11(a)는 부정적 프롬프트 사용으로 인한 이미지 품질 향상을 보여줍니다.

![](/assets/images/posts/191/img_17.png)

그림 10. 실제 LQ 이미지에 대한 정성적 비교. SUPIR은 구조화된 건물과 실제와 같은 강을 성공적으로 복원합니다. 또한 해변 의자의 수평 판자와 같이 LQ에 존재하는 디테일도 유지합니다. 더 자세히 보려면 확대하세요.

![](/assets/images/posts/191/img_18.png)

**그림 11**. 텍스트 프롬프트의 영향. (a) 부정적 프롬프트는 상세하고 선명한 복원 결과를 낳습니다. (b) 환각이 있는 긍정적 프롬프트를 제공하면, SUPIR는 LQ 이미지에 없는 콘텐츠 생성을 피합니다. 더 나은 보기를 위해 확대하십시오.

![](/assets/images/posts/191/img_19.png)

**그림 12**. 다양한 규모의 데이터셋에서 SUPIR 훈련에 대한 정성적 비교. 더 나은 보기를 위해 확대하십시오.

![](/assets/images/posts/191/img_20.png)

**그림 13**. 제안된 복원 안내 샘플링 방법의 효과. 작은 τ\_r​는 결과를 LQ 이미지에 더 가깝게 만들어 충실도를 강조합니다. 큰 τ\_r​는 지각 품질을 강조하지만, 충실도는 낮아집니다. 더 나은 보기를 위해 확대하십시오.

### 4.4. 소거 연구(Ablation Study)

**커넥터(Connector)**. 우리는 제안된 ZeroSFT 커넥터와 제로 컨볼루션 [95]을 비교합니다. 정량적 결과는 표 2c에 나와 있습니다. ZeroSFT에 비해 제로 컨볼루션은 비참조 지표에서 비슷한 성능을 보이지만, 전참조 성능은 훨씬 낮습니다. 그림 9에서, 비참조 지표의 하락은 저충실도 콘텐츠 생성으로 인해 발생함을 발견했습니다. 따라서, IR 작업에서는 ZeroSFT가 지각 효과를 잃지 않으면서 충실도를 보장합니다.

**훈련 데이터 확장(Training data scaling)**. 우리는 대규모 모델을 두 개의 더 작은 IR 데이터셋인 DIV2K [3]와 LSDIR [1]에서 훈련했습니다. 정성적 결과는 그림 12에 나와 있으며, 이는 대규모 고품질 데이터로 훈련하는 것이 중요하고 필요함을 명확히 보여줍니다.

**부정적 품질 샘플과 프롬프트(Negative-quality samples and prompt)**. 표 2b는 다양한 설정 하에서의 정량적 결과를 보여줍니다. 여기서 우리는 이미지 품질을 설명하는 긍정적인 단어를 "긍정적 프롬프트"로 사용하고, 부정적 품질 단어와 3.2절에서 설명한 CFG 방법을 "부정적 프롬프트"로 사용합니다. 긍정적 프롬프트나 부정적 프롬프트를 각각 추가하는 것만으로도 이미지의 지각 품질을 향상시킬 수 있음을 알 수 있습니다. 둘을 동시에 사용하는 것이 최상의 지각 결과를 낳습니다. 부정적 샘플을 훈련에 포함시키지 않으면, 이 두 프롬프트는 지각 품질을 향상시킬 수 없습니다. 그림 4와 그림 11(a)는 부정적 프롬프트 사용으로 인한 이미지 품질 향상을 보여줍니다.

**복원 안내 샘플링 방법(Restoration-guided sampling method)**. 제안된 복원 안내 샘플링 방법은 주로 τ\_r​에 의해 제어됩니다. τ\_r​가 클수록 각 단계에서 생성에 대한 수정이 적어집니다. τ\_r​가 작을수록 더 많은 생성된 콘텐츠가 LQ 이미지에 가깝도록 강제됩니다. 정성적 비교는 그림 13을 참조하십시오. τ\_r = 0.5일 때, 출력이 LQ 이미지에 의해 제한되어 텍스처와 세부 사항을 생성할 수 없어 이미지가 흐릿해집니다. tau\_r = 6 일 때는, 생성 중에 많은 안내가 없습니다. 모델은 LQ 이미지에 없는 많은 텍스처를 생성하며, 특히 평면 영역에서 그러합니다. 그림 8(a)는 변수 tau\_r의 함수로서 복원의 정량적 결과를 보여줍니다. 그림 8(a)에서 볼 수 있듯이, τ\_r​를 6에서 4로 줄여도 시각적 품질은 크게 저하되지 않으며, 충실도 성능은 향상됩니다. 복원 안내가 계속 강화되면서, PSNR은 계속 향상되지만, 이미지는 점차 흐릿해지고 세부 사항이 손실됩니다. 그림 13에서 볼 수 있듯이 말입니다. 따라서 우리는 τ\_4를 기본 매개변수로 선택하며, 이는 이미지 품질을 손상시키지 않으면서 충실도를 효과적으로 향상시킵니다.

### 5. 결론

우리는 모델 확장, 데이터셋 보강 및 고급 설계 기능을 통해 지각 품질과 제어된 텍스트 프롬프트를 향상시키며 IR의 지평을 확장하는 선구적인 IR 방법인 SUPIR를 제안합니다.

**감사의 말씀**. 이 연구는 중국 국가자연과학재단(National Natural Science Foundation of China) (62276251, 62272450), CAS-HK 공동 연구실, 중국 국가중점 R&D 프로그램 (No. 2022ZD0160100), 및 중국 과학 아카데미 청소년 혁신 촉진 협회(Youth Innovation Promotion Association of Chinese Academy of Sciences) (No. 2020356)의 지원을 받았습니다.

<https://www.youtube.com/watch?v=OZiD2-K7Io8>
