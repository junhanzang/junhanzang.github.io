---
title: "Scalable Extraction of Training Data from (Production) Language Models"
date: 2024-01-09 23:19:42
categories:
  - 인공지능
---

Poem 반복문으로 정보 유출 시켰던 논문

결국 P(x) = y 라는 수식을 기반으로 함

x가 이전에 학습했던 데이터라면 이걸 기반으로 y라는 기억을 떠올리게 될 것이다가 기본 컨샙

y가 vector들의 증폭으로 인한 오류 발생이라면 가능함

추가적인 정보는 당연하게 모델이 클 수록 내뱉을 수 있는 양이 많아진다.

더 많은 반복 학습을 하니까.

GPT는 일반적인 LLM과 다르다고 말하는데, 내가 볼때는 잘 모르겠음. 애초에 비공개 모델이라

데이터 역산도 결국 자신들이 internet crolling한거라 100퍼 신뢰도에 대해서는 모르겠음
