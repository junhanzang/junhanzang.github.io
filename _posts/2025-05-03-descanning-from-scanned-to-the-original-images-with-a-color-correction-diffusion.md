---
title: "Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model"
date: 2025-05-03 23:25:00
categories:
  - 인공지능
tags:
  - descanning
---

<https://aifactory.space/task/8832/overview?utm_source=pytorchkr&ref=pytorchkr>

[디스캐닝 모델 체험](https://aifactory.space/task/8832/overview?utm_source=pytorchkr&ref=pytorchkr)

<https://arxiv.org/abs/2402.05350>

[Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model](https://arxiv.org/abs/2402.05350)

<https://github.com/jhcha08/Descanning>

[GitHub - jhcha08/Descanning: [AAAI 2024] Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model](https://github.com/jhcha08/Descanning)

**초록**  
문서와 이미지와 같은 방대한 양의 아날로그 정보가 디지털 세계에서 저장, 공유, 분석을 위해 스캔된 복사본 형태로 디지털화되고 있다. 그러나 이러한 콘텐츠는 인쇄, 보관, 스캔 과정에서 발생하는 다양한 왜곡으로 인해 품질이 심각하게 저하된다. 스캔된 복사본으로부터 고품질 콘텐츠를 복원하는 작업은 많은 제품에서 필수적인 과제로 떠올랐지만, 아직까지 체계적으로 탐구되지 않았으며, 우리가 알기로는 공개된 데이터셋도 존재하지 않는다. 본 논문에서는 이 문제를 **디스캐닝(Descanning)**으로 정의하고, **DESCAN-18K**라는 고품질의 대규모 신규 데이터셋을 소개한다. 이 데이터셋은 다양한 복합 열화를 포함한 실제 환경의 원본 이미지와 스캔 이미지 쌍 총 18,000쌍으로 구성되어 있다. 이러한 복합적인 열화를 제거하기 위해, 우리는 전역 색상 열화를 보정하는 **컬러 인코더(color encoder)**와 국지적인 열화를 제거하는 **조건부 노이즈 제거 확산 확률 모델(conditional denoising diffusion probabilistic model, DDPM)**로 구성된 새로운 이미지 복원 모델 **DescanDiffusion**을 제안한다. 또한 DescanDiffusion의 일반화 능력을 더욱 향상시키기 위해, 스캔 이미지에서 흔히 나타나는 열화를 재현하는 방식으로 **합성 데이터 생성 기법**도 설계하였다. 종합적인 실험과 분석을 통해, 우리의 DescanDiffusion이 상용 복원 제품을 포함한 기존 방법들보다 객관적·주관적으로 뛰어난 성능을 보임을 입증하였다.

**서론**  
지난 수십 년 동안 잡지, 책, 사진 등 일반적인 종이 형태의 정보는 디지털 형태로 저장, 공유, 분석하기 위해 스캔 과정을 통해 활발히 디지털화되어 왔다. 예를 들어, 구글은 2002년부터 "Project Ocean"이라는 프로젝트명 아래 2,500만 권 이상의 책을 스캔하고 디지털화하였다(Love 2017). 하지만 이러한 스캔된 이미지들은 인쇄, 보관, 스캔 과정에서 다양한 요인에 의해 품질이 저하되는 경우가 많다. 따라서 원본 정보를 정확하게 보존하려면, 이러한 과정에서 발생한 열화를 디지털화된(스캔된) 복사본에서 제거하는 것이 필요하다. 기술적으로 보면, 각 스캔 이미지는 원본 디지털 이미지를 인쇄하고 다시 스캔하여 얻어진 것이므로, 스캔본마다 대응되는 **정답 디지털 원본(Ground Truth)** 이 존재한다.

본 논문에서는 이러한 문제를 **디스캐닝(descanning)**이라는 새로운 역문제(inverse problem)로 정의한다. 즉, 스캔본으로부터 원래의 디지털 이미지를 복원하는 이미지 복원 문제이다. 이는 물리적으로 종이에 인쇄된 정보가 스캔 또는 보관 과정에서 손상된 것을 복원하는 것을 의미한다. 우리는 이러한 열화를 크게 두 가지 범주로 나눈다: **색상 관련 열화(color-related degradation, CD)**와 **비색상 열화(non-color-related degradation, NCD)**. CD에는 색상 변화(color transition)가 포함되고, NCD는 외부 노이즈, 내부 노이즈, 하프톤 패턴(halftone pattern), 텍스처 왜곡(texture distortion), 번짐 현상(bleed-through effect) 등을 포함하며, 이들 각각은 이후에 자세히 설명된다.

지금까지 여러 실제 이미지 복원 방법과 데이터셋들이 제안되어 왔으나, 현실 세계의 스캔 이미지에서 발생할 수 있는 다양한 복합 열화를 다룬 연구는 거의 없다. 이는 스캔 이미지에 특화된 데이터셋의 부족 때문이기도 하다. 따라서 학습 기반의 디스캐닝 모델을 훈련하기 위해서는 실제 스캔 이미지를 다수 수집하고, 이들의 열화 특성을 체계적으로 분석하는 것이 중요하다. 본 연구에서는 **DESCAN-18K**라는 새로운 디스캐닝용 데이터셋을 구축하였다. 이 데이터셋은 해상도 1024×1024의 RGB TIFF 원본 이미지와, 다양한 스캐너로부터 얻은 스캔본 이미지 쌍 18,360개로 구성되어 있다. DESCAN-18K는 위에서 언급한 대표적인 6가지 복합 열화가 존재하는 스캔 이미지에 대한 풍부한 정보를 제공하며, 다양한 자연 장면과 텍스트를 포함하고 있어 디스캐닝 문제를 어렵지만 실용적인 문제로 만든다. 이러한 특성은 일반적으로 한두 가지 열화 유형만 포함하거나, 텍스트 또는 이미지 중 하나만 포함하는 기존 복원 데이터셋과는 차별화된다. 우리는 DESCAN-18K에 대한 통계적 분석을 수행하고, 존재하는 열화를 체계화하였다. 또한 이 분석을 기반으로, 원래 DESCAN-18K와 유사한 열화를 포함한 추가 학습용 합성 데이터쌍도 생성하였다.

한편, 확산 모델(diffusion model, Sohl-Dickstein et al. 2015)은 최근 저수준 시각 작업(low-level vision task)에 매우 효과적인 생성 기법으로 주목받고 있다(Kawar et al. 2022; Saharia et al. 2022c). 그러나 이러한 모델은 아직 복합 열화를 포함한 이미지 복원 문제, 즉 본 논문에서 정의한 디스캐닝 문제에 충분히 활용되지 않았다. 이러한 복잡한 복원 문제를 해결하기 위해, 우리는 전역 색상 보정을 위한 컬러 인코더와 국지적 생성 복원을 위한 **조건부 노이즈 제거 확산 확률 모델(conditional denoising diffusion probabilistic model, DDPM)** (Ho, Jain, and Abbeel 2020)로 구성된 새로운 이미지 복원 모델 **DescanDiffusion**을 제안한다.

**본 논문의 주요 기여는 다음과 같다:**

1. 우리는 스캔 이미지에 존재하는 복합 열화를 제거하여 원본 이미지를 복원하는 실제적이고 새로운 이미지 복원 문제인 **디스캐닝(descanning)**을 정의한다.
2. 디스캐닝 과제를 위한 대규모 데이터셋인 **DESCAN-18K**를 구축하였다. 또한 이 데이터셋에 대한 통계적 분석을 수행하고, 원본 → 스캔 변환 과정에서 발생하는 열화 유형을 분석하였다. 이러한 분석을 기반으로 **합성 데이터 생성 기법**도 고안하였다.
3. 우리는 **DescanDiffusion**이라는 새로운 이미지 복원 모델을 제안한다. 이 모델은 전역 색상 보정을 위한 컬러 인코더와, 복합 열화를 다루기 위한 조건부 DDPM으로 구성된다.
4. 다양한 실험과 분석을 통해 DescanDiffusion의 효과를 입증하였다. 여기에는 보지 못한 유형의 스캐너에 대한 일반화 성능, 상용 제품과의 비교 등이 포함된다. DescanDiffusion은 기존의 다른 기법들보다 우수한 성능을 보였으며, 새로운 상황에도 잘 일반화된다.

**관련 연구**  
**단일 열화를 대상으로 한 이미지 복원**

단일한 색상 열화(CD, color degradation) ― 예를 들어 색상 바램(fading)이나 채도(saturation) 문제 ― 를 다루는 대부분의 이미지 복원 기법은 **합성곱 신경망(CNN)**이나 **비전 트랜스포머(Vision Transformer)**(Dosovitskiy et al. 2020)를 기반으로 개발되어 왔다(Wang et al. 2018; Xu et al. 2022; Zhu et al. 2017; Wang et al. 2022a; Wang et al. 2022b; Zamir et al. 2022; Liang et al. 2021). 예를 들어, Zhu et al. (2017)과 Wang et al. (2018)은 **이미지-투-이미지 변환 기반 생성적 적대 신경망(GAN, Goodfellow et al. 2014)** 기법의 대표적인 예이다.

단일한 비색상 열화(NCD, non-color degradation)를 대상으로는 **노이즈 제거(denoising)**(Lefkimmiatis 2018; Chang et al. 2020), **초해상도(super-resolution, SR)**(Zhang et al. 2018b; Niu et al. 2020), **블러 제거(deblurring)**(Nah, Hyun Kim, and Mu Lee 2017; Sun et al. 2015)와 같은 단일 작업에 대해 다양한 복원 기법들이 제안되어 왔다.

이러한 모델들은 블러, 노이즈 등 단일 열화가 존재할 때는 뛰어난 성능을 보인다. 하지만 다양한 색상 열화(CD)와 비색상 열화(NCD)가 동시에 존재할 때 이를 잘 처리할 수 있을지는 불확실하다. 디스캐닝(descanning) 문제의 경우, 스캔된 이미지는 스캐닝, 인쇄 등 디지털 처리 과정에서 비롯된 고도의 불확실성과 다양성을 지닌 복합적인 CD와 NCD를 포함한다. 따라서 위에서 언급한 기존 방법들을 그대로 적용하면 성능이 저하될 수 있으며, **디스캐닝에 특화된 모델**이 별도로 개발되어야 한다.

이에 본 논문에서는 CD와 NCD를 모두 적절히 처리할 수 있도록 설계된 구성 요소를 갖춘 **새로운 이미지 복원 모델**을 제안한다.

**현실 세계의 사진 복원**  
현실 세계의 사진 복원을 위한 다양한 연구들이 제안되어 왔다(Wan et al. 2020; Ho and Zhou 2022; Luo et al. 2021; Kim and Park 2018; Yu et al. 2022; Chen et al. 2021). Wan et al. (2020)은 이미지 공간과 잠재(latent) 공간 각각에서 변환 네트워크를 사용하여, 긁힘, 먼지 자국, 다양한 노이즈 등 여러 열화가 있는 **실제 오래된 사진**을 복원하였다. Ho and Zhou (2022)는 **스마트폰으로 스캔한 사진**에서 발생하는 열화를 제거하기 위해 반지도학습(semi-supervised) 방식을 사용하였고, 입력으로는 스마트폰으로 스캔한 DIV2K(Timofte et al. 2018) 이미지, 목표값으로는 원래의 디지털 버전을 사용하였다. Yu et al. (2022)은 **모아레 제거(demoiréing)**를 위한 ESDNet을 제안하였으며, 이는 시각적으로 어색한 색상 전이(color transitions)와 패턴을 동시에 제거한다는 점에서 디스캐닝(descanning)과 유사한 과제이다.

하지만 현실 세계에서 얻은 스캔 이미지에는 하프톤 패턴(halftone pattern)이나 번짐 현상(bleed-through effect)과 같은 **더 복잡한 특수한 비색상 열화(NCD)**가 존재하기 때문에, 기존 방법들로는 이러한 이미지를 적절히 복원하기 어렵다. 스캔된 문서를 복원하기 위한 **전통적인 이미지 처리 기반 방법**들도 일부 존재한다(Verma and Malik 2015; Bhasharan, Konstantinides, and Beretta 1997). 그러나 이들 방법은 대부분 문서 특화 열화 ― 예를 들어 어두운 테두리 제거, 스캔 시 생기는 명암 불균형 등 ― 를 제거하는 데 초점을 맞춘다. 이러한 열화는 일반적으로 책의 기하학적 불일치(예: 말린 페이지나 책등)로 인해 발생하며, **다양한 컬러 사진과 텍스트를 포함한 스캔 이미지를 원본 디지털 이미지로 복원하는** 본 연구의 목표와는 차이가 있다.

따라서 디스캐닝 문제를 포괄적으로 해결하기 위해, 우리는 **여러 스캐너에서 수집된 실제 스캔 이미지와 그 원본**으로 구성된 대규모 데이터셋을 구축하였으며, 스캔 이미지의 특성에 맞춰 설계된 디스캐닝 모델도 제안한다.

![](/assets/images/posts/556/img.png)

**캡션 참고**  
**그림 1**: DESCAN-18K에서 관찰되는 열화 예시들. (a)와 (e)는 DESCAN-18K에 포함된 스캔 이미지 예시이다. (b)부터 (h)까지는 (e)를 제외하고, 위쪽 행의 주황색 점선 패치는 원본 이미지에서, 아래쪽 행의 파란색 점선 패치는 해당 스캔 이미지에서 추출한 것이다. (더 다양한 예시는 부록을 참조하라.)

**이미지 복원을 위한 확산 모델(Diffusion Models)**  
최근 확산 모델(diffusion models)의 인상적인 생성 성능 덕분에, 이러한 모델들은 **텍스트-투-이미지 생성**(Ramesh et al. 2021; Saharia et al. 2022a), **자연어 처리**(Li et al. 2022), **비전 응용 분야**(Lugmayr et al. 2022; Baranchuk et al. 2021) 등 다양한 분야에 활발히 적용되고 있다. 이미지 복원을 위한 확산 모델들도 여러 가지가 제안되었다. 예를 들어, Kawar et al. (2022)은 **초해상도(SR), 블러 제거(deblurring), 인페인팅(inpainting)** 등 다양한 이미지 복원 작업을 위한 확산 모델을 소개하였다. Saharia et al. (2022c)은 **조건부 방식(conditional manner)**으로 DDPM을 적용하고, **반복적 정제(iterative refinement)** 과정을 통해 강력한 SR 성능을 달성하였다.

본 논문에서는 확산 모델, 특히 **DDPM**의 복원 능력과 일반화 능력을 활용한 **DescanDiffusion**을 제안한다. 우리는 일반적인 DDPM을 디스캐닝 문제에 단순히 적용하면 원본 이미지의 **색상 분포(color distribution)**에서 벗어나는 현상이 발생할 수 있음을 관찰하였다. 이 문제를 해결하기 위해, 스캔 이미지를 입력으로 받아 **원본 이미지의 색상 분포를 예측하고 색상 보정 이미지(color-corrected image)**를 계산하는 **컬러 인코더(color encoder)**를 설계하였다. 이를 통해 DDPM이 보다 유리한 초기 조건에서 복원을 시작할 수 있게 된다.

예측된 색상 분포는 **확산 과정 중 DDPM에 조건(condition)**으로도 활용되어, 색상 정보를 명시적으로 제공함으로써 모델을 더욱 효과적으로 유도할 수 있다.

**데이터셋**  
본 연구에서는 **DESCAN-18K**라는 대규모 데이터셋을 새롭게 제안한다. 이 데이터셋은 해상도 **1024×1024**의 RGB TIFF 형식으로 저장된 **스캔 이미지와 원본 이미지 쌍 18,360개**를 포함한다. 다양한 이미지/텍스트 콘텐츠, 색상, 질감 등을 포함하는 대량의 스캔-원본 이미지 쌍을 수집하기 위해, 우리는 **Raspberry Pi Foundation(Dixon 2012)**에서 **CC BY-NC-SA 3.0** 라이선스로 제공하는 11종의 잡지를 활용하였다. 해당 잡지들은 보관 기간이 수일에서 최대 7년에 이를 만큼 충분히 오래되어 다양한 형태의 열화를 포함하고 있다.

**데이터셋 처리 과정**  
우리는 다음과 같은 **다양한 상용 스캐너**를 사용하여 각 잡지 페이지를 수작업으로 스캔하였다:

- Plustek OpticBook 4800
- Canon imageRUNNER ADVANCE 6265
- Fuji Xerox ApeosPort C2060
- Canon imagePRESS C650

스캔된 이미지는 **RGB TIFF 포맷**으로 디지털화되며, 색상 보정을 위해 **IT 8.7 (ISO 12641)** 표준에 따라 보정된다. 대부분의 스캐너는 이 표준을 따르기 때문에, 스캐너 모델 간 색상 차이를 줄일 수 있어, 제안 모델의 **범용성**(다양한 스캐너에 대한 일반화)이 높아진다. 스캔 이미지 확보 후, 온라인에서 해당 페이지의 **원본 PDF 파일**을 수집하고 동일한 **RGB TIFF 포맷**으로 변환하였다.

잡지 페이지의 스캔본과 원본은 여백 설정, 종이 구김 등으로 인해 **정렬되지 않은 상태**로 존재하므로, 우리는 다음과 같은 절차를 거쳐 정렬 작업을 수행하였다:

- 각 페이지에 대해 **AKAZE (Alcantarilla and Solutions 2011)** 기반의 **이미지 정합(image registration)**을 수행
- 이후 **수작업으로 쌍을 검토**하여, 정렬 정도가 현저히 어긋난 이미지들은 제거
- 마지막으로, 각 이미지를 무작위로 **1024×1024** 크기로 자른 후, 다시 AKAZE를 사용해 정렬
- 결과적으로 **정렬된 이미지 쌍 18,360개**를 확보하였다.

Plustek OpticBook 4800 및 Canon imageRUNNER ADVANCE 6265로 스캔한 **18,000개의 이미지 중 17,640개는 학습용**, **360개는 검증용**으로 사용된다. 즉, 검증셋은 학습셋과 별도로 구성되어 있다. 또한 Fuji Xerox ApeosPort C2060과 Canon imagePRESS C650로 스캔한 **360개의 이미지는 테스트셋**으로 남겨둔다. **테스트셋에 사용된 스캐너는 학습 및 검증셋에 사용된 스캐너와 다르며**, 이는 **이전에 본 적 없는 스캐너 유형에 대한 일반화 성능**을 평가할 수 있도록 해준다.

**데이터셋 분석**

전체 데이터셋을 분석한 결과, 스캔 이미지에 존재하는 열화(degradation)는 총 **6가지 유형**으로 분류할 수 있었다. 각 열화 유형을 개별적으로 설명하지만, 실제로는 여러 열화가 **복합적으로** 나타나는 경우가 많다. 그림 1에서 (a)와 (e)는 DESCAN-18K에 포함된 **스캔 이미지 예시**이다. 그림 1의 (b)부터 (h)까지는 (e)를 제외하고, **위쪽 행의 주황색 점선 패치**는 **원본 이미지**에서 추출한 것이며, **아래쪽 행의 파란색 점선 패치**는 그에 대응되는 **스캔 이미지**에서 추출한 것이다.

그림 1에서 보이듯, 우리는 열화를 다음과 같이 분류한다:

- **외부 노이즈(External noise)**: 인쇄, 스캔, 보관 중 이물질이 유입되어 발생하는 노이즈로, **점(dot)** 또는 **국소적 얼룩(localized stain)** 형태로 나타난다.
- **내부 노이즈(Internal noise)**: 스캐닝 과정에서 발생하는 시각적 열화로, **구김**, **곡선**, **선형 레이저 패턴** 등으로 나타난다.
- **번짐 현상(Bleed-through effect)**: **뒷면 페이지의 내용이 비쳐 스캔본에 함께 담기는 현상**으로, 일반적인 실제 이미지에서는 나타나지 않고 **스캔 이미지에서만** 발생하는 특이한 열화다.
- **텍스처 왜곡(Texture distortion)**: 스캔 도중 종이의 **물리적 질감이나 주름**으로 인해 발생하는 왜곡. 이 열화는 일반적으로 이미지 **전체에 걸쳐 나타나는 경향**이 있으며, 반면 외부 노이즈는 **국소적으로** 나타난다.
- **하프톤 패턴(Halftone pattern)**: 인쇄 과정에서 **여러 색상(시안, 마젠타, 옐로우, 블랙 등)**의 **점(dot)**들을 **다양한 크기와 간격으로 배치하여 연속적인 형태를 표현**하려 할 때 생기는 열화다.
- **색상 전이(Color transition)**: 스캔 또는 보관 과정 중 이미지의 **색상이 전체적으로 변화**되는 **색채 왜곡**이다. 대표적으로 **색상 바램(fading)** 또는 **채도 증가(saturation)** 등이 이에 해당한다.

DESCAN-18K에 대한 **자세한 통계 분석**은 부록(supplementary material)에서 확인할 수 있다.

![](/assets/images/posts/556/img_1.png)

**그림 2**: **DescanDiffusion 개요**

- (a): **전반적인 DescanDiffusion의 처리 과정** — 전역 색상 보정(Global Color Correction)과 지역 생성 정제(Local Generative Refinement) 모듈로 구성됨
- (b): **전역 색상 보정 모듈** — **컬러 인코더(Color Encoder)**가 색상 보정 벡터를 예측하고, 이를 통해 **색상 보정 이미지** 를 생성
- (c): **조건부 DDPM(Conditional DDPM)**을 활용한 **지역 생성 정제 모듈**의 학습 과정

**합성 데이터 생성**  
우리는 데이터셋 분석을 바탕으로, 스캔 이미지에서 관찰된 열화 중 일부를 **시뮬레이션하여 합성 데이터**를 생성한다. 구체적으로 다음과 같은 방식으로 열화를 모사한다:

1. **색상 전이(Color transition)**: 원본 이미지의 **HSV 색 공간**을 조정하여 색상 왜곡을 모사한다.
2. **번짐 현상(Bleed-through effect)**: **두 개의 원본 이미지를 알파 블렌딩(alpha-blending)**하여 뒷면 내용이 비치는 현상을 생성한다.
3. **하프톤 패턴(Halftone pattern)** 및 **텍스처 왜곡(Texture distortion)**: **가우시안 노이즈(Gaussian noise)**를 적용하여 표현한다.
4. **외부 노이즈(External noise)** 및 **내부 노이즈(Internal noise)**: 각각 **점(dot)** 형태와 **선형 레이저 패턴(linear laser pattern)** 형태로 합성한다.

이러한 합성 과정을 통해, DescanDiffusion 모델이 **이전에 보지 못한 스캐너로부터 스캔된 이미지까지 효과적으로 복원할 수 있도록 일반화 성능을 향상**시키고자 한다.

열화의 강도와 적용 확률은 각 샘플마다 **균등 분포(uniform distribution)**를 따라 **무작위로 결정**되며, **DESCAN-18K 학습 데이터셋의 일부 원본 이미지**를 활용하여 합성 데이터를 생성한다. 구체적으로, **DescanDiffusion+** 모델은 전체 **17,640개의 학습 이미지 쌍 중, 25%는 합성-원본 쌍**, 75%는 기존의 **스캔-원본 쌍**을 사용하여 학습된다. 반면, **기존의 DescanDiffusion** 모델은 오직 스캔-원본 쌍만을 사용한다. 이 비율은 **경험적으로 결정된 값**이며, 이에 대한 **소거(ablation) 실험 결과**는 부록(supplementary material)에 포함되어 있다. 또한, 본 연구의 **합성 데이터 생성 방식은 어떤 원본 문서 이미지에도 적용 가능**하므로, **학습 데이터셋을 추가적으로 증강(augmentation)**하는 데 사용할 수 있다.

**사전 지식: DDPM**

이 절에서는 DescanDiffusion의 핵심 요소 중 하나인 **DDPM (Denoising Diffusion Probabilistic Model)** (Ho, Jain, and Abbeel 2020)을 간략히 소개한다.

데이터 분포로부터 샘플링된 이미지 x\_0​가 주어졌을 때, **정방향(noising) 확산 마르코프 과정**을 통해 여러 단계 t에 걸쳐 점진적으로 노이즈를 추가한다. 노이즈의 강도는 **노이즈 스케줄** **β**로 조절되며, 다음과 같은 확률 분포를 갖는다:

![](/assets/images/posts/556/img_2.png)

여기서 T는 확산 과정의 총 단계 수이며, x0,x1,…,x\_T​는 잠재 변수(latent variables)이다. T→∞일 때, x\_T​는 **등방성 가우시안 노이즈(Gaussian isotropic noise)**로 수렴한다. 정방향 과정 중 임의의 x\_t​는 다음의 **폐형식(closed-form)**을 통해 샘플링할 수 있다. 여기서 t∼U({1,…,T})이고:

![](/assets/images/posts/556/img_3.png)

![](/assets/images/posts/556/img_4.png)

![](/assets/images/posts/556/img_5.png)

**제안하는 방법**  
스캔된 이미지에는 복잡한 열화들이 혼합되어 있기 때문에, 디스캐닝(descanning)은 기존의 일반적인 이미지 복원 과제보다 훨씬 더 어려운 문제이다. 우리는 스캔 이미지의 열화를 **색상 관련 열화(CD)**와 **비색상 열화(NCD)**로 분류하였고, 이에 따라 새로운 이미지 복원 모델 **DescanDiffusion**을 설계하였다. 이 모델은 두 가지 모듈로 구성된다:

1. **전역 색상 보정 모듈(Global Color Correction Module)**
2. **국소 생성 정제 모듈(Local Generative Refinement Module)**

각 모듈은 각각 CD와 NCD를 효과적으로 처리하도록 설계되었다. **그림 2는 제안하는 DescanDiffusion의 전체 구조 개요를 나타낸다.**

**컬러 인코더를 활용한 전역 색상 보정**

그림 2 (b)에 나타난 **전역 색상 보정 모듈(global color correction module)**에서는, 원본 이미지 I\_o​의 **색상 분포(color distribution)**를 예측하기 위해 **컬러 인코더 Φ**를 사용한다. Φ의 출력은 스캔 이미지 I\_s​의 색상 분포를 보정하는 데 사용되며, 이 과정을 통해 I\_s​의 색상 분포가 I\_oI에 근접하게 되어 **대부분의 색상 관련 열화(CD)**가 제거된다. 이로써 생성된 **색상 보정 이미지 I\_c**는, 이후 단계인 **국소 생성 정제 모듈(local generative refinement module)**에서 **조건(condition)**으로 효과적으로 활용될 수 있다.

컬러 인코더 Φ로는 **ResNet-34**(He et al., 2016)를 채택하였다. 이는 계산 효율이 높고 수용 영역(receptive field)이 크기 때문이다. 입력으로는 스캔 이미지 I\_s​, 목표값으로는 원본 이미지의 색상 분포 vo∈R1×6가 주어진다. 컬러 인코더는 다음과 같이 출력 벡터 vc∈R1×6를 예측한다:

![](/assets/images/posts/556/img_6.png)

여기서 v\_o​와 v\_c​는 각각 원본 이미지 I\_o​와 색상 보정 이미지 I\_c​의 색상 채널 k∈{R,G,B}에 대해 계산된 **평균 μok,μsk** 및 **\*\*표준편차 σok,σsk\**로 구성된 벡터이다.

이 과정은 다음의 **L2 손실 함수**를 통해 최적화된다:

![](/assets/images/posts/556/img_7.png)

여기서 Θ는 컬러 인코더 Φ의 학습 가능한 파라미터이다.

![](/assets/images/posts/556/img_8.png)

참고로, **히스토그램 매칭(histogram matching)**을 모사할 수 있는 이미지-투-이미지 변환 방법들(Isola et al., 2017; Zhu et al., 2017)도 IcI\_cIc​ 복원에 사용할 수 있다. 그러나 본 논문에서 제안한 색상 보정 방식은 **훨씬 낮은 계산 복잡도**로도 **경쟁력 있는 성능**을 보이는 것으로 나타났다.

**DDPM 기반 국소 생성 정제(Local Generative Refinement)**

우리가 제안하는 **국소 생성 정제 확산 모델(LGRDM, Local Generative Refinement Diffusion Model)**은 주로 **색상 보정 이미지** **I\_c**​로부터 **비색상 열화(NCD)**를 제거하는 데 목적이 있다. 또한, LGRDM은 I\_c​의 **국소 색상 분포(local color distribution)**를 원본 이미지 I\_o​에 더 가깝게 이동시킬 수 있도록 한다.

![](/assets/images/posts/556/img_9.png)

![](/assets/images/posts/556/img_10.png)

**LGRDM(Local Generative Refinement Diffusion Model)**은 **UNet**(Ronneberger, Fischer, and Brox 2015)을 기반으로 한 **조건부 노이즈 제거 네트워크 ϵθ**를 포함한다. 그림 2 (c)에서 보듯이, ϵθ는 전 단계인 전역 색상 보정 모듈에서 나온 두 가지 요소를 조건으로 사용한다:

- **색상 보정 이미지 I\_c​**
- **색상 보정 벡터 v\_c​**

첫 번째 조건인 I\_c​는 복원 과정이 원본 이미지 I\_o​를 향하도록 **유도(guidance)**하며, 이를 통해 **더 빠르고 안정적인 수렴**이 가능해진다. I\_c​ 조건은 시간 단계 t∈{T,…,1}마다 잠재 변수 x\_t​와 **채널 차원에서 결합(concatenate)**함으로써 적용된다.

두 번째 조건인 v\_c​는 **생성 이미지의 색상 분포가 과도하게 벗어나는 것을 방지**하는 역할을 한다. DDPM은 생성 능력이 매우 뛰어난 대신, 목표 이미지와는 다른 색상 분포를 만들어낼 수 있는 경향이 있기 때문이다. v\_c​를 활용한 **색상 조건부 학습(color conditioning)**은 이러한 색상 분포의 왜곡을 **제한하고 유지**하는 데 도움을 준다.

이를 위해 v\_c​는 **단일 레이어 컬러 프로젝션 네트워크**를 통해 **고차원 임베딩 공간**으로 사영되며, 이후 **타임스텝 임베딩(timestep embedding)**에 더해져 조건 정보로 사용된다 (Nichol and Dhariwal 2021).

최종적으로, ϵθ​는 아래와 같은 방식으로 정의된 잠재 변수 x\_t​에서 **추가된 노이즈 ϵ**을 추정하도록 훈련된다:

![](/assets/images/posts/556/img_11.png)

이 훈련은 다음 손실 함수를 최소화하도록 최적화된다:

![](/assets/images/posts/556/img_12.png)

**알고리즘 1과 2는 LGRDM의 학습 및 추론 과정을 각각 의사 코드(pseudo-code)로 설명**하고 있으며, **알고리즘 2에 나오는** **T\_o**는 **샘플링 단계 수 중 최적값**으로, **경험적으로 결정된다** (자세한 내용은 부록 참조).

![](/assets/images/posts/556/img_13.png)

**표 1**:  
원본 **DESCAN-18K 테스트셋**에 대한 디스캐닝 성능의 정량적 비교 (평균 **PSNR/SSIM/LPIPS/FID** 기준). 별표(\*)가 붙은 방법은 **사전 학습된(pre-trained)** 버전임을 나타낸다.

**학습 전략에 대한 논의**  
우리의 모델은 **DESCAN-18K 데이터셋만을 사용하여 처음부터 학습**되었다. ResNet은 **전역 색상 보정(global color correction)**의 역할을 수행하기 위해 별도로 학습되었으며, 스캔 이미지의 색상 분포를 원본 이미지와 정렬시키는 데 집중되었다.

만약 전체 프레임워크를 처음부터 공동 학습하게 되면, 학습 초기에 ResNet이 출력하는 불완전한 결과가 DDPM 학습을 **혼란스럽게 만들고**, 결과적으로 **최적이 아닌 성능**으로 이어질 수 있다. 이는 DDPM이 ResNet의 출력을 **조건(condition)**으로 삼기 때문이다. 이 전략은 **텍스트-투-이미지 확산 모델 학습 시 텍스트 인코더를 고정(freeze)시키는 일반적인 방법**(Saharia et al. 2022b)과 유사한 원리이다.

![](/assets/images/posts/556/img.jpg)

**그림 3**: DESCAN-18K 테스트셋에 대한 **디스캐닝 성능의 정성적 비교**.  
각 행의 스캔 이미지(Scanned으로 표기)는 주로 다음과 같은 열화를 포함하고 있음:

- **1번째 행**: 텍스처 왜곡(texture distortion), 색상 전이(color transition), 선형 레이저 형태의 내부 노이즈(internal noise)
- **2번째 행**: 색상 전이와 텍스처 왜곡
- **3번째 행**: 1번째 행과 동일한 유형의 열화

우리의 **DescanDiffusion+ 모델**은 **텍스트 영역**, **자연 장면**, **화면 콘텐츠(screen contents)**에서 발생하는 열화를 처리함에 있어, 다른 이미지-투-이미지 변환 모델, 현실 사진 복원 모델, 최신 이미지 복원 기법, 그리고 상용 제품보다 **우수한 성능을 보인다**.  
(더 다양한 예시는 **부록(supplementary material)**에서 확인 가능)

### 실험 설정

**디스캐닝(descanning)**은 아직 기존 연구가 존재하지 않는 **새로운 문제**이기 때문에, 기존 방법들과 직접적인 비교가 매우 어렵다. 이 문제를 해결하기 위해, 우리는 디스캐닝과 유사한 작업을 수행하는 다양한 모델들과 함께 제안한 방법을 **광범위하게 평가**하였다. 비교 대상은 다음과 같이 분류된다:

1. **이미지-투-이미지 변환 모델**:
   - **Pix2PixHD** (Wang et al., 2018)
   - **CycleGAN** (Zhu et al., 2017)
2. **최근 이미지 복원 모델** (디스캐닝과 유사한 과제 수행):
   - **HDRUNet** (Chen et al., 2021)
   - **Restormer** (Zamir et al., 2022)
   - **ESDNet** (Yu et al., 2022)
   - **NAFNet** (Chen et al., 2022)
3. **현실 세계 사진 복원 모델**:
   - **OPR** (Wan et al., 2020)
   - **DPS** (Ho and Zhou, 2022)
4. **상용 복원 앱**:
   - **Clear Scan¹** (IndyMobileApp, 2016)  
     ([링크](https://play.google.com/store/apps/details?id=com.indymobileapp.document.scanner))
   - **Adobe Scan²** (Adobe, 2017)  
     ([링크](https://play.google.com/store/apps/details?id=com.adobe.scan.android))
   - **Microsoft Lens³** (Microsoft, 2015)  
     ([링크](https://play.google.com/store/apps/details?id=com.microsoft.office.officelens))
5. **최근 확산 기반 이미지 복원 모델**:
   - **DDRM** (Kawar et al., 2022)

![](/assets/images/posts/556/img_14.png)

**표 2**:

**히스토그램 매칭(histogram matching)**을 통해 전역 색상 보정을 수행한 상태에서의 DESCAN-18K 테스트셋에 대한 **디스캐닝 성능 정량 비교**. 사용된 **평가지표와 비교 모델**은 표 1과 동일함.

![](/assets/images/posts/556/img_15.png)

**표 3**:  
**원본 DESCAN-18K 테스트셋**에 대해 **DDRM**과 제안 모델인 **DescanDiffusion**의 **정량적 성능 비교**. DDRM은 **해상도 256×256**에서만 동작하기 때문에, DDRM에 대한 비교는 이 해상도에서 **독립적으로 수행**됨. 평가지표는 표 1과 동일함.

우리는 **OPR 및 DPS를 제외한 모든 비교 모델**을 **DESCAN-18K 학습셋으로 재학습(re-train)**하였다. OPR과 DPS는 **현실 세계 손상 사진 복원**에 최적화되어 있다고 판단하여, **공식 사전 학습된 모델**을 그대로 사용하였다.

**기존 방법과의 비교**

디스캐닝 성능을 **정량적으로 평가**하기 위해 다음의 네 가지 지표를 사용하였다:

- **PSNR (Peak Signal-to-Noise Ratio)**: 복원 이미지와 원본 이미지 간의 **픽셀 단위 정확도**를 측정
- **SSIM (Structural Similarity Index Measure)**: 사람의 시각 구조를 반영한 **지각적 유사도** 측정 (Wang et al., 2004)
- **LPIPS (Learned Perceptual Image Patch Similarity)**: 딥러닝 기반 **지각 품질 비교 지표** (Zhang et al., 2018a)
- **FID (Fréchet Inception Distance)**: 생성 이미지와 실제 이미지의 **분포 차이**를 측정 (Heusel et al., 2017)

표 1의 **정량적 결과**에 따르면, **DescanDiffusion** 및 **DescanDiffusion+**는 **모든 지표에서 기존 방법들(상용 제품 포함)을 능가**하였다. 테스트셋은 학습에 사용되지 않은 **다른 종류의 스캐너**로 스캔된 이미지로만 구성되어 있으므로, 이 결과는 **제안한 방법이 보지 못한 스캐너에 대해서도 뛰어난 일반화 성능과 실용성**을 가짐을 보여준다. 즉, **스캐너 종류와 관계없이** 안정적으로 복원이 가능하다는 점은, 현실 세계에 존재하는 **다양한 스캐너 환경**을 고려했을 때 디스캐닝 과제에서 매우 중요한 특성이다.

**표 2**는 비교 대상 모델들에 대해 **히스토그램 매칭 기반 전역 색상 보정**을 적용한 후의 정량적 성능을 나타낸다. 표 1과 비교했을 때, 대부분의 모델에서 지표가 **현저히 향상**되었음을 볼 수 있다. 이는 **스캔 이미지에서 색상 열화(CD)가 주요한 원인**임을 의미하며, 따라서 이를 처리하기 위한 **전역 색상 보정**의 중요성을 부각시킨다. 이러한 결과는 제안한 **컬러 인코더**와 **색상 조건부 DDPM(color-conditioned DDPM)**이

- **저차원 색상 통계**를 정밀하게 추정하고,
- **색상 분포에 기반한 모델 유도(guidance)**를 수행함으로써, **높은 디스캐닝 성능에 크게 기여**했음을 뒷받침한다.

**DescanDiffusion+**는 PSNR 및 SSIM에서 **DescanDiffusion보다 소폭 높은 성능**을 보였으며, LPIPS 및 FID에서는 **유사한 성능**을 나타냈다. 시각적으로 분석한 결과, DescanDiffusion+는 **합성된 열화와 유사한 고주파 열화**를 제거하는 데 더 효과적인 경향을 보였다 (자세한 예시는 부록 참고).

또한, **표 3**은 우리가 제안한 **DescanDiffusion**이 최신 **확산 기반 이미지 복원 모델인 DDRM**(Kawar et al., 2022)을 **능가함**을 보여준다. 이 결과는 **확산 기반 이미지 복원 모델들이 스캔 이미지의 복합 열화를 효과적으로 제거하기 위해서는, 전역 색상 보정 모듈과 같은 추가 구성 요소가 필요함**을 시사한다.

**그림 3**은 딥러닝 기반 방법들과 상용 제품의 시각적 복원 결과를 보여준다. DescanDiffusion은 **스캔 이미지에서 CD와 NCD 문제를 거의 완전히 해결**한 반면, 다른 모델들은 이러한 문제를 **충분히 처리하지 못하거나 오히려 악화시키는** 경우도 존재한다. 예를 들어, **3번째 행**의 예시에서는 **NAFNet과 ESDNet이 내부 노이즈 제거에 실패**하였고, **상용 제품** 및 **현실 사진 복원 모델들**은 일부 경우에 **열화를 제거하지 못하거나 새로운 아티팩트(artifact)를 생성**하기도 했다.

![](/assets/images/posts/556/img_16.png)

**표 4**:  
제안한 방법의 세 가지 구성 요소에 대한 **Ablation Study(구성 요소 제거 실험)** 결과.

![](/assets/images/posts/556/img_17.png)

**표 5**:  
DESCAN-18K 테스트셋에 대한 **추론 시간(inference time)** 비교.

### **구성 요소 제거 실험 (Ablation Study)**

우리는 제안한 모델의 세 가지 핵심 구성 요소가 성능에 미치는 영향을 분석하기 위해 **Ablation Study(구성 요소 제거 실험)**를 수행하였다:

1. **DDPM에 제공되는 색상 보정 이미지 조건** (CIC: Color-corrected Image Condition)
2. **DDPM에 제공되는 색상 보정 벡터 조건** (CVC: Color-correction Vector Condition)
3. **합성 데이터 생성 기법** (SDG: Synthetic Data Generation)

**표 4 (a), (b)**에 따르면, **전역 색상 보정 모듈**을 통해 얻은 **색상 보정 이미지 I\_c**를 DDPM의 조건으로 사용할 경우, 단순히 스캔 이미지를 조건으로 사용하는 **기본 DDPM(vanilla DDPM)**에 비해 **성능이 크게 향상**됨을 확인할 수 있다. 또한, 여기에 **색상 보정 벡터 v\_c**를 DDPM의 조건으로 **추가 제공**할 경우, **디스캐닝 성능이 추가적으로 향상**된다 (**표 4 (c)**). 이 v\_c​는 **R, G, B 채널별 평균(μ)과 표준편차(σ)**로 구성되어 있으며, 이를 통해 DDPM이 **색상 분포를 일관되게 유지하도록 명시적으로 유도**할 수 있다. 마지막으로, 기존 DESCAN-18K 데이터만 사용하는 대신 **합성 데이터를 혼합(SDG)**함으로써, **보지 못한 유형의 스캐너로 스캔된 이미지에 대한 일반화 성능**을 높일 수 있다. **표 4 (d)**는 SDG를 적용한 모델이 다른 구성보다 **우수한 성능**을 보인다는 것을 보여준다. 한편, **SDG만을 적용한 기본 DDPM** (표 4 (e)) 역시 기존 vanilla DDPM보다는 성능이 향상되었지만, **CIC, CVC, SDG를 모두 포함한 최종 모델**(표 4 (d))과 비교하면 **성능 저하**가 발생하였다. 따라서 **전역 색상 보정의 중요성**이 여전히 핵심임을 확인할 수 있다.

### **추론 시간 평가 (Inference Time Evaluation)**

**표 5**는 대표적인 경쟁 모델들의 **추론 시간**을 비교한 결과이며, **NVIDIA TESLA V100 GPU**에서 측정되었다. 우리의 방법은 **확산 기반 모델**이기 때문에, CNN이나 Transformer 기반 모델에 비해 **추론 속도가 느린 편**이다. 그러나 **표 1에서 확인된 바와 같이**, 제안한 모델은 다른 방법들보다 **우수한 성능을 달성**하였다. 게다가, 본 연구에서는 확산 과정을 순수한 노이즈가 아닌 **스캔 이미지에서 시작**하므로, **역방향 확산 과정을 단 10단계만 수행해도 최대 92%까지 추론 시간을 단축**할 수 있다. (자세한 설명은 **알고리즘 2** 및 **부록** 참고)

### **추가 데이터셋에 대한 실험**

![](/assets/images/posts/556/img_18.png)

**표 6**:  
**DPS** 및 **OPR** 데이터셋에 대한 **디스캐닝 성능의 정량적 비교 결과** (각각 DPS/OPR). 이들 데이터셋에는 명확한 정답 이미지(reference image)가 없기 때문에, **비참조 이미지 품질 지표**를 사용하였다:

- **NRQM** (Ma et al., 2017),
- **NIQE** (Mittal, Soundararajan, and Bovik, 2012),
- **PI** (Blau et al., 2018)

제안한 방법의 다양한 열화 상황에 대한 성능을 평가하기 위해, 우리는 **추가적인 데이터셋**에서도 모델을 비교하였다.

- **DPS** (Ho and Zhou, 2022): **스마트폰으로 스캔한 이미지 100장**
- **OPR** (Wan et al., 2020): **오래된 사진 이미지 7장**

**표 6**은 각 비교 모델의 정량적 성능을 데이터셋별로 나누어 보여준다 (슬래시로 구분). 결과는, 제안한 **DescanDiffusion이 스마트폰 스캔 이미지 및 복합 열화를 포함한 오래된 사진에 대해서도 일반화 성능을 잘 유지함**을 검증한다.

그럼에도 불구하고, **DescanDiffusion의 핵심 특화 영역은 스캐너로부터 생성된 스캔 이미지에서 복합적으로 혼합된 CD와 NCD를 제거하는 것**에 있다. 이러한 스캔 이미지의 특성으로 인해, 제안된 **DESCAN-18K는 디스캐닝 성능을 평가하기 위한 가장 적합한 데이터셋**임을 강조한다.

### **결론 (Conclusion)**

**방대한 양의 스캔 콘텐츠**가 존재하는 디지털 세계에서, **스캔 이미지 복원**은 매우 중요한 문제이다. 우리의 연구는, **이 문제를 디스캐닝(descanning)**이라는 이름으로 **처음으로 정의**하였으며, 이를 해결하기 위해 다음과 같은 기여를 한다:

- **DESCAN-18K**: 스캔 이미지와 원본 이미지 쌍으로 구성된 **대규모 데이터셋**을 새롭게 제안하였다.
- DESCAN-18K에 포함된 열화 유형을 분석하고, 이를 **색상 관련 열화(CD)**와 **비색상 열화(NCD)**로 분류하였다.
- 이 분석을 바탕으로, **전역 색상 보정을 위한 컬러 인코더**와 **국소 생성 정제를 위한 조건부 DDPM**을 결합한 새로운 이미지 복원 모델 **DescanDiffusion**을 제안하였다.

**풍부한 데이터셋과 특화된 모델 구조** 덕분에, DescanDiffusion은 **복원된 이미지의 시각적 품질 측면에서 매우 우수한 성능**을 달성하였다. 본 연구는 복잡하고 다양한 열화를 가진 이미지 복원 문제를 해결하기 위한 **정밀한 분석과 효과적인 아키텍처 설계 전략**을 제공함으로써, 관련 연구의 길을 열었다고 본다.

향후 방향으로는, 제안한 모델을 **광학 문자 인식(OCR)**과 같은 후속 작업에 활용하거나, 제안한 데이터셋을 기반으로 **현실 세계 이미지 복원 모델의 성능을 평가하는 데 활용**하는 것도 중요한 연구 과제가 될 수 있다.

### **감사의 말 (Acknowledgments)**

본 연구는 아래의 사업으로부터 지원을 받았습니다:

- 과학기술정보통신부(MSIT)에서 정보통신기획평가원(IITP)을 통해 지원된 **2022-0-00759 과제**
- 과학기술정보통신부(MSIT)에서 정보통신기획평가원(IITP)을 통해 지원된 **인공지능 혁신 허브 과제 (2021-0-02068)**
- 과학기술정보통신부(MSIT)에서 정보통신기획평가원(IITP)을 통해 지원된  
  **인공지능 융합혁신 인재양성 사업 (경희대학교), 과제번호 RS-2022-00155911**
