---
title: "Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought"
date: 2025-07-01 21:38:41
categories:
  - 인공지능
---

<https://arxiv.org/abs/2505.12514>

[Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org/abs/2505.12514)

**초록**  
대규모 언어 모델(Large Language Models, LLMs)은 다양한 응용 분야에서 뛰어난 성능을 보여주고 있으며, 특히 질문에 답하기 전에 '사고 토큰(thinking tokens)'을 생성하는 연쇄적 사고(chain-of-thought, CoT) 기법을 통해 어려운 추론 문제에서도 강력한 성능을 보이고 있다. 기존 이론 연구에서는 이산 토큰(discrete tokens)을 사용하는 CoT가 LLM의 추론 능력을 강화함을 보여주었으나, 최근 연속적 CoT(continuous CoT)에 대한 연구는 방향 그래프 도달성(directed graph reachability)과 같은 다양한 추론 과제에서 이산 방식보다 더 우수한 성능을 보임에도 불구하고, 이에 대한 이론적 설명은 부족한 실정이다.

본 논문에서는 연속 CoT를 사용하는 깊이 2의 트랜스포머가 그래프의 지름(diameter)을 D라 할 때, **D단계**의 연속 CoT만으로 방향 그래프 도달성 문제를 해결할 수 있음을 증명한다. 이는 현재까지 알려진 이산 CoT 기반의 고정 깊이 트랜스포머가 **O(n²)** 단계의 디코딩을 요구하는 것보다 훨씬 효율적이다 (여기서 n은 정점의 수, D < n). 우리의 구성에서 각 연속적 사고 벡터는 여러 탐색 경계를 동시에 인코딩하는 **중첩 상태(superposition state)**로 작동하여 병렬적인 너비 우선 탐색(BFS)을 가능하게 한다. 반면, 이산 CoT는 중첩 상태에서 단일 경로만을 샘플링하므로 순차적 탐색만 가능하며, 이는 더 많은 단계가 필요하고 지역 최적해에 빠질 위험이 있다.

우리는 이러한 이론적 구성과 학습을 통해 얻은 실험 결과가 잘 일치함을 실증적으로 확인하였다. 특히, **중첩 상태로서의 다중 탐색 경계 인코딩**은 명시적인 감독(supervision) 없이도 연속 CoT 학습 중에 자연스럽게 나타나는 현상임을 관찰하였다.

\* 공저자들의 기여는 동일함.

## 1 서론

대규모 언어 모델(Large Language Models, LLMs)은 특히 연쇄적 사고(chain-of-thought, CoT) 기법(Wei et al., 2022)을 적용했을 때, AIME나 수학 증명과 같은 어려운 문제를 포함한 다양한 추론 과제에서 우수한 성능을 보여주고 있다. 그러나 이러한 CoT를 활용하더라도, 보다 정교한 추론 능력을 요구하는 과제들—예컨대, 복잡한 규모의 추론 및 계획 문제(Zheng et al., 2024; Xie et al., 2024)—에서는 여전히 한계를 드러낸다(Kambhampati, 2024; Valmeekam et al., 2024; Zhou et al., 2025).

기존의 이산 CoT를 확장하여 더 복잡한 추론 문제를 해결하는 방법은 아직까지 명확히 해결되지 않은 연구 과제다. 최근 Hao et al. (2024)은 연속적인 잠재 사고(latent thought)를 활용하는 **Coconut**(chain-of-continuous-thought)을 제안하였고, 방향 그래프 도달성(directed graph reachability)과 같은 합성 과제뿐 아니라, GSM8K(Cobbe et al., 2021)와 같은 실제 수학 추론 벤치마크에서도 성능 향상을 보여주었다. 특히 Coconut은, 최종 해답에 도달하기 전에 여러 후보 탐색 경계를 잠재적으로 동시에 저장할 수 있음을 시사하는 초기 결과를 보인다. 이는 각 사고 토큰을 하나씩 샘플링하여 순차적으로 모델에 입력해야 하는 이산 CoT와는 뚜렷하게 대조된다. 그러나 연속적인 사고의 표현력과 작동 메커니즘에 대해서는 아직 명확한 이론적 이해가 부족하다.

본 연구에서는 Coconut의 메커니즘을 **그래프 도달성(graph reachability)** 문제를 통해 탐구한다. 이 문제는 방향 그래프 내에서 주어진 시작 노드와 도착 노드 사이에 경로가 존재하는지를 판단하는 과제이며, 매우 일반적인 형태의 문제로, 튜링 기계의 정지 문제와 같은 이론적 문제나 지식 그래프 등 실용적인 응용 사례들을 모두 포함한다(Ye et al., 2024; Hao et al., 2024; Zhou et al., 2025). 이러한 설정 하에서 우리는 그래프의 지름(두 노드 사이 최장 경로 길이)을 D라 할 때, **깊이 2의 트랜스포머**가 **D 단계의 연속 사고(continuous thought)**만으로도 **정점 수가 n인 그래프**에 대한 도달성 문제를 해결할 수 있음을 증명하였다(D < n). 반면, 이산 CoT를 사용하는 고정 깊이 트랜스포머의 경우에는 **O(n²)** 단계가 필요하다는 것이 현재까지의 최선 결과이다(Merrill and Sabharwal, 2023a).

직관적으로 말해, 우리의 구성에서는 각 잠재 사고 벡터가 여러 유효한 탐색 경로들의 **중첩(superposition)** 상태로 표현되므로, 매 자회귀(autoregressive) 단계마다 그래프 상에서 **암묵적 병렬 탐색**을 수행할 수 있다. 이러한 연속 사고는 양자역학에서의 중첩 상태(superposition state)처럼 작동하여, 다수의 탐색 경계를 동시에 저장하고 효율적인 **너비 우선 탐색(BFS)**을 가능케 한다(Böhm, 2013). 반면, 이산 사고 토큰은 중첩 상태에서 **붕괴된 상태(collapsed state)**로 볼 수 있으며, 모델이 탐색 분기를 하나만 선택하도록 강제한다. 이로 인해 잘못된 탐욕적 탐색이나, 되돌아가며 진행하는 깊이 우선 탐색 방식으로 흐를 수 있으며, 이는 더 많은 계산 비용을 초래한다. 또한 기존 이론적 접근은 주어진 문제나 입력 길이에 맞게 위치 인코딩을 맞춤 설계해야 했으나, 본 연구의 구성은 **사인파 위치 인코딩(sinusoidal positional encoding)**(Vaswani et al., 2017)이나 **회전 위치 임베딩(rotary position embedding, RoPE)**(Su et al., 2024)과 같은 실제 널리 쓰이는 위치 인코딩에도 적용 가능하다.

더 나아가, 우리는 이론적으로 설계한 구조가 실제 **기울기 기반 학습(gradient-based training)**에서도 잘 구현됨을 보였다. 구체적으로, **연속 CoT를 사용하는 깊이 2 트랜스포머**는 **이산 CoT를 사용하는 깊이 12 트랜스포머**보다 그래프 도달성 문제에서 더 뛰어난 성능을 보였다. 어텐션 패턴과 내부 표현을 분석한 결과, 연속 사고는 실제로 중첩 상태 내에서 다수의 가능성 있는 탐색 경계를 병렬로 인코딩하고 있다는 것이 확인되었다. 주목할 만한 점은, 이러한 **중첩 기반 표현**이 다른 탐색 경로들을 명시적으로 지도하지 않고도, **그래프 도달성의 최적 경로만을 학습한 상황에서 자발적으로 등장**한다는 것이다.

---

## ? 더 시각적으로, "탐색 방식" 비교

### 이산 CoT: 한 경로씩만 탐색

```
Start
  |
  v
 [A] --→ [B] --→ [C] --→ [D]
        (한 경로만 따라가며 생각함)
```

- 한 번에 하나의 경로만 따라감
- 실수하면 다시 돌아가야 함

깊이가 깊어질수록 느려짐

---
