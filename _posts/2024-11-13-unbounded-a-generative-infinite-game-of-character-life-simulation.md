---
title: "Unbounded: A Generative Infinite Game of Character Life Simulation"
date: 2024-11-13 12:23:48
categories:
  - 인공지능
---

<https://arxiv.org/abs/2410.18975>

[Unbounded: A Generative Infinite Game of Character Life Simulation](https://arxiv.org/abs/2410.18975)

**초록**

우리는 생성적 무한 게임이라는 개념을 도입합니다. 이는 생성 모델을 사용하여 기존의 유한하고 하드코딩된 시스템의 한계를 초월하는 비디오 게임입니다. 이 개념은 제임스 P. 카르세의 유한 게임과 무한 게임의 구분(Carse, 1986)에 영감을 받아, 최근 생성 AI의 발전을 활용하여 Unbounded라는 캐릭터 생활 시뮬레이션 게임을 개발했습니다. 이 게임은 생성 모델에 완전히 내포되어 있습니다. 구체적으로, Unbounded는 샌드박스 형식의 생활 시뮬레이션에서 영감을 받아, 가상 세계에서 사용자가 자율적인 가상 캐릭터에게 음식을 주고, 놀아주고, 지도하는 등의 상호작용을 할 수 있도록 합니다. 이 상호작용에는 LLM이 생성하는 개방형 메커니즘이 포함되어 있으며, 일부는 자발적으로 발생할 수 있습니다.

Unbounded를 개발하기 위해, 우리는 LLM(대형 언어 모델) 및 비주얼 생성 도메인에서 기술적 혁신을 제안합니다. 구체적으로, 우리는 다음을 제시합니다: (1) 게임의 메커니즘, 서사, 캐릭터 상호작용을 실시간으로 동적으로 생성하는 특수화된 디스틸드 대형 언어 모델(LLM), 그리고 (2) 여러 환경에서 캐릭터의 일관되면서도 유연한 시각적 생성을 보장하기 위해 비전 모델에 적용된 새로운 동적 지역 이미지 프롬프트 어댑터(IP-Adapter)입니다. 우리는 질적 및 양적 분석을 통해 우리의 시스템을 평가하였으며, 기존의 관련 접근 방식에 비해 캐릭터 생활 시뮬레이션, 사용자 지시 이행, 서사 일관성, 캐릭터 및 환경의 시각적 일관성에서 유의미한 개선을 보였음을 확인하였습니다.

![](/assets/images/posts/297/img.png)

**그림 1: Unbounded의 예시.** 우리는 사용자가 커스텀한 마법사 캐릭터 '아르키버스(Archibus)'의 삶을 따라갑니다. 사용자는 자연어를 사용해 생성적 게임과 상호작용할 수 있으며, 아르키버스의 배고픔, 에너지, 재미 수치가 이에 따라 갱신됩니다. 사용자가 플레이하는 동안 자발적이고 제한 없는 이야기가 전개되며, 캐릭터는 새로운 환경을 탐험하고 다양한 가능한 행동 및 예상치 못한 상호작용을 경험할 수 있습니다. 게임은 상호작용이 가능한 속도로 매초 갱신되며 실행됩니다.

**1. 서론**  
제임스 P. 카르세는 그의 저서 "유한 게임과 무한 게임: 놀이와 가능성으로서의 삶의 비전"(Carse, 1986)에서 두 가지 유형의 게임을 구분합니다. 카르세는 유한 게임을 "승리를 목적으로 하는" 게임으로 정의하며, 이는 경계와 고정된 규칙, 명확한 종료점을 가지고 있습니다. 반면, 무한 게임은 "플레이를 계속하기 위해 하는" 게임으로 고정된 경계가 없으며, 규칙이 진화합니다. 전통적인 비디오 게임은 본질적으로 유한 게임입니다. 이는 프로그래밍 및 컴퓨터 그래픽의 한계 때문입니다. 예를 들어, 게임 메커니즘은 프로그래밍 언어로 완전히 사전 정의되어야 하며, 그래픽 자산도 일반적으로 사전 설계되어야 합니다(전통적인 절차적 생성 방식도 구조적인 한계를 여전히 겪고 있음). 이는 플레이어가 취할 수 있는 행동과 경로가 유한하며 때로는 미리 정해져 있음을 의미합니다. 또한, 이러한 게임들은 사전 정의된 규칙, 경계, 승리 조건을 특징으로 하여 무한 게임의 정의와 상충됩니다.

최근 생성 모델의 발전은 매우 인상적입니다. 우리는 이러한 발전이 마침내 최초의 생성적 무한 비디오 게임을 만들 수 있는 가능성을 열었다고 가정합니다. 생성적 무한 게임은 모든 논리나 그래픽이 더 전통적인 프로세스가 아닌 생성 모델에 의해 완전히 포괄되는 게임입니다. 이러한 가능성을 실현한 두 가지 주요 발전이 있습니다: (1) 대형 언어 모델(LLM)은 지속적인 비디오 게임 메커니즘(예: 게임 환경 또는 캐릭터와의 상호작용, 캐릭터 상태 추적, 객체의 영속성)을 인코딩하고, 상호작용형 이야기를 생성하며, 자발적이고 때로는 발현적인 행동을 생성할 수 있습니다. (2) 시각적 생성 모델은 프롬프트에 따라 고품질의 이미지를 생성할 수 있습니다. 이 연구에서 우리는 게임의 모든 행동과 그래픽이 AI 모델에 의해 생성되어 하드코딩된 시스템의 제약을 초월한, 최초의 상호작용형 생성 무한 게임이라고 믿는 Unbounded를 소개합니다. Unbounded는 샌드박스 형식의 생활 시뮬레이션 및 디지털 펫 게임(예: Little Computer People, The Sims, Tamagotchi)에서 영감을 받았으며, 비디오 게임에서 얻기 어려웠던 제약 없는 스토리텔링 경험을 제공하는 던전 앤 드래곤 같은 테이블탑 롤플레잉 게임의 요소도 통합하고 있습니다.

이전에 발표된 몇 가지 유용한 연구는 우리의 생성적 무한 게임 개념과 관련된 아이디어들을 제안하였습니다. Gaudl 등(2018)은 게임 플레이와 게임 디자인을 융합하는 유체 게임(fluidic games)을 제안했으며, Cook 등(2016)의 자동화된 게임 디자인은 새로운 게임 제작을 돕는 자동화 시스템을 탐구했습니다. Treanor 등(2015)의 연구는 사용자 경험에서 인공지능을 전면에 내세운 게임 디자인 기법을 제안했습니다. 이러한 개념들은 사전 정의된 게임 매개 변수와 도구 내에서 구조화된 탐험을 강조하며, 디자인 공간은 광범위하지만 결국 유한하다는 점에서 우리의 생성적 무한 게임 정의와 다릅니다. 반면 우리가 구상하는 무한 게임은 사전 정의된 구조를 넘어 지속적으로 진화하는 것을 목표로 하며, 생성 모델이 실시간으로 콘텐츠와 메커니즘을 동적으로 생성하여 고정된 종료점이나 상호작용의 한계 없이 열린 게임 플레이 경험을 제공합니다.

게임의 일부를 생성하는 구성 요소로서 머신 러닝 모델을 사용하는 중요한 연구도 존재합니다. Agarwal(2024)은 새로운 상호작용을 생성하고, Sun 등(2023)은 새로운 메커니즘과 아이템, 일부 그래픽 자산을 생성합니다. Liapis 등(2019)은 게임 디자인을 위해 여러 모델을 조율하는 작업을 다루고 있습니다. 그러나 이러한 연구들은 게임의 모든 구성 요소를 생성하지는 않습니다. 반면, 우리의 연구에서는 게임의 모든 메커니즘, 캐릭터, 환경, 내러티브, 그래픽이 생성 모델에 의해 완전히 생산됩니다. 이는 최근 연구인 Genie(Bruce 등, 2024)와 GameNGen(Valevski 등, 2024)와 유사하지만, 주로 모호한 메커니즘의 플랫폼 게임을 생성하거나 기존 게임의 행동을 재생성하는 이러한 연구들과 달리, 우리의 연구는 LLM 기반 게임 엔진을 통해 안정적인 게임 메커니즘을 가진 열린 내러티브 경험을 제안합니다.

**Unbounded**는 캐릭터 시뮬레이션과 열린 상호작용을 중심으로 한 게임 플레이 루프를 제공합니다(그림 2). 플레이어는 캐릭터를 게임에 삽입하고 그들의 외모와 성격을 정의할 수 있습니다. 게임은 이 캐릭터들이 환경을 탐험하고, 객체와 상호작용하며, 대화를 나눌 수 있는 세계를 생성합니다. 게임은 플레이어의 행동과 선택에 따라 새로운 시나리오, 이야기, 도전 과제를 생성하며, 개인화되고 무한한 게임 경험을 제공합니다. 몇 가지 생성적 게임 예시는 그림 3에 나와 있습니다.

구체적으로, **Unbounded**는 다음과 같은 기능을 가지고 있습니다: (1) **캐릭터 개인화**: 플레이어는 자신의 캐릭터를 게임에 삽입하고, 외모와 성격을 정의할 수 있습니다. (2) **게임 환경 생성**: Unbounded는 캐릭터가 탐험하고 상호작용할 수 있는 지속적인 세계를 생성합니다. (3) **열린 상호작용**: 플레이어는 자연어 지시를 사용하여 캐릭터와 상호작용할 수 있으며, 상호작용을 제한하는 사전 정의된 규칙이 없습니다. (4) **실시간 생성**: 우리는 게임 속도에 특별히 주의를 기울여 단순 구현보다 5-10배 속도를 개선하여, 각 새로운 장면을 약 1초의 지연 시간으로 제공합니다.

우리의 접근 방식은 LLM과 비전 생성 도메인 모두에서 기술적 혁신을 도입합니다. 언어 측면에서는 일관된 게임 메커니즘을 유지하고, 일관된 서사를 생성하며, 실시간으로 문맥에 맞는 캐릭터 응답을 생성할 수 있는 LLM 기반 게임 엔진을 개발했습니다. 우리 모델은 자동으로 생성된 두 개의 협력적인 강력한 LLM 에이전트를 통해 인간의 주석 없이도 학습된 특수화된 디스틸드 모델로, 플레이어의 입력과 게임 상태에 맞춰 동적으로 게임 규칙과 시나리오를 생성합니다. 시각적 생성 측면에서는 새로운 지역 IP-Adapter를 도입하여 여러 이미지에서 시각적 일관성을 유지하면서 캐릭터와 환경을 일관되게 생성할 수 있습니다. 특히, 우리 지역 IP-Adapter는 교차 주의 계층에서 나온 주의 출력에서 얻은 동적 마스크로 게임 환경과 캐릭터 외모를 인코딩하여 이미지 생성을 조건화합니다. 이는 환경과 캐릭터 간의 간섭을 완화하여 두 요소가 신뢰성 있게 장면에 나타나도록 합니다. 이러한 접근 방식은 게임 상태와 플레이어 행동을 반영하는 실시간 이미지 생성을 가능하게 합니다.

이 연구의 기여는 개념적이고 기술적인 측면에 있습니다. 우리는 생성적 무한 게임의 개념을 도입하여 상호작용형 엔터테인먼트의 미래에 미칠 가능성과 영향력을 입증합니다. 우리는 게임 로직과 콘텐츠가 생성 모델에 포함된 새로운 게임 디자인 패러다임을 제시합니다. 우리의 주요 기술적 기여는 게임 로직 및 내러티브 생성을 위한 특수화된 디스틸드 LLM과 일관된 시각적 생성을 위한 지역 IP-Adapter입니다. 우리는 지역 IP-Adapter의 효과를 정량적 및 정성적 평가를 통해 입증하였으며, 캐릭터 및 환경 일관성에서 최첨단 기술을 능가했습니다. 또한, 우리는 우리의 디스틸드 LLM이 매우 큰 LLM과 비교해도 상호작용 속도를 유지하며 성능이 유사함을 보여줍니다. 이러한 발전은 **Unbounded**의 창조를 가능하게 했으며, AI 기반 상호작용 경험 분야에서의 미래 연구 및 개발을 위한 기초를 마련합니다.

![](/assets/images/posts/297/img_1.png)

**그림 2: Unbounded의 예시.** 초기 사용자 입력을 바탕으로, Unbounded는 게임 시뮬레이션 환경을 설정하고 해당 환경에서 캐릭터의 행동을 생성합니다. 사용자는 자연어 지시를 통해 캐릭터와 상호작용하며, 무한한 선택지를 탐험하면서 게임을 즐길 수 있습니다.

**2. 관련 연구**

**제어 가능한 텍스트-이미지 생성.**  
제어 가능한 텍스트-이미지 생성은 확산 모델 응용에서 주요 연구 방향이 되어, 생성 과정을 다양한 방식으로 안내할 수 있게 합니다. 예를 들어, ControlNet(Zhang 등, 2023)은 깊이 맵, 포즈, 가장자리, 분할 맵과 같은 제어 신호를 사용하여 이미지 생성을 안내하는 조건화 메커니즘을 도입했습니다. 다른 연구들은 경계 상자를 사용하여 생성된 이미지 내에서 객체 배치를 제어하는 레이아웃 제어에 초점을 맞추고 있습니다(Li 등, 2023; Shin 등, 2022). 이러한 제어 신호를 넘어 일관된 캐릭터(Ruiz 등, 2023; Gal 등, 2022; Kumari 등, 2023; Avrahami 등, 2024) 또는 일관된 얼굴 정체성(Li 등, 2024b; Wang 등, 2024b; Yan 등, 2023; Ruiz 등, 2024)을 여러 세대에 걸쳐 생성하는 개인화도 주요 연구 영역 중 하나입니다. 그러나 대부분의 기존 접근 방식은 캐릭터와 환경을 별도로 조건화하는 지원이 부족하며, 종종 캐릭터 생성을 위해 사전 정의된 마스크가 필요하고(Chen 등, 2024; Lugmayr 등, 2022; Yang 등, 2023), 환경은 입력 이미지와 동일하게 유지됩니다. 이러한 한계로 인해 캐릭터를 다양한 환경에 일관되게 통합하고 입력 프롬프트와 일치시키는 데 어려움이 있습니다. IP-Adapter(Ye 등, 2023)는 환경 및 캐릭터 이미지를 조건으로 생성하는 작업을 처리합니다. 그러나 IP-Adapter는 조건을 과도하게 재구성하는 경향이 있어, 서로 간섭을 일으키는 문제가 있습니다. 본 논문에서는 IP-Adapter를 기반으로 하여 블록 드롭을 사용하는 향상된 지역 IP-Adapter를 제안하고, 캐릭터와 환경 생성을 분리하여 일관성을 개선합니다.

**이미지 생성에서의 대형 언어 모델.**  
대형 언어 모델은 강력한 맥락 학습 능력을 입증했으며(Brown, 2020), 이를 통해 사람의 지시와 맥락 예시를 기반으로 다양한 맞춤형 작업을 해결할 수 있습니다. 이미지 생성 분야에서 대형 언어 모델은 프롬프트를 기반으로 이미지 레이아웃을 생성하는 작업(Cheng 등, 2024a; b), 상호작용형 다중 회차 이미지 생성(Zeqiang 등, 2023; Huang 등, 2024; Gong 등, 2023; Wang 등, 2023b), 그리고 텍스트와 이미지가 혼합된 생성기(Team, 2024; Zhou 등, 2024a) 등 다양한 작업에 활용되었습니다. 이러한 응용과는 달리, 우리의 연구는 특수화된 대형 언어 모델을 증류하여 게임 엔진으로 사용하며, 게임 메커니즘, 서사 및 캐릭터 상호작용을 생성하는 역할을 담당하는 데 초점을 맞추고 있습니다.

**게임 생성.**  
절차적 콘텐츠 생성(Procedural Content Generation, PCG) 분야에서는 동적 게임 콘텐츠를 생성하기 위한 다양한 접근 방식이 탐구되었습니다(Summerville 등, 2018). 초기 연구들은 개념 맵(Treanor 등, 2012), 마르코프 체인(Snodgrass & Ontañón, 2014), 베이즈 네트워크(Guzdial & Riedl, 2016), LSTM(Summerville & Mateas, 2016)을 사용하여 상호작용하는 게임 환경을 시뮬레이션했습니다. 최근 연구에서는 게임 레벨이나 동적 환경을 생성하기 위해 생성적 적대 신경망(GAN)을 사용하는 것(Volz 등, 2018; Kumaran 등, 2019; Schubert 등, 2021; Kim 등, 2020), 게임 생성에 확산 모델을 활용하는 것(Zhou 등, 2024b), 게임 환경이나 메커니즘을 설계하고 생성하기 위해 LLM을 사용하는 것(Sudhakaran 등, 2024; Todd 등, 2023; Nasir & Togelius, 2023; Hu 등, 2024; Zala 등, 2024; Anjum 등, 2024; Chung & Kreminski, 2024; Chung 등, 2024), 그리고 1001 Nights(Sun 등, 2023)에서 장면 생성을 위해 확산 모델을 사용하며 아이템과 내러티브를 생성하기 위해 LLM을 사용하는 것과 같은 연구가 발전했습니다. 이 연구들의 주요 특징 중 하나는 AI가 게임 디자인을 돕거나 환경이나 상호작용과 같은 게임의 하나의 구성 요소를 생성하는 데 주로 사용된다는 점입니다. 우리의 연구는 생성 모델을 사용하여 게임의 모든 행동, 그래픽, 캐릭터, 환경, 내러티브를 완전히 생성하는 것을 목표로 합니다.

Bruce 등(2024)은 이전 게임 프레임과 사용자 행동을 조건으로 하는 비디오 확산 모델을 사용하여 완전히 새로운 상호작용형 게임을 합성하는 연구를 진행했습니다. 이 연구는 초기 단계에서 인상적인 결과를 달성했으나, 생성되는 게임의 범위가 주로 2D 플랫폼 게임에 한정된다는 한계가 있습니다. 이는 무한 게임이 아니라는 점에서 우리의 연구와 다릅니다. 우리는 픽셀만을 모델링하여 설득력 있는 무한 게임을 생성하는 것은 어려운 문제라고 믿으며, 대신 언어 모델을 사용하여 모든 개방형 게임 메커니즘을 생성하는 방식을 선택했습니다. Valevski 등(2024)은 확산 모델을 사용해 Doom 게임 엔진을 실행하도록 학습시키고, 픽셀만을 모델링하여 게임 메커니즘을 일관되게 생성하는 성과를 거두었습니다. 하지만 이 연구는 현재 이미 존재하는 단일 유한 게임에 확산 모델을 맞추는 데 그치고 있습니다.

게임 콘텐츠 생성 외에도 AI가 게임에서 다양한 역할(예: 경쟁자, 디자이너, 팀원)을 맡게 하는 연구가 이루어졌습니다(Zhu 등, 2021; Gallotta 등, 2024; Pell, 1992; Agarwal 등, 2023). Cook(2022)은 8x8 크기의 그리드에서 진행되는 게임의 자동화된 게임 디자인을 위해 지속적인 창의성을 가진 시스템을 구축했습니다. 시각적 게임 환경 생성 외에도 조건부 언어 생성 모델을 사용해 지식 그래프를 완성하는 내러티브 텍스트 게임을 만드는 연구(Ammanabrolu 등, 2020)나 LLM 및 기타 AI 도구를 사용하여 게임을 생성하거나(Li 등, 2024a; Latitude Inc., 2023; Wang 등, 2023a), 게임 내에서 다양한 역할을 수행하는 연구(Zhu 등, 2023; Kreminski 등, 2020; Cui 등, 2023; Zhou 등, 2023; Dambekodi 등, 2020)도 있습니다.

우리의 연구는 다음과 같은 점에서 이러한 연구들과 차별화됩니다: (1) 생성 모델을 사용하여 모든 게임 메커니즘, 그래픽, 캐릭터, 환경, 내러티브를 생성합니다. (2) 사용자가 커스텀 캐릭터를 삽입하고 게임 세계와 초기 스토리 아크를 개인화할 수 있는 생성적 게임의 개인화를 도입합니다. (3) 비전 및 언어 도메인에서의 혁신을 통해 상호작용 가능한 실시간 갱신 속도를 달성합니다.

![](/assets/images/posts/297/img_2.png)

**그림 3: Unbounded의 생성적 게임 예시.** 사용자는 게임에 커스텀 캐릭터를 삽입하고, 자연어 지시를 통해 캐릭터와 상호작용하며, 캐릭터를 다양한 환경으로 데려가서 게임 메커니즘에 따라 건강한 상태를 유지하도록 상호작용할 수 있습니다.

**3. 방법**

우리는 텍스트-이미지 생성 모델과 대형 언어 모델을 기반으로 한 상호작용형 생성 무한 게임인 **Unbounded**를 소개합니다. Unbounded는 다음을 제공합니다: (1) **커스텀 캐릭터 개인화**: 사용자가 외모와 성격을 커스터마이징하여 독특한 캐릭터를 만듭니다. (2) **동적 세계 생성**: 시스템은 탐험을 위한 지속적이고 상호작용 가능한 게임 세계를 생성합니다. (3) **개방형 상호작용 및 게임 플레이**: 플레이어는 자연어로 캐릭터와 상호작용하며, 게임은 플레이어의 행동에 따라 새로운 시나리오와 이야기를 동적으로 생성합니다. (4) **인터랙티브 속도의 생성**: 게임은 거의 실시간 상호작용이 가능하며, 약 1초에 가까운 갱신 속도를 달성합니다. 우리는 이 기능들을 가능하게 하는 방법들을 이 섹션에서 자세히 설명합니다.

**3.1 캐릭터 일관성을 위한 잠재 일관성 모델의 개인화**  
Unbounded의 핵심 기능 중 하나는 실시간 상호작용을 제공하는 완전한 생성 모델 기반 게임입니다. 이는 **잠재 일관성 모델(LCM)**(Luo 등, 2023)을 사용하여 단 두 번의 확산 단계만으로도 고해상도 이미지를 생성할 수 있게 함으로써 가능합니다. LCM을 사용함으로써 Unbounded는 거의 1초에 가까운 갱신 속도로 실시간 텍스트-이미지(T2I) 생성을 실현하여 상호작용형 게임 경험을 제공합니다.

게임에서 사용자 커스텀 캐릭터를 지원하기 위해 우리는 **DreamBooth**(Ruiz 등, 2023)를 T2I 모델에 통합합니다. 캐릭터 이미지 세트를 기반으로 우리는 **LoRA 모듈**(Hu 등, 2021)을 사용하여 확산 모델을 미세 조정합니다. 미세 조정 과정에서 고유 식별자인 "[V]"를 추가하여, 모델 내에서 약한 사전 지식을 가진 주제를 나타냅니다. DreamBooth 개인화는 기본 확산 모델에서 수행되며, 주제 특화된 LoRA를 몇 단계의 확산을 위해 학습된 LCM LoRA와 결합합니다. 이 단순한 산술적 LoRA 병합은 추론 속도와 주제 보존을 모두 유지하는 데 놀랍게도 잘 작동합니다. 개인화를 위한 다른 대안들도 존재하며, 많은 경우 설정 시간이 필요 없지만, 이들은 캐릭터의 특징을 강하게 보존하는 데 종종 실패합니다. 이는 이러한 유형의 게임에서 만족스러운 경험을 제공하기 위해 매우 중요한 요소입니다.

![](/assets/images/posts/297/img_3.png)

**그림 4: (a) 전체 이미지 생성 방법.** 우리는 LCM LoRA를 사용해 실시간 이미지 생성을 달성하고, DreamBooth LoRA로 캐릭터의 일관성을 유지하며, 환경과 캐릭터의 일관성을 개선하기 위해 지역 IP-Adapter(그림 (c)에서 보여짐)를 도입했습니다. (b) 우리가 제안한 동적 마스크 생성 방식은 환경과 캐릭터의 조건화를 분리하여 두 요소 간의 간섭을 방지합니다.

**3.2 환경 일관성을 위한 블록 드롭을 사용한 지역 IP-Adapter**  
Unbounded의 또 다른 핵심 기능은 사전 정의된 환경에서 사용자의 지시에 따라 다양한 행동을 수행하는 캐릭터를 생성하는 것입니다. 따라서 캐릭터와 환경의 일관성을 유지하는 것이 필수적입니다. 캐릭터 일관성은 3.1절에서 설명한 대로 처리되지만, 추가로 두 가지 도전 과제가 발생합니다: 다양한 세대에 걸쳐 환경 일관성을 보장하고, 캐릭터를 환경 내에 정확히 배치하면서 텍스트 프롬프트와의 일치성을 잃지 않는 것입니다. 기존 방법은 모든 요구사항을 상호작용 속도에서 일관되게 수행하는 데 실패하는 경우가 많았습니다. 주요 기술적 기여 중 하나로, 우리는 텍스트 프롬프트를 따라 사전 정의된 환경에 캐릭터를 일관되게 삽입하기 위한 새로운 **지역 IP-Adapter**를 제안합니다.

**3.2.1 지역 IP-Adapter**  
우리는 주제와 환경 모두에 대해 이중 조건화를 가능하게 하는 개선된 IP-Adapter 버전(Ye 등, 2023)을 제안합니다. 이를 통해 사용자 지정 환경에서 사전 정의된 캐릭터를 생성할 수 있습니다. 기존 IP-Adapter가 단일 이미지 조건화에 집중한 것과 달리, 우리의 접근법은 이중 조건화와 동적 지역 주입 메커니즘을 도입하여 생성된 이미지에서 두 개념을 동시에 표현할 수 있게 합니다.

예를 들어보겠습니다. 그림 4에서, "사막 하늘 아래, [V] 마녀가 선인장을 유도하여 생기 넘치고 빛나는 꽃을 피우게 한다"라는 텍스트 프롬프트와 사막 환경 이미지를 주었을 때, 모델은 캐릭터가 선인장 옆에 서 있으며 사막 환경 안에 있어야 한다는 것을 알아야 합니다. 이는 모델이 (1) 환경을 올바르게 유지하고 (2) 캐릭터를 유지하며 (3) 프롬프트를 따를 수 있어야 함을 의미합니다. IP-Adapter를 사용하여 환경을 인코딩하면 (2)와 (3)에 큰 손상을 입히게 됩니다(그림 8 참조). 우리의 지역 IP-Adapter는 두 요소를 생성하기 위한 새로운 주의 분리 메커니즘을 구현하여 이 문제를 해결합니다. 구체적으로, 우리는 각 레이어의 숨겨진 상태와 캐릭터 텍스트 임베딩 간의 교차 주의를 활용하는 동적 마스크 기반 접근법을 도입합니다. 그림 4에 나와 있듯이, 우리의 접근법은 어댑터를 환경과 캐릭터에 해당하는 영역에 각각 적용하여 환경 조건화가 캐릭터의 외형을 방해하지 않도록 하며 그 반대의 경우도 마찬가지입니다.

![](/assets/images/posts/297/img_4.png)

-----

<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
mermaid.initialize({
startOnLoad: true,
theme: 'default'
});
</script>
<div class="mermaid">
flowchart TD
subgraph inputs["입력"]
Ot["텍스트 교차 주의 출력\n(Ot)"]
Kc["캐릭터 텍스트 임베딩\n(Kc)"]
end
subgraph attention["주의력 계산"]
Wq["Wq\n(쿼리 가중치)"]
Wk["Wk\n(키 가중치)"]
calc["주의력 점수 계산\nAc = Wq·Ot \* Wk·Kc^T"]
end
subgraph mask["동적 마스크 생성"]
rank["주의력 점수 순위화"]
threshold["임계값 설정\n(상위 r%)"]
mask\_gen["마스크 생성 (Mc)\n1: Ac ≤ 임계값\n0: Ac > 임계값"]
end
subgraph output["최종 출력 계산"]
Oe["환경 IP-Adapter\n출력 (Oe)"]
Oc["캐릭터 IP-Adapter\n출력 (Oc)"]
final["최종 출력 계산\nO = Ot + αe·Mc·Oe + αc·(1-Mc)·Oc"]
end
Ot --> Wq
Kc --> Wk
Wq --> calc
Wk --> calc
calc --> rank
rank --> threshold
threshold --> mask\_gen
mask\_gen --> final
Oe --> final
Oc --> final
style inputs fill:#f0f0f0
style attention fill:#e1f5fe
style mask fill:#e8f5e9
style output fill:#fff3e0
</div>

-----

![](/assets/images/posts/297/img_5.png)

**그림 5: 서로 다른 블록의 교차 주의 레이어에서 캐릭터 임베딩과 숨겨진 상태 간의 주의 맵.** 우리가 사용하는 캐릭터 임베딩은 "[V] 마녀"입니다.

**3.2.2 환경 조건화에서 블록별 드롭**  
우리의 지역 IP-Adapter에서는 캐릭터 텍스트와 숨겨진 상태 간의 교차 주의에서 생성된 동적 마스크를 사용합니다. 이 마스크의 품질은 캐릭터와 환경 생성을 분리하는 데 핵심적인 역할을 합니다. 그림 5는 다운 샘플 블록의 교차 주의 레이어에서 캐릭터 임베딩과 숨겨진 상태 간의 주의 맵을 보여줍니다. 우리는 이 주의가 캐릭터에 집중하지 않고 전체 이미지에 퍼져 있음을 관찰했습니다. 이는 확산 모델이 이러한 레이어에서 캐릭터와 환경 생성을 분리하지 않으며, 대신 텍스트 프롬프트를 기반으로 전체 이미지 구조에 집중하고 있음을 강하게 시사합니다. 이는 Wang 등(2024a)의 발견과도 일치하는데, 다운 샘플 블록은 공간적 레이아웃을 더 많이 포착하고, 업 샘플 블록은 스타일을 포착한다는 것입니다. 우리는 다운 샘플 블록에서 지역 IP-Adapter를 사용하지 않고, 미드 및 업 샘플 블록에서만 이를 사용합니다. 이렇게 하면 캐릭터와 환경 간의 공간적 레이아웃 생성이 더 잘 이루어질 수 있습니다. 추가적으로, 업 샘플 블록에서 동적 지역 IP-Adapter를 추가함으로써 생성된 배경이 조건화된 환경과 더 강하게 일치하도록 하고, 캐릭터의 외형과 자세와 같은 세부 사항을 보존하면서 관련된 의미 정보를 추출할 수 있음을 확인했습니다.

**3.3 개방형 상호작용과 통합된 게임 메커니즘을 가진 언어 모델 게임 엔진**  
**Unbounded**는 장면 텍스트 설명을 기반으로 생성된 이미지를 통해 사전 정의된 환경에서 캐릭터의 행동을 시뮬레이션하며, 캐릭터의 상태를 모니터링하고 사용자에게 자연어로 캐릭터 및 게임 환경과의 상호작용을 제공합니다. 예를 들어, 사용자는 캐릭터를 다양한 환경으로 데려가거나 캐릭터와 상호작용할 수 있습니다(예: "캐릭터의 머리를 쓰다듬는다") 또는 본질적으로 개방형 행동을 취할 수 있습니다(예: "캐릭터를 쓰다듬은 뒤 우주 정거장에서 로켓 타기에 데려간다"). 게임은 궁극적으로 언어 모델을 기반으로 구축되었기 때문에, 이러한 광범위한 기능들은 몇 가지 도전 과제를 제시합니다: (1) **환경 바인딩**: 모델은 자연어 지시에 따라 캐릭터를 올바른 환경에 배치해야 합니다. (2) **일관된 스토리 생성**: 모델은 사용자 지정 캐릭터 특성에 맞춰 일관된 서술 설명과 캐릭터 응답을 생성해야 합니다. (3) **게임 메커니즘 생성**: 모델은 캐릭터의 상태(예: 배고픔, 에너지, 재미, 위생)를 모니터링하고 사용자 상호작용 및 스토리 이벤트에 따라 상태를 업데이트해야 합니다. (4) **프롬프트 재작성**: 모델은 확산 모델을 위해 내러티브를 재작성해야 합니다(예: 캐릭터에 특별 토큰 "[V]"를 추가하고, 더 나은 환경 일관성을 위해 환경 설명을 사전 생성된 환경에 맞춰야 함).

놀랍게도, 매우 큰 언어 모델(예: GPT-4, GPT-4o)이 자세한 지시와 맥락 학습(Brown, 2020)을 사용하여 이러한 기능을 나타낼 수 있다는 것을 확인했습니다. 하지만 이러한 큰 모델을 게임 엔진으로 사용하는 것은 큰 지연 시간(예: 7B 모델이 한 번 응답하는 데 5초 소요) 때문에 직접적으로 실현 가능하지 않습니다. 이에 따라 우리는 매우 큰 모델에서 이러한 기능을 증류하여 실시간 상호작용을 지원하는 **Gemma-2B**(Team 등, 2024)를 기반으로 한 더 작은 모델에 넣는 방법을 제안합니다. 이 섹션에서는 두 가지 주요 기술적 기여를 제안합니다: (1) 각각 월드 모델링과 사용자 상호작용을 제어하는 두 개의 매우 큰 언어 모델을 사용한 캐릭터 생활 시뮬레이션 게임 디자인 (2) 이 지식을 하나의 작은 언어 모델로 증류하여 상호작용 가능한 속도를 달성할 수 있는 프레임워크.

**3.3.1 다중 LLM 협업을 통한 캐릭터 생활 시뮬레이션**  
우리는 두 개의 LLM 에이전트를 사용하여 캐릭터 생활 시뮬레이션 게임을 구축합니다. 첫 번째 에이전트는 세계 시뮬레이션 모델로 작동하여, 게임 환경을 설정하고 내러티브 및 이미지 설명을 생성하며, 캐릭터의 상태를 추적하고 캐릭터의 행동을 시뮬레이션하는 역할을 담당합니다. 두 번째 에이전트는 사용자 모델로 기능하며, 세계 시뮬레이션 모델과의 상호작용을 통해 플레이어의 역할을 시뮬레이션합니다. 이 에이전트는 세 가지 유형의 상호작용을 제공합니다: 현재 환경 내에서 이야기를 계속 진행하기, 캐릭터를 다른 환경으로 이동시키기, 또는 캐릭터와 상호작용하여 건강한 상태를 유지하도록 돕기. 각 상호작용 범주에서 사용자는 캐릭터의 성격 세부 정보를 제공하거나 캐릭터 행동을 안내하여 시뮬레이터의 내러티브 생성에 영향을 줄 수 있습니다. 이러한 세계 시뮬레이션 LLM과 사용자 LLM 간의 상호작용을 통해 동적인 캐릭터 생활 시뮬레이션 게임이 가능해지며, 사실상 무한한 상호작용 가능성과 서사 경로를 제공합니다.

![](/assets/images/posts/297/img_6.png)

**그림 6: LLM 증류를 위한 사용자-시뮬레이션 데이터 수집 과정 개요.**  
(a) 먼저 다양한 주제와 캐릭터 데이터를 수집하고, ROUGE-L을 사용하여 다양성을 필터링합니다. (b) 세계 LLM과 사용자 LLM이 다중 회차 교환을 통해 사용자-시뮬레이션 데이터를 생성합니다.

**3.3.2 소형 LLM 증류를 위한 프레임워크**  
우리는 여러 강력한 LLM이 생성한 합성 데이터를 사용하여 더 큰 LLM의 기능을 더 작고 효율적인 모델에 증류하는 프레임워크를 제안합니다. 이 프레임워크는 두 가지 단계로 구성됩니다: (1) 자동화된 데이터 수집(그림 6)과 (2) 소형 모델 증류.

**자동화된 데이터 수집**  
우리의 목표는 다양한 캐릭터 특성을 이해하고 다양한 주제를 아우르는 게임을 생성할 수 있는 범용 캐릭터 생활 시뮬레이터를 구축하는 것입니다. 이를 위해 첫 번째 단계는 다양한 주제와 캐릭터에 대한 데이터셋을 수집하는 것입니다. 우리는 대형 LLM에 다양한 주제와 해당 주요 캐릭터 쌍을 생성하도록 프롬프트를 줍니다. 데이터의 다양성을 보장하기 위해, 기존 데이터와의 ROUGE-L 유사도가 0.7 이하인 생성된 쌍만을 유지합니다(Wang 등, 2022 참조). 이는 LLM의 지시 이행 능력을 향상시키기 위해 다양한 데이터가 중요하다는 것을 입증한 연구입니다. 이 과정을 통해 5,000개의 고유한 주제-캐릭터 쌍을 얻으며, 이는 사용자-시뮬레이터 상호작용 데이터의 기반이 됩니다.

두 번째 단계에서는 세계 시뮬레이션 LLM과 사용자 LLM 간의 다중 회차 상호작용 데이터를 수집합니다. 이 과정은 세계 시뮬레이션 LLM이 데이터셋에서 무작위로 추출된 주제-캐릭터 쌍을 기반으로 게임 환경을 설정하고 캐릭터 행동을 시작하는 것에서 시작됩니다. 이후 사용자 LLM은 상호작용 입력을 제공합니다. 그러면 세계 시뮬레이션 LLM이 갱신된 캐릭터 행동, 상태, 응답을 생성합니다. 이 반복 과정은 각 세션마다 5회의 상호작용 라운드를 진행하며, 총 5,000개의 사용자-시뮬레이터 상호작용 예제를 생성합니다. 모든 프롬프트 템플릿은 부록에 있습니다.

**증류**  
상호작용 데이터를 수집한 후, 우리는 5,000개의 합성 사용자-시뮬레이터 상호작용 샘플을 사용하여 더 작은 Gemma-2B 모델을 미세 조정합니다. 지도 학습 미세 조정 동안, 우리는 사용자 입력 데이터에 대한 손실을 마스킹하여, 다중 회차 상호작용 기록과 현재 사용자 입력을 기반으로 세계 시뮬레이션 모델의 행동을 학습하는 데 최적화를 집중합니다. 이러한 접근법을 통해 Gemma-2B는 게임 엔진으로서 더 큰 LLM의 기능을 복제하면서 실시간 상호작용을 지원할 수 있게 됩니다. 증류된 Gemma-2B는 사용자 입력을 효과적으로 따르고 무한한 상호작용을 지원하면서 GPT-4o와 유사한 성능을 보입니다.

**4 실험 설정**  
**4.1 평가 벤치마크**

**이미지 생성 평가**  
우리의 이미지 생성 접근법을 평가하기 위해, 우리는 GPT4o(OpenAI, 2023)를 사용하여 5,000개의 (캐릭터 이미지, 환경 설명, 텍스트 프롬프트) 트리플릿으로 구성된 평가 데이터셋을 수집했습니다. 이 데이터셋은 5개의 캐릭터(강아지, 고양이, 판다, 마녀, 마법사), 100개의 다양한 환경, 그리고 1,000개의 텍스트 프롬프트(환경당 10개)를 포함합니다. 우리는 이미지 생성 성능을 환경 일관성, 캐릭터 일관성, 텍스트 프롬프트와의 의미적 정렬이라는 세 가지 기준에 따라 평가합니다. 이미지 간의 유사도를 측정하기 위해, 우리는 CLIP-I(Radford 등, 2021), DINO(Caron 등, 2021), DreamSim(Fu 등, 2023)을 사용합니다. 환경 참조 이미지와 생성된 이미지 간의 유사도를 각각 CLIP-IE, DINOE, DreamSimE로 나타내며, 캐릭터 참조 이미지와 생성된 이미지 간의 유사도를 CLIP-IC, DINOC, DreamSimC로 나타냅니다. 추가로, 우리는 CLIP-T(Radford 등, 2021)를 사용하여 텍스트 프롬프트와의 의미적 정렬을 평가합니다. **Unbounded**가 캐릭터 생활 시뮬레이션 게임이기 때문에 이미지 내에 캐릭터가 존재하는지 여부를 보장하는 것이 중요합니다. 따라서, 우리는 생성된 이미지에서 캐릭터의 존재를 탐지하기 위해 Grounding-DINO(Liu 등, 2023)을 추가로 활용합니다. 생성된 이미지에 캐릭터가 없을 경우, 유사도 점수를 0으로 설정하고 거리 점수를 1로 설정합니다.

**LLM 생성 평가**  
우리는 추가로 100개의 사용자-시뮬레이터 상호작용 샘플을 포함하는 평가 데이터셋을 섹션 3.3의 파이프라인을 사용하여 수집했습니다. 각 사용자-시뮬레이터 상호작용 샘플은 사용자와 세계 모델 간의 5회의 상호작용을 포함합니다. 우리는 평가자로서 GPT-4(OpenAI, 2023)를 사용하여 두 모델(기준 모델 vs. 우리의 모델)의 응답을 전체 점수 및 네 가지 측면에서 평가합니다: 캐릭터 상태 업데이트의 정확성, 환경 관련성, 이야기 일관성, 사용자 입력 지시 이행. 점수는 0에서 10까지의 범위로 매겨집니다.

**4.2 구현 세부 사항**  
우리의 이미지 생성기는 **SDXL**(Podell 등, 2023)을 기반으로 구축되었습니다. 우리는 DreamBooth **LoRA**를 랭크 16, 배치 크기 1, 학습률 1e-4로 설정하여 **A100** 하나에서 500 스텝 동안 학습했으며, 약 30분이 소요되었습니다. 캐릭터 앞에 추가하는 특별 토큰은 "sks"입니다. 추론 시, 우리는 **LCM-LoRA**와 **DreamBooth LoRA**를 각각 스케일 1.0으로 병합합니다. 환경 인코딩을 위해 **IP-Adapter-plus-sdxl-vit-h**를 사용하고, 캐릭터 인코딩을 위해 **IP-Adapter-plus-face-sdxl-vit-h**를 사용합니다. 동적 마스크 비율 r%은 60%로 설정됩니다.

우리의 **LLM**은 **Gemma-2B**(Team 등, 2024)를 기반으로 합니다. 우리는 GPT-4o에서 수집한 5,000개의 사용자-시뮬레이터 상호작용 샘플을 사용하여 LLM을 증류합니다. 우리는 **LLM**을 배치 크기 8, 4개의 **A100**에 분산하여 6,500 스텝 동안 학습하며, 학습률은 1e-4입니다. 학습률 스케줄러는 **cosine annealing**(Loshchilov & Hutter, 2016)로 설정되었으며, **warmup** 스텝 비율은 0.03입니다. 평가 시, 우리는 샘플링을 사용하여 LLM으로 응답을 생성합니다. 샘플링 하이퍼파라미터는 기본값으로 설정됩니다.

**5 결과 및 분석**  
**표 1: Unbounded와 다른 방법들의 환경 일관성 및 캐릭터 일관성 유지 비교.**  
**Unbounded**는 일관성 유지에서 가장 우수한 성능을 달성했으며, 텍스트 프롬프트와의 의미적 정렬에서도 유사한 성능을 유지했습니다. 최고 점수는 **굵은 글씨**로 표시됩니다.

![](/assets/images/posts/297/img_7.png)

![](/assets/images/posts/297/img_8.png)

**그림 7: 텍스트 프롬프트를 기반으로 환경과 캐릭터가 일관된 이미지를 생성하는 다른 접근 방식들과의 비교.**  
우리는 우리의 방법이 관련 연구들보다 훨씬 뛰어난 성능을 보인다는 것을 관찰했습니다.

**표 2: 일관된 이미지 생성 접근법에서 동적 지역 IP-Adapter와 블록 드롭의 효과성에 대한 분석.**

![](/assets/images/posts/297/img_9.png)

**5.1 환경 일관성 및 캐릭터 일관성을 유지하기 위한 다양한 접근 방식과의 비교**

**정량적 결과**  
우리는 환경 일관성과 캐릭터 일관성을 유지하는 데 있어 블록 드롭을 포함한 우리의 지역 IP-Adapter와 이전 접근 방식을 비교합니다. 모든 접근 방식에 대해 캐릭터 LoRA와 LCM LoRA를 모델에 병합하여 빠른 추론을 지원하고 캐릭터 일관성을 개선하며 공정한 비교를 제공합니다. 표 1에서 보여지듯이, 우리의 접근 방식은 환경 일관성과 캐릭터 일관성에서 이전 접근 방식을 일관되게 능가하며, 의미적 정렬을 유지하는 데 있어서도 유사한 성능을 보입니다. 구체적으로, 우리의 접근 방식은 **StoryDiffusion**(Zhou 등, 2024c)을 캐릭터 일관성에서 **CLIP-IC**에서 0.047, **DreamSimC**에서 0.057로 크게 앞서고, 환경 일관성에서는 **CLIP-IE**에서 0.035, **DINOE**에서 0.065, **DreamSimE**에서 0.058로 능가하여 우리의 접근 방식의 효과를 입증합니다. 또한, 우리의 접근 방식은 의미적 정렬을 유지하는 데 있어서도 유사한 성능을 달성하여 강력한 텍스트 따르기 능력을 시사합니다.

**정성적 결과**  
그림 7에서 다른 접근 방식과의 정성적 비교를 제시합니다. 블록 드롭을 사용한 우리의 지역 IP-Adapter는 높은 캐릭터 일관성을 유지한 이미지를 일관되게 생성하며, 다른 방법들은 캐릭터를 포함하지 못하거나 일관되지 않은 외형의 캐릭터를 생성할 수 있습니다(예시 1 & 2 참조). 또한, 우리의 접근 방식은 환경 일관성과 캐릭터 일관성을 잘 균형 잡고 있는 반면, 다른 접근 방식은 조건 환경과 다른 환경을 생성할 수 있습니다(예: **StoryDiffusion**의 예시 1 & 3).

![](/assets/images/posts/297/img_10.png)

**그림 8: 우리의 지역 IP-Adapter 접근 방식과 기준 접근 방식 간의 비교.**

**5.2 블록 드롭을 포함한 동적 지역 IP-Adapter의 효과**

**정량적 결과**  
우리는 블록 드롭을 포함한 지역 IP-Adapter가 텍스트 프롬프트에 따라 캐릭터를 환경에 배치하는 데 필수적이며, 환경과 캐릭터의 일관성을 유지하는 데 효과적임을 절제 연구(아블레이션 스터디)를 통해 입증합니다. 표 2에서 보여지듯이, 블록 드롭을 추가함으로써 다중 IP-Adapter(No. 2 vs. No. 1)와 비교했을 때 환경 및 캐릭터 일관성이 향상되었으며, **CLIP-IE**에서 0.291, **CLIP-IC**에서 0.264가 증가하고, 텍스트 프롬프트와 생성된 이미지 간의 정렬도 개선되었습니다. 또한, 우리의 지역 IP-Adapter는 환경 일관성을 유지하면서도 캐릭터 일관성과 텍스트 정렬을 향상시킵니다(No. 3 vs. No. 2). 우리는 환경 IP-Adapter의 스케일 효과도 탐구했으며, 더 작은 스케일(예: 0.5)을 사용할 경우 일반적으로 캐릭터 일관성이 향상되지만, 환경 일관성은 약간 손상된다는 것을 발견했습니다(No. 6 vs. No. 3).

**정성적 결과**  
그림 8에서 보여지듯이, 환경을 조건화하는 데 IP-Adapter를 사용하면 환경 재구성에 효과적이지만, 캐릭터 일관성은 환경 스타일에 의해 영향을 받습니다. 블록 드롭을 도입하면 텍스트 프롬프트에 대한 준수도가 향상되며, 캐릭터와 환경 모두에 대해 올바른 공간 레이아웃을 가진 이미지를 생성하게 됩니다. 그러나 캐릭터의 외형은 여전히 주변 환경의 영향을 받습니다. 제안된 동적 마스크 방식을 포함한 지역 주입 메커니즘을 도입함으로써, 생성된 이미지는 환경에 대한 효과적인 조건화와 함께 강력한 캐릭터 일관성을 달성할 수 있습니다.

**표 3: Unbounded와 다양한 LLM이 개방형 상호작용 및 통합된 게임 메커니즘의 게임 엔진 역할을 수행하는 비교.**  
우리는 **GPT-4**를 사용하여 우리의 모델과 다른 LLM 간의 쌍별 점수를 제공합니다.

![](/assets/images/posts/297/img_11.png)

**5.3 특화된 대형 언어 모델 증류의 효과**  
우리는 다양한 사용자-시뮬레이터 상호작용 데이터를 통해 **Gemma-2B**를 효과적인 게임 엔진으로 증류할 수 있음을 보여줍니다. 표 3에서 볼 수 있듯이, 소형 LLM(예: **Gemma-2B**, **Llama3.2-3B**) 또는 약간 더 큰 LLM(예: **Gemma-7B**)의 제로샷 추론은 우리의 모델에 비해 성능이 낮게 나타나, 게임 세계와 캐릭터 행동 시뮬레이션을 위해 더 강력한 LLM에서의 증류의 중요성을 강조합니다. 또한, 우리의 모델이 **GPT-4o**와 유사한 성능을 달성했음을 보여주며, 우리의 접근 방식의 효과성을 입증합니다. 우리는 또한 1천 개의 데이터와 5천 개의 데이터로 증류된 **Gemma-2B** 모델을 비교하여 증류 데이터 크기가 성능에 미치는 영향을 조사했습니다. 결과는 더 큰 데이터셋을 사용할 경우 모든 측면에서 성능이 일관되게 향상되었음을 보여주며, 더 많은 데이터를 사용하여 **GPT-4o**의 성능과 완전히 일치하는 추가 개선의 가능성을 강조합니다.

**6 결론**  
우리는 생성 모델에 기반한 상호작용형 생성 무한 게임 **Unbounded**를 소개합니다. **Unbounded**는 두 가지 주요 구성 요소, 즉 실시간 상호작용을 위한 특화된 증류된 LLM과 여러 장면에서 일관된 생성을 위한 제안된 **지역 IP-Adapter**를 사용하는 빠른 확산 모델을 기반으로 구축되었습니다. 우리는 제안된 접근 방식이 일관된 캐릭터, 환경, 이야기를 갖춘 생성 모델에 내포된 상호작용형 게임을 가능하게 하며, 무한 게임의 특성을 지닌 확장된 게임 플레이를 제공함을 보여줍니다.

**감사의 말**  
우리는 **Shiran Zada**, **Peyman Millanfar**, **Shlomi Fruchter**, **Michael Goin**, 그리고 **Matthew Guzdial**에게 깊이 있는 피드백과 논의에 대해 감사드립니다.

[2410.18975v2.pdf

7.05MB](./file/2410.18975v2.pdf)

이 부록에서는 다음 내용을 제시합니다:

• **A절**: 사용자-시뮬레이터 데이터 수집에 사용한 프롬프트.  
• **B절**: GPT-4를 판사로 하여 LLM 평가를 위해 사용한 평가 프롬프트.  
• **C절**: 재현성 진술.

**부록 A: 합성 사용자-시뮬레이터 상호작용 데이터 수집을 위한 프롬프트**  
이 절에서는 사용자-시뮬레이터 데이터를 수집하기 위해 사용한 프롬프트 템플릿을 제공합니다. 구체적으로, 우리는 그림 9에 표시된 템플릿을 사용하여 **GPT-3.5**에 다양한 주제와 캐릭터 설명을 생성하도록 요청합니다. 사용자 LLM의 잠재적인 사용자 상호작용을 안내하는 프롬프트 템플릿은 그림 10에 나와 있습니다. 사용자 상호작용이 대화 기록과 일치하도록 보장하기 위해, 우리는 상호작용 기록을 사용자 LLM의 입력으로 포함합니다. 그림 11에 나와 있는 세계 시뮬레이션 LLM 프롬프트 템플릿 또한 대화 기록을 받아 다음 캐릭터 행동, 상태, 내러티브를 생성합니다. 우리는 세계 시뮬레이션 LLM이 한 번에 하나의 이야기만 생성하도록 제한하여 사용자가 이야기를 어떻게 계속할지 선택할 수 있도록 합니다.

**부록 B: 평가 프롬프트**  
그림 12에는 두 LLM의 출력을 비교하기 위해 사용한 프롬프트 템플릿을 포함합니다. 이 프롬프트는 **Vicuna**(Chiang 등, 2023)에서 가져와 수정한 것으로, 주어진 작업에서 두 LLM의 성능을 비교하는 효과적인 도구로 검증되었습니다.

**부록 C: 재현성 진술**  
첫째, 우리는 **섹션 4.2**에서 **Unbounded**의 구현 세부 사항을 포함하며, Dreambooth 미세 조정과 **LLM** 증류를 위한 학습 하이퍼파라미터, 그리고 **LLM**과 이미지 생성을 위한 추론 시 사용된 하이퍼파라미터를 다룹니다. 둘째, **섹션 3.3**에서 학습을 위해 수집한 사용자-시뮬레이터 데이터에 대한 자세한 설명을 제공하고, 부록 **섹션 A**에서 **GPT** 모델을 쿼리하는 데 사용된 프롬프트 템플릿을 추가로 포함합니다. 마지막으로, **LLM** 기반 평가를 위해 두 **LLM**의 출력을 비교하기 위해 **GPT-4**를 쿼리하는 프롬프트 템플릿을 부록 **섹션 B**에 제공합니다.

![](/assets/images/posts/297/img_12.png)

**그림 9:** 다양한 주제와 캐릭터 데이터를 수집하는 데 사용된 프롬프트 템플릿.

![](/assets/images/posts/297/img_13.png)

**그림 10:** 사용자 **LLM**을 쿼리하는 데 사용된 프롬프트 템플릿.

![](/assets/images/posts/297/img_14.png)

**그림 11:** 세계 시뮬레이션 **LLM**을 쿼리하는 데 사용된 프롬프트 템플릿.

![](/assets/images/posts/297/img_15.png)

**그림 12:** 두 **LLM** 출력 간 성능을 비교하기 위해 **GPT-4**를 쿼리하는 데 사용된 프롬프트 템플릿. 이 프롬프트는 **Vicuna**(Chiang 등, 2023)에서 수정한 것입니다.
