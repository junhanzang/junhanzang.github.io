---
title: "Chat-GPT 잡아내는 AI 나왔다"
date: 2023-02-04 21:12:46
categories:
  - 일상생활
tags:
  - adversarial attacks
  - ChatGPT
  - 챗GPT
---

출처: <https://n.news.naver.com/article/015/0004804576>

[AI 전쟁의 서막…챗GPT 잡아내는 AI 나왔다](https://n.news.naver.com/article/015/0004804576)

간단한 한 요약: “학생들이 (GPT 같은) LLM(대규모 언어 모델) 사용해 과제를 끝낼 수 있는데 이런 경우 선생은 학생의 학습 내용을 정확하게 평가할 수 없다”며 미국 스탠퍼드대의 크리스토퍼 매닝 교수와 첼시 핀 교수 등이 참여한 연구팀은 지난 26일 챗GPT의 바탕인 AI 언어모델 GPT3로 만들어진 문장 찾아내는 기술(디텍트GPT·DetectGPT)을 공개했다.

디텍트 GPT는 과연 Chat gpt를 잘 잡아낼 수 있을까?

이 부분에 대해서 나는 회의적으로 생각한다. 물론 모델을 공개하지 않고 이에 대한 꾸준한 업데이트가 된다면 잡긴 하겠지만 효율성이 높다고 보여지지 않는다. 애초에 LLM 분야에서 사용된 패턴을 통해서 detect를 실행하게 될텐데, 학생이 정말 사용하지 않았지만 이와 유사하다면 어떻게 될까? 그런 큰 리스크 때문에 나는 위의 DetectGPT에 대해서 회의적이다. 실제 AI 분야에는 Adversarial Attacks라는 분야가 있다. 이 해당 분야에서 image detect에 대해서 투명 망토가 나온게 최소 3년전이고 최근에 가장 잘 알려진 것은 메릴랜드 대학교의 것이다.

<http://www.ainet.link/9035>

[[투명망토] 인공지능(AI) 카메라를 속여 사람을 알아보지 못하게 하는 실생활의 ˝보이지 않는 망](http://www.ainet.link/9035)

이렇게 인공지능을 속이는 분야를  Adversarial Attacks라고 하며 이 원리는 인공지능이 그린 그래프의 경계를 교묘하게 위치하여 다른 사물로 인식시키거나, 아예 feature map자체의 인식을 없애는 것과 같은 형태이다. 이를 모방한다면 과연 DetectGPT는 잡아낼 수 있을까? 심지어 더 어려운 분야인 LLM에서? 나는 회의적으로 바라본다. 그리고 생성도 매번 같은 패턴으로 하지 않고 다른 패턴의 형태로 하는데 이를 잡는다는 것은 정말 어려운 일이 될 것이며, 미래의 교육은 어쩌면 누가 인공지능과 같은 전자기기를 잘 다루는지에 대한 창의적인 영역으로 들어가지 않을까...
