---
title: "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning"
date: 2024-11-27 19:55:22
categories:
  - 인공지능
---

<https://arxiv.org/abs/2411.07279>

[The Surprising Effectiveness of Test-Time Training for Abstract Reasoning](https://arxiv.org/abs/2411.07279)

graph TB subgraph "전통적인 언어 모델" A1[입력] --> B1[단일 추론 과정] B1 --> C1[출력] end subgraph "테스트 시점 계산 모델" A2[입력] --> B2[초기 추론] B2 --> D2{품질 검사} D2 -->|충분| E2[출력] D2 -->|부족| F2[추가 추론] F2 --> G2[자가 검토] G2 --> H2[수정] H2 --> I2[최종 출력] end style A1 fill:#f9f style A2 fill:#f9f style B1 fill:#bbf style B2 fill:#bbf style C1 fill:#f96 style E2 fill:#f96 style I2 fill:#f96 style F2 fill:#bfb style G2 fill:#bfb style H2 fill:#bfb

**초록**

언어 모델은 학습 데이터 분포 내의 작업에서 인상적인 성능을 보여주지만, 복잡한 추론이 필요한 새로운 문제에서는 종종 어려움을 겪습니다. 우리는 테스트 시점 훈련(TTT)이 모델의 추론 능력을 개선하는 메커니즘으로 얼마나 효과적인지 조사합니다. TTT는 입력 데이터로부터 파생된 손실을 사용하여 추론 중 모델 파라미터를 일시적으로 업데이트하는 방식입니다. 우리는 추상 및 추론 코퍼스(ARC)를 벤치마크로 사용하여 이를 평가했습니다. 체계적인 실험을 통해 성공적인 TTT를 위한 세 가지 중요한 요소를 확인했습니다: (1) 유사한 작업에 대한 초기 미세 조정, (2) 보조 작업 형식 및 데이터 증강, (3) 인스턴스별 훈련. TTT는 ARC 작업에서 성능을 크게 향상시켰으며, 기본 미세 조정 모델에 비해 최대 6배의 정확도 개선을 이루었습니다. 80억 파라미터를 가진 언어 모델에 TTT를 적용한 결과, ARC의 공개 검증 세트에서 53%의 정확도를 달성했으며, 이는 공개 및 순수 신경망 접근 방식에 대해 현재의 최고 성능을 거의 25% 개선한 것입니다. 또한, 최근의 프로그램 생성 접근법과 우리의 방법을 앙상블로 결합하여 ARC 공개 검증에서 61.875%의 정확도를 기록했으며, 이는 인간의 평균 점수와 일치합니다. 우리의 연구 결과는 명시적인 기호적 탐색이 신경 언어 모델에서 추상적 추론을 개선하는 유일한 방법이 아님을 시사합니다. 소수의 예제를 기반으로 한 추가 테스트 시점 훈련 역시 매우 효과적일 수 있습니다.

![](/assets/images/posts/344/img.png)

**그림 1**: (왼쪽): 무작위로 선택된 ARC 검증 작업 80개의 하위 집합에서 Pass@2 정확도. TTT는 미세 조정된 모델(FT)의 성능을 최대 6배까지 향상시켰으며, 다양한 모델 크기에서 일관된 개선을 보였습니다. (오른쪽): 모델이 TTT를 적용한 후에만 성공적으로 해결한 작업의 예시. 전체 데이터셋 결과는 표 1에 있습니다.

**1. 서론**

대규모 신경 언어 모델(LM)은 학습 데이터에 나타나는 작업이나 그러한 작업의 간단한 변형 및 조합에서 뛰어난 성능을 발휘합니다 (Brown et al., 2020; Todd et al., 2024). 자연어로 작성된 작업 명세나 몇 개의 예제가 주어졌을 때, LMs는 종종 원하는 작업을 성공적으로 추론하고 적절한 출력을 생성합니다. 그러나 LM이 사전 학습 데이터와 매우 다른 종류의 비사소적인 추론, 계획 또는 문자열 조작을 포함하는 새로운 문제도 해결할 수 있을까요? 이 질문은 현재 AI 시스템의 새로운 기술 획득 능력을 이해하는 데 있어 핵심적입니다. 이러한 능력은 지능의 중요한 척도로 제안되었습니다 (Chollet, 2019).

복잡하고 새로운 작업에 대해서는 단순히 LM에서 샘플링하여 올바른 답을 얻기 어려운 경우가 종종 있습니다 (Wu et al., 2023). 그러나 최근 몇 년간 중요한 발견은 LM의 성능이 추가적인 테스트 시점 계산을 통해 LM 디코딩을 증강함으로써 상당히 향상될 수 있다는 점입니다. 이러한 범주의 방법으로는 체인-오브-쏘트 프롬프팅 (Wei et al., 2022), 다수결을 이용한 샘플링 (self-consistency; Wang et al., 2022), 코드 실행 (Brown et al., 2024; Snell et al., 2024; Damani et al., 2024), 그리고 탐색 (Yao et al., 2024) 등이 있습니다.

최근 주목받고 있는 확장 전략 중 하나는 테스트 시점 훈련(TTT)으로, 이는 테스트 시점 입력을 기반으로 명시적인 경사 하강 단계를 통해 모델을 업데이트하는 방법입니다 (Krause et al., 2018; 2019). 이 방법은 일반적인 미세 조정과는 달리 매우 낮은 데이터 상황에서 동작합니다—일반적으로 단일 입력에 대한 비지도 목표 또는 한두 개의 맥락 내 레이블이 지정된 예제에 대한 지도 목표로 이루어집니다. 이 접근법의 현대적 버전은 Sun et al. (2020)에 의해 비전 모델에 제안되었으며, Gandelsman et al. (2022)에 의해 시퀀스 모델에도 적용되었습니다. TTT 접근법의 설계 공간은 넓으며, 현재 LM(특히 새로운 작업 학습)에 가장 효과적인 설계 선택이 무엇인지에 대한 이해는 제한적입니다. 이 논문에서는 다양한 TTT 설계 선택의 영향을 체계적으로 연구하고, 이를 사전 학습 및 샘플링 방식과의 상호작용 측면에서 분석합니다.

우리는 이 방법들을 Abstraction and Reasoning Corpus (ARC) (Chollet, 2019)에서 평가하며, 이는 극도로 어려운 몇 샷 시각적 추론 문제들을 모아둔 컬렉션입니다. ARC는 LM의 일반화 한계를 테스트하는 데 이상적인 벤치마크로, 새로운 형식의 새로운 작업을 제시하며 비사소적인 탐색과 추론 능력을 요구합니다. 현재의 언어 모델들은 ARC에서 성능이 저조합니다. 대부분의 성공적인 접근법은 프로그램 생성 기법에 의존해 왔습니다 (Butt et al., 2024; Ainooson et al., 2023; Huang et al., 2023), 그러나 최근 Cole et al. (2024)은 이 벤치마크에서 TTT를 사용하여 유망한 결과를 보고하였습니다.

우리는 few-shot 학습에 TTT를 효과적으로 적용하기 위한 몇 가지 중요한 요소를 확인했습니다: (1) 테스트 시점에서 마주하는 것과 유사한 작업에 대한 초기 미세 조정, (2) 테스트 시점 데이터셋을 구성하기 위한 보강된, leave-one-out 작업 생성 전략, (3) 인스턴스별 어댑터 훈련, (4) 가역 변환 하에서의 self-consistency (Wang et al., 2022) 접근법. 이러한 구성 요소들을 신중하게 선택하면 TTT는 ARC에서 LM 성능을 상당히 향상시킬 수 있으며, 10억 모델에서 최대 여섯 배의 정확도 증가를 이루며, 80억 모델로 ARC 작업에서 발표된 순수 신경 모델 중 최고의 결과를 달성할 수 있습니다. 실제로, 우리의 결과는 테스트 시점 훈련을 갖춘 일반적인 LM이 ARC에서 많은 신경-기호 접근법의 성능에 필적하거나 이를 능가할 수 있음을 보여줍니다.

**주요 기여 사항은 다음과 같습니다:**

1. ARC 작업에서 테스트 시점 훈련을 위한 주요 구성 요소를 식별하고 체계적으로 분석했습니다. 여기에는 새로운 테스트 시점 데이터 생성 및 self-consistency 요소가 포함됩니다.
2. ARC 검증 세트에서 발표된 신경 접근법 중 최고 성능을 달성했습니다: • 80억 파라미터 모델로 공개 검증 세트에서 53% 정확도. • 프로그램 생성 접근법과 앙상블한 결과, 데이터셋에서 평균 인간 성능과 비교되는 61.875% 정확도를 달성했습니다.
3. 이전에는 프로그램 생성만으로 해결할 수 있었던 작업을 우리의 TTT 프레임워크를 갖춘 순수 신경 접근법으로 해결할 수 있음을 입증했습니다.

이러한 결과는 기호적 요소가 복잡한 작업을 해결하는 데 반드시 필요하다는 가정을 도전적으로 검토합니다. 대신, 이러한 새로운 추론 문제를 해결하는 데 있어 중요한 요소는 테스트 시점에서 적절한 계산 자원을 할당하는 것일 수 있으며, 이 자원이 기호적 또는 신경 메커니즘을 통해 배치되는지 여부와 독립적으로 그 효과가 있을 수 있음을 시사합니다.

**2. 사전 지식**

본 섹션에서는 먼저 ARC 챌린지를 공식적으로 설명합니다. 다음으로, 우리의 연구의 기초를 이루는 맥락 내 학습(in-context learning)과 테스트 시점 훈련(test-time training)에 대해 개요를 제공합니다. 마지막으로, 기본 실험 설정을 자세히 설명합니다.

**2.1 ARC 챌린지**

추상 및 추론 코퍼스(ARC)는 언어 모델이 시각적 퍼즐을 해결하는 능력을 통해 추상적 추론 능력을 평가하는 것을 목표로 합니다. 각 퍼즐(이하 "작업")은 2D 그리드(최대 30×30 크기)로 이루어진 입력-출력 쌍으로 구성되며, 이는 최대 10개의 서로 다른 색상으로 이루어진 도형이나 패턴을 포함하고 있습니다. 이는 그림 1(b)에 표시되어 있습니다. 각 쌍의 출력은 직관적이고 공통된 변환 규칙 또는 함수 y=f(x) 를 적용하여 얻어집니다. 실제로 이러한 변환은 반사와 카운팅 같은 간단한 개념에서부터 중력 적용이나 경로 찾기와 같은 더 복잡한 개념에 이르기까지 다양하고 복합적입니다.

ARC의 각 작업은 학습 및 테스트 세트로 구성되며:

![](/assets/images/posts/344/img_1.png)

- 학습 예제는 ( x\_k^{train}, y\_k^{train})\_{k=1}^K 로 표시됩니다 (일반적으로 K 는 2에서 7 사이).
- 테스트 예제는 ( x\_m^{test}, y\_m^{test})\_{m=1}^M 로 표시됩니다 (일반적으로 M 은 1에서 3 사이).

학습 예제 집합이 주어지면, 기본 변환을 추론하여 테스트 입력 x\_{test} 에 대한 테스트 출력 y\_{test} 를 예측하는 것이 목표입니다.

작업을 d = (?\_{train}, ?\_{train}, ?\_{test}, ?\_{test}) 로 나타내며, 여기서 d ∈ ?\_{ARC} 는 이러한 ARC 작업의 모음입니다. ARC 데이터셋의 원래 학습 및 검증 세트는 각각 ?\_{ARC}^{train} 과 ?\_{ARC}^{val} 로 400개의 작업으로 구성되어 있습니다. 성공 기준은 모든 테스트 출력에 대해 정확히 일치하는 결과를 내는 것입니다 (부분 점수는 주어지지 않음). 이러한 작업에 대한 분류 및 분석은 Johnson et al. (2021)을 참조하십시오.

ARC에 대한 대부분의 접근 방식은 두 가지 주요 범주로 나눌 수 있습니다: 프로그램 생성과 순수 신경 접근 방식입니다. 프로그램 생성 접근 방식(Butt et al., 2024; Wang et al., 2024; Li et al., 2024; Greenblatt, 2024)은 먼저 변환 함수 f 를 찾고 나중에 이를 테스트 예제에 적용하려고 합니다. 반면에, 순수 신경 접근 방식(Thoms et al., 2023; Bober-Irizar and Banerjee, 2024)은 기본 변환을 암묵적으로 추론하면서 바로 테스트 출력 y\_{test} 를 예측하려고 합니다. 본 연구에서는 언어 모델(LM)을 사용하여 테스트 출력을 예측하는 순수 신경 접근 방식을 사용합니다.

우리는 텍스트 데이터로 사전 학습된 LM(비전 인코더가 없음)으로 시작합니다. 이 모델에 ARC 예제를 입력으로 제공하기 위해, 2D 그리드를 그림 8에 표시된 대로 텍스트 표현으로 변환하는 포맷팅 함수(denoted str)가 필요합니다. 이전 연구에서는 숫자의 리스트(Wang et al., 2024)나 색상 단어, 또는 도형과 위치가 라벨링된 연결된 구성 요소의 리스트(Greenblatt, 2024)로 예제를 제시한 바 있습니다. 이러한 문자열 표현이 주어지면, LM에 이를 제시하고 few-shot 프롬프팅을 통해 예측을 수행할 수 있습니다. 자세한 내용은 다음 섹션에서 설명합니다.

**2.2 맥락 내 학습 (In-context Learning)**

일정 규모 이상에서는 많은 LM이 입력 예제나 제공된 지시에 따라 단순히 조건을 맞추는 방식으로 매개변수를 업데이트하지 않고도 새로운 작업에 적응하는 능력을 보입니다. 입력-출력 쌍 ( x\_1, y\_1), ..., (x\_n, y\_n) 과 새로운 입력 x\_{n+1} 이 주어졌을 때, LM은 다음과 같이 샘플링하여 출력 ŷ\_{n+1} 을 생성할 수 있습니다:

ŷ\_{n+1} ∼ LM(⋅ ∣ x\_1, y\_1, ..., x\_n, y\_n, x\_{n+1}) ] (1)

맥락 내 학습의 가능성은 이전 연구(Akyürek et al., 2022)에서 암묵적인 기계 학습 시뮬레이션으로 논의되었으나, 실증적 증거는 언어 모델을 이용한 맥락 내 학습이 항상 표준 기계 학습 알고리즘과 유사하지 않으며 (Zhao et al., 2024; Min et al., 2022), 새로운 작업에서는 항상 잘 동작하지 않는다는 점을 보여줍니다 — 예를 들어, 소형 언어 모델(수십억 개의 파라미터로 이루어진 모델)은 ARC에서 성능이 저조합니다 (Opielka et al., 2024; Bober-Irizar and Banerjee, 2024).

**2.3 테스트 시점 훈련 (Test-Time Training)**

![](/assets/images/posts/344/img_2.png)

**Figure 2**: 테스트 작업에 대한 TTT 데이터셋 생성 (섹션 3.1 참조): 우리는 주어진 작업의 학습 예제에서 leave-one-out 작업을 생성하는 것으로 시작합니다. 이러한 작업들은 규칙 기반 변환을 통해 증강되어 전체 TTT 데이터셋을 만듭니다. 마지막으로, 기본 미세 조정(FT) 모델 위에 작업별 LoRA 어댑터를 훈련합니다.

테스트 시점 훈련(TTT)은 대규모 언어 모델 시대에 상대적으로 탐구되지 않은 접근 방식으로, 추론 중 모델의 동적 파라미터 업데이트를 통해 매개변수적 모델이 적응할 수 있도록 합니다. 이 기법은 모델이 테스트 데이터 구조를 활용하여 예측을 개선하는 일종의 전이 학습입니다. 일반적인 TTT 프로세스는 다음과 같이 작동합니다: 초기 모델 파라미터 ?₀ 로 시작하여, 각 테스트 입력(또는 입력 배치)에 대해 우리는 먼저 테스트 입력에서 ?\_{TTT}(d\_{input}) 라는 훈련 데이터를 생성합니다. 그런 다음 이러한 파라미터를 최적화하여 손실 함수 ℒ(?\_{TTT}; ?) 를 최소화하여 예측을 위한 임시 업데이트된 파라미터 ?\_d 를 생성합니다. 예측을 생성한 후, 다음 인스턴스나 배치에 대해서는 모델을 원래 파라미터 ?₀ 로 복원합니다. 따라서 TTT는 테스트 시점 입력에서 생성된 테스트 시점 데이터셋으로 기본 모델을 미세 조정하여 각 테스트 입력에 대해 특화된 예측 모델을 훈련합니다.

이전 연구들(e.g., Sun et al., 2020)에서, ?\_{TTT} 는 일반적으로 입력 ? 에 단독으로 비지도 목표(예: 마스크된 자동 인코딩)를 적용하여 생성되었습니다. 하지만 우리가 고려하는 맥락 내 학습 설정에서는 시연 쌍 ( x₁, y₁), ..., (x\_K, y\_K) 의 형태로 더 풍부한 맥락을 제공합니다. 여기에서 테스트 시점 튜닝을 적용하려면 먼저 테스트 입력 x 에 대해 입력별 데이터셋 ?\_{TTT} 을 매핑하는 초기 언어 모델 LM 을 구성하고, 데이터셋에 대한 손실 함수 ℒ 를 최적화하도록 LM을 미세 조정하며, 최종적으로 업데이트된 모델에서 샘플링하여 최종 예측을 얻습니다. 이 논문에서는 이 파이프라인의 각 구성 요소를 특성화하며 다음과 같은 내용을 설명합니다:

1. 테스트 입력에서 증강된 TTT 데이터셋 ?\_{TTT} 을 생성하는 방법 (섹션 3).
2. 변환에 대한 self-consistency를 기반으로 한 증강된 추론 전략 (섹션 4).
3. 유사한 작업의 데이터셋 ?\_{FT} 에 대해 미세 조정된 파라미터 ?₀ 을 가진 기본 모델 (섹션 5).

**2.4 실험 설정**

각 TTT 구성 요소의 영향을 조사하기 위해, 우리는 최적의 값으로 설정된 다른 요소들을 고정한 상태에서 하나의 요소를 변경하여 실험을 수행합니다(각각의 섹션에서 설명된 대로). 실험에서 기본 구성은 다음과 같은 설정을 사용합니다:

**모델 아키텍처 및 최적화**

우리는 Llama-3 모델에서 80억 개의 파라미터 언어 모델을 사용하며, Llama-3.2 모델에서 10억, 30억 개 모델도 사용합니다 (Dubey et al., 2024). 우리는 Low-Rank Adaptation (LoRA) (Hu et al., 2021)을 사용하여 파라미터 효율적인 테스트 시점 훈련을 진행합니다. 각 작업 d 에 대해, 데이터셋 ?\_{TTT} 에서 훈련된 별도의 LoRA 파라미터 집합을 초기화합니다. LoRA 랭크는 128로 설정되며, MLP, attention, 출력 레이어에 적용됩니다. 우리는 AdamW 옵티마이저 (Loshchilov and Hutter, 2019)를 사용하여 배치 크기 2로 2 에포크 동안 모델을 훈련합니다.

**데이터 및 포맷팅**

효율적인 평가를 위해 ARC 검증 세트에서 균형 잡힌 ARC 작업 80개를 무작위로 선택하며, LeGris et al. (2024a)의 분류에 따라 쉬운 작업 20개, 중간 작업 20개, 어려운 작업 20개, 전문가 작업 20개가 포함됩니다 (이 작업 목록은 표 2에서 확인하십시오). 논문 전체에서 ARC 작업의 이 하위 집합을 사용하며, 전체 검증 세트에 대한 최종 결과는 표 1에서 제공합니다. 효율성을 위해 ?\_{TTT} 는 작업당 최대 250개의 예제를 가지도록 제한합니다. 이를 통해 NVIDIA-A100 GPU를 사용할 때 100개의 무작위 검증 작업을 처리하는 데 약 12시간이 소요됩니다. 부록 B.2에서는 하이퍼파라미터에 대한 추가 세부사항을 제공합니다. 입력 그리드는 그림 8에 표시된 대로 numpy의 기본 배열 인쇄 형식을 사용하여 텍스트로 변환됩니다.

다음 섹션에서는 언어 모델을 사용한 추상적 추론에 성공적으로 기여하는 주요 요소들을 조사합니다. 우리의 분석은 미세 조정 데이터 ?\_{FT} , TTT 데이터 ?\_{TTT} , 훈련 목표, 추론 절차, 모델 크기의 영향을 다루며, 테스트 시점 훈련을 효과적으로 배포하기 위한 전략에 대한 통찰을 제공합니다.

**3. TTT에서 어떤 데이터셋과 손실을 사용할 것인가?**

**3.1 데이터 생성** 주어진 작업에 대해, 학습 입력-출력 쌍 ( x\_k^{train}, y\_k^{train} ){k=1}^K 의 집합을 가져와 이를 테스트 시점 훈련(TTT) 작업의 증강된 세트 ?{TTT} 로 변환합니다. ?\_{TTT} 는 두 단계의 과정을 통해 생성됩니다. 첫 번째로, 주어진 학습 입력-출력 쌍에서 leave-one-out 방식의 맥락 내 학습(in-context learning) 작업 집합을 만듭니다. 두 번째로, 이 집합에 대해 가역적인 규칙 기반 변환을 사용하여 증강된 데이터셋을 얻습니다. 이 과정은 그림 2에 요약되어 있습니다.

**1단계 - Leave-one-out 작업 생성**: 학습 예제에서 j 번째 예제 쌍을 제외함으로써 다음과 같은 합성 작업을 만들 수 있습니다:

![](/assets/images/posts/344/img_3.png)

여기서 j ∈ [1, K] 입니다. 즉, j 번째 예제 쌍을 테스트 케이스로 취급하여 합성 학습 작업 d\_j 를 생성합니다. 우리는 총 n 개의 작업을 생성할 수 있으며, 각 작업은 n-1 개의 예제 쌍을 포함합니다. 우리는 또한 d\_j 의 두 개의 무작위 순열 버전을 포함하며, 학습 예제의 순서를 무작위로 변환합니다.

**2단계 - 규칙 기반 변환**: 가역적인 변환 t 를 고려합니다. 이는 다음과 같은 특성을 가집니다:

![](/assets/images/posts/344/img_4.png)

1단계에서 얻은 각 작업에 대해, 우리는 t 를 사용하여 새로운 증강 작업 t(d\_j^{ICL}) 을 생성할 수 있으며, 여기서 t 는 작업의 각 개별 그리드에 적용됩니다.

우리는 회전, 뒤집기, 색상 순열, 예제 순열, 크기 스케일링 등 기본적인 관계를 유지하면서 통제된 변화를 도입하는 간단한 변환을 선택합니다. 이러한 변환 목록과 설명은 표 3에 제공되어 있습니다. 마지막으로, 우리는 다음과 같은 TTT 데이터셋을 얻습니다:

![](/assets/images/posts/344/img_5.png)

**기본선: End-to-End 학습 작업** 위에서 설명한 "테스트 시점 맥락 내 학습" 접근법과 비교하기 위해, 우리는 또한 "테스트 시점 종단간(end-to-end) 학습" 접근법을 평가합니다. 각 입력-출력 쌍을 독립적인 학습 인스턴스로 취급하여 예제 시연에서 직접 감독된 데이터셋을 생성합니다. 맥락 내 학습 설정과는 달리 예측에는 어떤 맥락도 사용되지 않습니다:

![](/assets/images/posts/344/img_6.png)

이는 맥락이 제공되지 않는 ICL 설정에서 (n-1) -out 작업 집합과 동등합니다. ICL 경우와 유사하게, 우리는 규칙 기반 변환을 적용하여 데이터셋을 증강할 수 있습니다:

![](/assets/images/posts/344/img_7.png)

이 접근법은 시연 맥락을 관리하는 오버헤드(즉, few-shot 프롬프트)가 없기 때문에 입력-출력 매핑을 직접 학습하는 만큼 계산적으로 더 효율적입니다.

**3.3 결과**

![](/assets/images/posts/344/img_8.png)

**Figure 3**: TTT에서의 다양한 데이터와 최적화 절제 실험의 정확도: 우리의 데이터 절제 연구는 ICL 데이터 형식이 효과적인 TTT에 필수적이며, TTT 데이터셋을 증강하기 위한 변환을 적용하는 것이 성능을 현저히 향상시킨다는 것을 보여줍니다. 최적화 절제에서는 작업별 어댑터를 학습하는 것이 단일 어댑터를 사용하는 것보다 상당히 뛰어났습니다. 또한, 맥락 내 시연에서 손실을 사용하는 것이 약간의 성능 향상을 제공하며, 양자화된 LoRA를 사용하는 경우 성능 감소가 미미하게 나타났습니다. 전체 논의는 섹션 3에 있습니다.

우리는 우리의 방법의 주요 구현을 다음 절제 실험과 비교합니다:

1. **FT (No TTT)**: TTT를 사용하지 않고 미세 조정된 모델을 사용하는 기본선입니다.
2. **No Transformations**: 변환 기반 데이터 증강이 없는 경우입니다. 즉, 섹션 3.1에서 설명된 데이터 생성 파이프라인의 2단계에서 생성된 데이터가 테스트 시점 훈련 데이터셋에 포함되지 않습니다.
3. **End-to-End (E2E) Data**: 표준 맥락 내 작업 설정 대신, 섹션 3.1에 설명된 대로 종단간 작업 형식을 사용합니다.
4. **Shared TTT**: 작업별 LoRA 어댑터를 학습하는 대신, 모든 작업의 집계된 데이터셋을 사용하여 단일 LoRA 어댑터를 학습합니다.
5. **No Demonstration Loss**: 데이터의 학습 출력에서 시연에 대한 손실을 사용하지 않습니다. 즉, TTT 손실은 단순히 다음과 같습니다:
6. **QLoRA**: 전체 정밀도의 기본 모델 업데이트 대신, 각 작업에 대해 양자화된 LoRA 어댑터(Dettmers et al., 2024)를 학습합니다. 이는 메모리 효율성을 고려한 LoRA의 대안입니다.

![](/assets/images/posts/344/img_9.png)

No Demonstration Loss

결과는 그림 3에 제시되어 있습니다. 우리의 TTT 방법은 효과적이며, 미세 조정된 모델의 정확도를 약 6배 (5 → 29) 향상시킵니다. 보조 작업의 구조는 TTT의 효과에 크게 영향을 미칩니다. 맥락 내 학습 작업을 사용하는 것이 종단간 작업을 사용하는 것보다 상당히 뛰어났으며, 동일한 조건에서 작업 성능이 11 (38% 감소) 개만큼 떨어지는 것을 보여줍니다. 이는 단순히 더 적은 파라미터를 학습하기 때문일 수 있습니다. 데이터를 증강하기 위한 변환을 생략하는 것은 16 개의 작업에서 성능 저하를 초래했습니다 (55% 감소).

다음으로, 우리는 TTT 최적화의 여러 구성 요소를 절제하여 성능에 미치는 영향을 분석했습니다. 모든 작업에 대해 단일 LoRA 어댑터를 학습하는 것은 7개의 작업에서 성능을 감소시켰습니다 ( 24% 감소). 이는 작업별 전용 어댑터를 학습하는 것이 작업당 더 많은 파라미터를 학습할 수 있기 때문에 예상된 결과입니다. 두 번째로, 우리는 출력 시연에서 손실을 적용한 결정이 성능을 약간 개선했다는 것을 발견했습니다 ( 26 → 29 ), 이는 모델이 시연을 처리하는 동안 변환에 대해 추론하도록 강제하기 때문이라고 믿습니다. 마지막으로, 양자화된 LoRA(QLoRA)를 사용하는 경우 성능이 약간 떨어지는 것만 관찰되었습니다 ( 29 → 26 ) — 메모리 병목이 있는 상황에서는 QLoRA가 유용할 수 있습니다.

**4. TTT 이후의 추론 전략은 무엇인가?**

![](/assets/images/posts/344/img_10.png)

**Figure 4**: 증강 추론 및 계층적 투표 (섹션 4): 우리는 leave-one-out 작업과 가역적인 기하학적 변환을 사용하여 증강된 추론을 위해 작업의 여러 동등한 버전을 얻습니다. 이러한 버전들의 예측은 계층적 투표 전략을 통해 집계됩니다: 먼저 각 변환 내에서 투표가 수행되고, 그런 다음 각 변환에서의 상위 후보들이 글로벌 투표를 통해 최종 상위 두 개의 예측으로 결정됩니다.

**4.1 증강 추론 (Augmented Inference)** 최근 연구에서는 테스트 시점 계산을 확장하면 언어 모델(LMs)의 성능을 크게 향상시킬 수 있음을 보여주었습니다. 이를 수행하는 가장 일반적인 기술 중 하나는 여러 응답을 샘플링하고, 랭커를 사용하여 최상의 응답을 선택하는 것입니다. 그러나 샘플링은 여러 가능한 솔루션이 있는 도메인(예: 코드 프로그램)이나 최종 답변에 이르는 여러 경로가 있는 도메인(예: 수학)에서는 매우 효과적이지만, 답변을 직접 생성할 때는 오히려 해로울 수 있습니다. 샘플들 간의 다양성을 직접적으로 보장하면서 동시에 일관성을 유지할 수 있는 방법이 없기 때문입니다. 이에 대한 대안적인 추론 시점 확장으로 우리는 기하학적 변환을 사용하여 여러 예측 후보를 생성하는 증강 추론 전략을 사용하며, 이는 탐욕적 디코딩 방식과 결합됩니다.

주어진 작업에 대해 학습 예제 ( x\_k, y\_k ){k=1}^K 와 테스트 입력 x{test} 이 있을 때, 우리는 그림 3에서 보이는 바와 같이 가역적인 기하학적 변환을 사용하여 작업의 동등한 변환 버전을 생성합니다. ? 는 가역적인 기하학적 변환 집합(예: 회전 및 반사)이라고 합시다. 각 변환 t ∈ ? 에 대해, 우리는 모든 학습 시연과 테스트 입력에 변환 t 를 적용하고, 이러한 변환된 입력을 사용하여 모델을 실행합니다. 그런 다음 최종 예측을 얻기 위해 역변환을 적용합니다.

![](/assets/images/posts/344/img_11.png)

우리는 학습 예제의 순서를 변경하여 예측을 추가로 증강합니다. 각 변환 g 에 대해, 우리는 시연 순서의 n=2 개의 다른 순열을 샘플링하여 작업당 n|?| 개의 총 예측을 생성합니다. 이는 모델이 시연 순서를 처리하는 데 있어 생길 수 있는 편향을 완화하기 위함입니다. Bober-Irizar와 Banerjee (2024)도 전치 및 회전이 추가적인 예측 후보를 생성하는 데 도움이 된다고 발견하였습니다.

**4.2 예측 결합 (앙상블, 투표 전략)**

우리는 후보 세트 {y\_i}\_{i=1}^{n \cdot |?|} 에서 최종 예측을 결정하기 위해 계층적 투표 전략을 사용합니다. 이 접근법은 최상의 후보를 점차 좁혀가는 두 단계의 투표를 포함합니다: 첫째, 각 변환 내에서 가장 빈번한 예측을 선택하고, 그 후 변환별 후보들 간의 전체 투표를 진행하여 가장 빈번한 두 개의 예측을 선정합니다. 각 단계의 세부사항은 다음과 같습니다:

1. **변환 내 투표(Intra Transformation Voting)**: 예측들을 해당 변환 t 에 따라 그룹화하고, 각 그룹에서 가장 빈번한 3개의 예측을 선택합니다. 만약 그룹 내에 3개의 고유한 예측이 존재하지 않는 경우, 다음을 통해 후보를 추가로 보완합니다:
   1. **행 기반 다수결(Row-based majority)**: 예측된 출력 그리드의 각 행에 대해, 해당 변환 그룹의 모든 예측에서 가장 빈번한 행 값을 선택합니다.
   2. **열 기반 다수결(Column-based majority)**: 마찬가지로, 예측된 출력 그리드의 각 열에 대해, 해당 변환 그룹의 모든 예측에서 가장 빈번한 열 값을 선택합니다.
2. **전역 투표(Global Voting)**: (1)에서 얻은 변환별 후보들을 사용하여 전체 투표를 진행하여 제출할 최종 상위 두 개의 빈번한 예측을 선택합니다. 동점인 경우, 신원(identity) 변환을 사용한 예측에 우선권을 부여합니다.

flowchart TB Start[예측 후보 세트] --> Split[변환별 그룹화] subgraph "1단계: 변환 내 투표" Split --> T1[변환 1 그룹] Split --> T2[변환 2 그룹] Split --> T3[변환 n 그룹] T1 --> V1{충분한\n후보가 있는가?} T2 --> V2{충분한\n후보가 있는가?} T3 --> V3{충분한\n후보가 있는가?} V1 -->|Yes| C1[상위 3개 선택] V1 -->|No| S1[보완 전략] V2 -->|Yes| C2[상위 3개 선택] V2 -->|No| S2[보완 전략] V3 -->|Yes| C3[상위 3개 선택] V3 -->|No| S3[보완 전략] subgraph "보완 방법" S1 --> R1[행 기반 다수결] S1 --> Col1[열 기반 다수결] R1 --> M1[후보 병합] Col1 --> M1 end end subgraph "2단계: 전역 투표" C1 --> GV[전체 투표] C2 --> GV C3 --> GV M1 --> GV GV --> Tie{동점?} Tie -->|Yes| ID[신원 변환\n우선 선택] Tie -->|No| Final[최종 상위 2개\n예측 선택] ID --> Final end style Start fill:#f9f,stroke:#333 style Final fill:#f96,stroke:#333 style GV fill:#bbf,stroke:#333 style T1 fill:#ddd,stroke:#333 style T2 fill:#ddd,stroke:#333 style T3 fill:#ddd,stroke:#333

**4.3 결과**

![](/assets/images/posts/344/img_12.png)

**Figure 5**: 다양한 가역적 변환과 투표 방식의 정확도: 우리의 분석 결과, 개별 변환은 일반적으로 보통 수준의 성능을 보이며 서로 비교적 유사하지만, 이들을 투표를 통해 집계하면 상당한 개선이 이루어진다는 것을 알 수 있습니다. 특히, 두 단계의 투표를 포함한 계층적 투표 전략이 평면적 투표 방식보다 우수한 성능을 발휘합니다. 우리의 계층적 방법은 오라클 수준의 성능에 근접하며, 정확한 답이 있을 때 이를 정확히 선택하는 효과성을 입증합니다. 전체 논의는 섹션 4.3에 있습니다.

증강된 추론과 투표의 영향을 분석하기 위해 다음 절제 실험을 수행했습니다:

1. **Vanilla**: 이 기본선은 증강된 추론이나 투표를 사용하지 않는 표준 추론 접근법을 따릅니다. 모델에서 작업의 2 개의 순열에 대해 두 가지 예측을 생성합니다. 이 설정은 증강된 추론 및 투표 전략의 이점을 평가하기 위한 기준점 역할을 합니다.
2. **변환된 추론 (회전/전치/뒤집기)**: 그림 5에 표시된 특정 변환 버전의 작업에서 예측이 생성될 때의 성능을 측정합니다. 이는 각 변환이 단독으로 적용될 때의 개별 효과성을 평가합니다. 참고로, Vanilla 역시 이 범주에 포함될 수 있으며, 변환은 항등 함수(identity function)로 간주됩니다.
3. **계층적 투표**: 증강 추론과 투표가 모두 포함된 우리의 전체 파이프라인입니다.
4. **평면적 투표**: 계층적 투표 전략 대신, n⋅|?| 개의 전체 예측 세트에 대해 단일 투표 라운드를 수행하여 가장 빈번한 두 개의 예측을 식별합니다.
5. **오라클 (Oracle)**: 오라클은 n⋅|?| 개의 예측 세트에 올바른 답이 있는 경우 이를 선택합니다. 오라클은 투표 절차가 완벽할 경우 가능한 최고의 성능에 대한 상한선을 제공합니다.

결과는 그림 5에 요약되어 있습니다. 그림에서 보듯이, 특정 변환 버전의 개별 성능은 일반적으로 낮으며, 전치 변환이 가장 낮은 정확도를 보였습니다. 그러나 이러한 변환들을 투표 절차를 통해 집계하면 상당한 개선이 이루어집니다. 이는 일부 작업이 변환된 버전에서 더 쉽게 해결될 수 있으며, 자기 일관성(self-consistency, 투표)을 통한 집계가 일반적으로 유익하다는 것을 시사합니다. 이는 이전 연구에서도 관찰된 바 있습니다. 또한, 평면적 투표 절차가 정확도를 향상시키기는 하지만, 우리의 계층적 투표 절차가 이를 능가합니다. 실제로, 계층적 절차는 오라클과 비교할 만한 수준으로, 계층적 집계가 높은 정확도로 올바른 답을 효과적으로 선택함을 나타냅니다.

flowchart TB subgraph "예시 상황" Input["입력된 예측들:\n A, A, B, C, B\n(실제 정답은 C)"] end subgraph "일반 투표" Input --> V1[투표 진행] V1 --> R1["결과: A 또는 B 선택\n(A: 2표, B: 2표, C: 1표)"] end subgraph "Oracle 동작" Input --> Check{예측들 중\n정답 C가\n존재하는가?} Check -->|Yes| R2["성공으로 기록\n(정답을 찾을 수 있는\n가능성이 있었음)"] Check -->|No| R3["실패로 기록\n(정답을 찾을 수 있는\n가능성이 없었음)"] end style Input fill:#f9f,stroke:#333 style R1 fill:#FFB6C1,stroke:#333 style R2 fill:#90EE90,stroke:#333 style R3 fill:#FFB6C1,stroke:#333

-----

Oracle 평가는 두 가지 중요한 역할을 합니다:

1. **모델의 잠재력 평가**

- 모델이 생성한 여러 예측들 중에 정답이 포함되어 있는지 확인
- "모델이 정답을 생각해낼 능력이 있는가?"를 검증

1. **논리적 타당성 검증**

- 모델이 생성한 예측들이 논리적으로 말이 되는지 평가
- 완전히 엉뚱한 예측만 하는 것이 아니라, 정답과 유사한 패턴을 인식하고 있는지 확인

예를 들어:

```
문제: 다음 패턴을 완성하세요
1 2 3
4 5 6
7 8 ?

모델의 예측들: [9, 0, 6, 3, 9]
정답: 9
```

이 경우 Oracle은:

- 예측 세트 안에 정답(9)이 있음을 확인
- 모델이 숫자 패턴의 논리를 이해하고 있다고 평가
- 다만 모든 예측이 정확한 것은 아니지만, 최소한 올바른 추론을 할 수 있는 능력이 있음을 검증

따라서 Oracle은 단순히 정답 유무를 체크하는 것이 아니라, 모델의 논리적 추론 능력과 패턴 인식 능력을 평가하는 도구라고 볼 수 있습니다.

-----

**5. TTT 이전의 미세 조정은 무엇인가?**

![](/assets/images/posts/344/img_13.png)

**Figure 6**: LLM 기반 합성 작업 생성: Python에서 일부 시드 작업 설명과 작업 생성 함수를 주어, 새로운 작업을 생성하는 더 많은 생성 함수를 만듭니다. 우리는 세 가지 접근법을 사용합니다: (1) 생성기만을 사용한 few-shot 프롬프트, (2) 생성기와 작업 설명을 함께 사용한 few-shot 프롬프트, (3) 두 단계 접근법: 먼저 자유 형식의 설명을 생성하고, 이를 바탕으로 더 많은 생성기를 생성합니다 (그림 9에 표시됨).

테스트 시점 훈련은 작업별 적응을 촉진하지만, 기본 모델의 역량은 최종 성능에 영향을 미칩니다. 우리는 기본 모델의 추상적 추론 능력을 미세 조정을 통해 강화하기 위해 여러 합성 학습 데이터 생성 접근법을 개발했으며, 작업 생성을 위한 자동화 및 반자동화 방법을 탐구했습니다. 본 섹션에서는 우리의 미세 조정 데이터 생성 전략을 자세히 설명하고, 서로 다른 데이터 소스와 모델 크기가 최종 성능에 미치는 영향을 분석합니다.

**5.1 미세 조정 데이터 준비** Hodel (2024)은 도메인별 언어(DSL)인 ReARC와 작업- i 를 해결하는 변환 f\_i , 그리고 ?\_{ARC}^{train} 데이터셋의 각 학습 작업에 대해 이 DSL로 구현된 데이터 생성 함수 g\_i 를 제공합니다. 이러한 함수들은 동일한 기본 변환 원리를 유지하는 새로운 입력-출력 쌍을 샘플링할 수 있게 해줍니다:

![](/assets/images/posts/344/img_14.png)

여기서 d 는 원래 작업- i 와 동일한 변환 함수 f\_i 를 사용하여 해결할 수 있는 새롭게 생성된 입력-출력 쌍을 나타냅니다. 2 생성된 예제는 f\_i(x) = y 라는 점을 확인하여 검증할 수 있습니다.

(a) **기존 생성기 사용** ReARC의 생성 함수 g 들은 이미 동일한 작업의 다른 형태를 생성함으로써 효과적인 데이터 증강 도구를 제공합니다. 우리는 이러한 학습 작업에서 많은 횟수로 코드를 실행하여 추가 샘플을 생성하고, 이러한 새로운 예제들( d ∼ eval(g\_i) )을 무작위로 학습 및 테스트 예제 집합으로 나눕니다. 이러한 증강 예제들은 이미 DSL 릴리스와 함께 제공됩니다.

(b) **LLM을 사용한 Few-shot 프롬프트** 또한, 우리는 LM(우리의 경우 GPT-4와 GPT-4-o의 앙상블)을 사용하여 새로운 작업을 생성하는 여러 접근법을 사용했습니다.

가장 간단한 접근법은 few-shot 예제를 사용하여 새로운 작업 생성기를 생성하는 것입니다:

![](/assets/images/posts/344/img_15.png)

여기서 g' 는 새로운 생성 함수이고, g\_1, …, g\_m 은 기존의 생성 함수들입니다 (그림 6에 표시됨). 우리는 기존 학습 세트에서 균일하게 m 개의 예제를 샘플링합니다. 이 과정을 여러 번 반복하여 충분한 양의 작업을 얻습니다.

우리는 생성 함수들에 작업 설명을 추가하여 설명과 생성기를 함께 생성합니다:

![](/assets/images/posts/344/img_16.png)

여기서 s\_i 는 작업 i 의 설명을 나타냅니다.

작업 설명을 얻기 위해, 우리는 10개의 학습 작업에 대해 시드 설명을 수동으로 작성했습니다. 이러한 시드 설명들은 few-shot 프롬프트를 통해 학습 및 검증 작업 설명을 생성하는 데 사용되었습니다. 작업의 다양성을 높이기 위해 계층적 필드(카테고리, 요약, 설명)가 포함된 작업 설명을 사용했습니다. 이러한 설명을 얻는 과정은 부록 D.1에 제공되어 있습니다.

작업 설명과 함수 생성을 동시에 생성하는 대신, 다음과 같은 두 단계 접근법을 추가로 적용했습니다:

![](/assets/images/posts/344/img_17.png)

이 접근법은 먼저 작업 설명 s' 를 생성하고, 그런 다음 기존 작업 쌍과 새로운 설명을 바탕으로 생성기 생성에 조건을 겁니다. 총 6426개의 생성기를 이러한 LLM 기반 접근법으로 수집했습니다. 우리는 그림 11에서 이러한 LM이 생성한 작업의 정성적 샘플을 제공합니다.

(c) **기하학적 변환** 마지막으로, 우리의 합성 작업들은 다양한 기하학적 변환을 통해 강화되었습니다. 이러한 변환은 기본 변환(회전, 반사, 임의 이동 및 크기 스케일링), 패턴 연산(임의 패칭, 타일링, 반복), 색상 순열, 여러 기본 변환을 순차적으로 적용한 복합 변환을 포함합니다. 이러한 변환은 세 가지 방식으로 적용됩니다:

![](/assets/images/posts/344/img_18.png)

변환의 전체 사양과 적용 세부 사항은 부록 B.1에 제공되어 있습니다. 이러한 변환은 작업의 변형 버전에 무작위로 30%의 확률로 적용됩니다.

**5.2 결과**

우리는 증강 데이터를 사용하여 10억, 30억 파라미터의 Llama 3.2와 80억 파라미터의 Llama 3 모델에 대해 전체 미세 조정을 수행했습니다. 형식과 학습 목표는 섹션 2.4에서 TTT에 대해 설명된 것과 동일합니다. 하이퍼파라미터 세부 사항은 부록 B.2에 제공되어 있습니다. 증강 데이터에 대해 다음과 같은 절제 실험을 수행했습니다:

1. **No FT**: 미세 조정을 거치지 않은 원래의 Llama 3 지시 조정 모델.
2. **All**: 섹션 5.1에 설명된 모든 방법 사용, 여기에는 ReARC, 규칙 기반 증강, LM 생성이 포함됩니다.
3. **No-Geom**: 모든 작업에서 기하학적 변환을 제거합니다.
4. **No-LM**: LM이 생성한 작업을 제외하고 ReARC와 규칙 기반 증강만 사용합니다.

![](/assets/images/posts/344/img_19.png)

**Figure 7**: **왼쪽**: 서로 다른 데이터 소스로 미세 조정할 때의 정확도. 모든 미세 조정된 모델이 유사한 성능을 보이지만, TTT 이후의 성능은 상당한 변동을 보입니다. 예상대로, 미세 조정 데이터에서 기하학적 변환을 제거하면 전체 데이터셋으로 훈련된 모델에 비해 성능이 저하됩니다. 놀랍게도, 미세 조정에서 LM 생성 데이터를 제외한 모델이 전체 데이터를 사용한 모델보다 더 나은 성능을 보였습니다. **오른쪽**: 서로 다른 모델 크기에 따른 성능 결과. 예상대로, 기본 미세 조정된 모델의 성능은 모델 크기가 증가할수록 향상되며, 이는 현재의 스케일링 법칙 경향과 일치합니다. 그러나 TTT 이후의 스케일링 동작은 덜 명확합니다. 예를 들어, TTT 이후 10억과 30억 모델의 최종 성능은 동일하게 나타납니다. 전체 논의는 섹션 5.2에 있습니다.

**FT 데이터가 TTT에 어떻게 영향을 미치는가?** 그림 7에서 서로 다른 미세 조정 데이터를 사용한 모델들을 비교합니다. 우리는 ReARC와 규칙 기반 증강을 사용하여 훈련된 모델이 가장 강력한 성능을 달성한다는 것을 발견했습니다. 놀랍게도, LM이 생성한 작업을 포함하면 성능이 5% 저하되었으며, 이는 현재의 LM 기반 작업 생성 방법이 Li et al. (2024)에서 사용된 것과 같은 더 정교한 필터링 메커니즘을 필요로 함을 시사합니다 (표 1에 그들의 결과를 참조하십시오). 마지막으로, FT 성능이 TTT 성능과 거의 상관관계가 없음을 발견했습니다.

**모델 크기와 TTT에서의 스케일링** 그림 7에서 서로 다른 모델 크기를 사용한 결과를 보여줍니다. 모델 크기가 증가할수록 FT 성능이 일관되게 향상되며, 80억 모델이 36%의 최고 정확도를 달성했습니다. 또한, TTT가 작은 모델들의 성능 격차를 효과적으로 줄여줌을 관찰했으며, 10억과 30억 모델은 TTT 이후 유사한 정확도를 달성했습니다.

**6. ARC 벤치마크 및 다른 시스템과의 비교**

**Table 1**: ARC 검증 세트에서의 다양한 시스템 점수: 우리의 TTT 파이프라인은 기본 모델의 성능을 지속적으로 개선합니다. 미세 조정된 모델에 TTT를 적용했을 때 47.1%의 정확도를 달성했고, Li et al. (2024)의 BARC 모델에 적용했을 때는 53%를 기록하여 순수 LM 기반 접근법 중 최고 성능을 달성했습니다. 프로그램 생성 기반 모델과 우리의 방법을 앙상블한 결과, 61.875% 의 성능을 기록하여 평균 인간 성능(60.2%)에 근접했습니다.

![](/assets/images/posts/344/img_20.png)

우리는 80개의 작업에서 개발 실험을 수행한 후, 전체 ARC 공개 평가 세트에서 우리의 시스템을 기존 접근법과 비교한 포괄적인 결과를 제시합니다. 우리의 분석은 세 가지 주요 측면에 초점을 맞추고 있습니다: TTT 방법론의 영향, 기존 방법과의 결합의 이점, 그리고 완전히 신경망 기반과 프로그램 생성 방법 간의 차이점.

**테스트 시점 훈련의 영향** 우리는 기본 미세 조정된 모델(섹션 5에서 LM 데이터 없이 미세 조정된 80억 모델)에 우리의 TTT와 추론 절차(섹션 3 및 4에 설명)를 적용했습니다. TTT는 정확도를 39.25% 에서 47.125% 로 향상시켜 기존의 종단간 신경망 모델 결과를 초과했습니다.

**기존 방법과의 통합** Li et al. (2024)의 동시 연구는 BARC를 도입하여 신경망과 프로그램 생성 접근법을 결합하여 54.375% 의 정확도를 달성했습니다—이는 이전에 공개된 최고 성과입니다. 그들의 완전한 신경망 접근법은 우리의 시스템과 유사점을 공유하지만, 우리의 TTT와 추론 파이프라인에는 성능을 향상시키는 여러 추가 요소가 있습니다. 특히, 우리의 테스트 시점 훈련은 작업별 LoRA와 더 많은 증강 세트를 포함하고 있으며, 우리의 예측 파이프라인은 가역 변환 하에서 증강된 추론과 계층적 자기 일관성 투표 체계를 포함합니다. 우리는 우리의 TTT 파이프라인을 BARC의 완전한 신경망 모델에 적용하여 53% 의 정확도를 달성하였으며, 이는 그들의 원래 TTT 방법에 비해 35% 의 개선입니다.

이러한 결과를 바탕으로, 우리는 BARC의 구성 요소와 우리의 접근법을 다양한 조합으로 탐구했습니다:

- 우리의 TTT 파이프라인과 신경망 모델을 BARC의 생성기와 결합하여 정확도를 58.5% 까지 올렸습니다.
- 우리의 TTT 파이프라인을 BARC의 신경망 모델과 생성기와 결합하여 정확도를 61.875% 까지 올렸습니다. 이 최종 구성은 ARC 공개 평가 세트에서 새로운 최고 성능을 달성했으며, 평균 인간 성능(LeGris et al., 2024b)과 일치합니다. 이는 상당한 발전을 나타내지만, 최고 인간 성능인 97.8% 에는 여전히 큰 격차가 있어 더 나은 개선의 여지가 있음을 시사합니다.

**프로그램 생성과 종단간 모델링 비교** Li et al. (2024)는 프로그램 생성과 완전한 신경망 기반 ARC 예측기가 동일한 작업으로 훈련되더라도 상호 보완적임을 발견했습니다. 그들의 종단간 신경망 모델은 프로그램 생성 모델이 해결한 작업의 42.2% 만을 해결할 수 있었습니다. 하지만 우리는 우리의 TTT 파이프라인을 갖춘 BARC의 미세 조정된 완전한 신경망 모델이 프로그램 생성 모델이 해결한 작업의 73.5% 를 해결한다는 것을 발견했습니다. 이는 우리의 TTT 파이프라인이 신경망 모델의 체계적인 추론 패턴을 학습하는 능력을 프로그램 생성 모델이 포착한 것과 유사하게 크게 향상시킴을 시사합니다.

**7. 결론** 이 연구에서 우리는 테스트 시점 훈련(TTT)을 조사하고, 이를 통해 ARC 데이터셋에서 언어 모델의 성능을 크게 향상시킬 수 있음을 증명했습니다. 우리는 작업별 LoRA 어댑터 학습과 기하학적 변환을 사용한 증강된 테스트 시점 데이터셋 생성이 필수적이라는 것을 발견했습니다. 또한, 가역 변환을 사용하여 여러 예측을 생성하고 자기 일관성을 사용하여 최상의 후보를 선택하는 증강된 추론 파이프라인을 개발했습니다. 전체 파이프라인은 여러 테스트 시점 계산 방법을 적용하며, 각 구성 요소는 긍정적인 기여를 합니다. 이는 테스트 시점 계산이 언어 모델 성능을 개선할 수 있을 뿐만 아니라, 서로 다른 테스트 시점 방법들이 상호 보완될 수 있음을 시사합니다. 우리의 TTT 파이프라인은 기존 방법(BARC)과 결합하여 ARC 공개 세트에서 최고 성능을 달성했으며, 평균 인간 성능에 근접한 성과를 보였습니다. 우리의 연구 결과는 테스트 시점 방법이 차세대 언어 모델 발전에 중요한 역할을 할 수 있음을 시사합니다.

**제한 사항**

**평가 프레임워크** ARC 챌린지는 공개 및 비공개 리더보드를 유지하며, 비공개 평가는 숨겨진 작업에서 수행됩니다. 우리의 TTT 파이프라인은 공개 벤치마크에서 유망한 결과를 보였지만, 하드웨어 제약(80억 모델에 대해 A100 GPU로 100개의 작업을 12시간 내 처리)으로 인해 공식 리더보드 제출은 현재 불가능합니다. 공식 리더보드는 P100 또는 2×T4 NVIDIA GPU에서 12시간 내 완료를 요구합니다. 개발 중 우리는 80개의 작업으로 검증을 수행하였으며, 잠재적인 최적화 편향의 가능성을 인정합니다. 표 3에 자세히 설명된 기하학적 증강은 TTT 단계에서 선택되었습니다. 표준 하이퍼파라미터(학습률, 배치 크기, 에포크)는 80개의 검증 작업을 포함한 개발 세트를 사용하여 최적화되었습니다.

**실험 재현성** 우리의 실험의 계산 요구 사항을 고려할 때, 이 사전 인쇄본은 포괄적인 표준 오차 분석 없이 결과를 보고합니다. 우리의 예비 관찰 결과는 실행 간 변동이 최소임을 나타내며, 최종 버전에서 상세한 통계 분석을 포함할 계획입니다.

**데이터 누출** 기본 Llama-3가 공개 검증 세트에서 매우 낮은 성능을 보이더라도, 데이터셋이 다양한 플랫폼(GitHub, Kaggle)에 공개되어 있기 때문에 이러한 모델들이 사전 학습 중에 이러한 예제를 접했을 가능성이 있습니다.

**감사의 말** 매개변수 효율적 학습에 대한 유익한 논의를 제공한 Aniruddha Nrusimha와 논문의 초기 초안에 대한 피드백을 제공한 Jyo Pari에게 감사드립니다. 이 연구는 미국 국립 과학 재단(NSF)의 IIS-2212310, IIS-2238240, CCF-2217064 지원으로 수행되었습니다.

[2411.07279v1.pdf

5.72MB](./file/2411.07279v1.pdf)
