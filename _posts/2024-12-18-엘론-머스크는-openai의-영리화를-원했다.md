---
title: "엘론 머스크는 OpenAI의 영리화를 원했다"
date: 2024-12-18 13:11:52
---

<https://openai.com/index/elon-musk-wanted-an-openai-for-profit/>

### 사건의 타임라인

- **2015년 11월**: OpenAI는 비영리 단체로 시작되었으나, 엘론이 이 방식에 의문을 제기함.
- **2015년 12월**: OpenAI가 공식적으로 발표됨.
- **2017년 초**: AGI(인공지능 일반) 개발을 위한 컴퓨팅 비용이 수십억 달러에 이를 것이라는 연구 결과를 통해 깨달음을 얻음.
- **2017년 여름**: OpenAI의 미션을 진전시키기 위해 엘론과 영리화가 필요하다는 데 합의함.
- **2017년 가을**: 엘론은 영리 회사에서 최대 지분, 절대적인 통제권, 그리고 CEO 자리를 요구함.
- **2017년 9월**: 엘론이 "Open Artificial Intelligence Technologies, Inc."라는 공익 기업을 설립함.
- **2017년 9월**: OpenAI와 그 기술에 대한 단독 통제권을 부여하는 것은 미션에 반하므로, 엘론의 조건을 거부함.
- **2018년 1월**: 엘론은 OpenAI가 테슬라와 합병하지 않으면 실패할 것이라고 주장함.
- **2018년 2월**: 엘론이 OpenAI의 공동 의장직에서 사임함.
- **2018년 12월**: 엘론은 "매년 수십억 달러를 즉시 조달하든가 아니면 그만두라"고 요구함.
- **2019년 3월**: OpenAI는 비영리 구조 내에서 수익 제한 형태의 OpenAI LP를 발표함.
- **2023년 3월**: 엘론이 OpenAI 경쟁 회사인 xAI를 설립함.

엘론 머스크의 최신 법적 소송은 1년 내 네 번째 시도로, 자신의 주장을 재구성하려는 시도이다. 그러나 그의 말과 행동은 스스로를 대변한다. 2017년, 엘론은 OpenAI의 새로운 구조로 영리 기업을 원했을 뿐만 아니라 이를 실제로 설립했다. 그러나 다수 지분과 전권을 얻지 못하자 그는 떠났고, 우리가 실패할 것이라고 말했다. 이제 OpenAI가 선도적인 AI 연구소가 되고, 엘론이 경쟁 AI 회사를 운영하는 상황에서, 그는 우리가 우리의 미션을 효과적으로 추구하지 못하도록 법원에 요청하고 있다.

![](https://blog.kakaocdn.net/dna/kSJKZ/btsLlKrsGe6/AAAAAAAAAAAAAAAAAAAAAGUmLuJKiDutOZslOiDmFmxi5B9Qd4abmdV3RRnUexHI/img.webp?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=LjCRg7W5ht9ikfJ3PuSLb7QVhHs%3D)

**엘론 머스크가 2017년 9월 15일에 설립한 공익 법인은 OpenAI의 미래 구조로 제안된 형태였다.**

**"소송으로 AGI를 달성할 수는 없습니다."**  
우리는 엘론의 업적을 깊이 존경하며, OpenAI의 초기 기여에 대해 감사하고 있습니다. 하지만 그는 법정이 아니라 시장에서 경쟁해야 합니다. 미국이 AI 분야에서 글로벌 리더의 위치를 유지하는 것은 매우 중요합니다. 우리의 미션은 AGI(인공지능 일반)가 인류 전체에 혜택을 주도록 보장하는 것이며, 우리는 앞으로도 미션 중심의 조직으로 남을 것입니다. 엘론 또한 이 목표를 공유하며, 자신의 성공을 이끈 혁신과 자유 시장 경쟁의 가치를 지켜나가길 바랍니다.

**2015년 11월: OpenAI는 비영리 단체로 시작되었으며, 엘론은 이에 의문을 제기했다.**  
2015년 11월 20일, 엘론은 다음과 같이 말했습니다.  
"구조가 최적화된 것 같지 않습니다…. 아마도 비영리 단체와 병렬로 운영되는 일반 C 법인이 더 나을 것입니다."  
우리는 당시 비영리 구조가 올바른 선택이라고 판단했지만, 이후 우리의 미션을 위해 필요한 자본을 유치하려면 구조를 진화시켜야 한다는 점을 깨닫게 되었습니다.

```
Re: AI 문서
––––– 전달된 메시지 –––––
보낸 사람: Elon Musk <삭제됨>
날짜: 2015년 11월 20일 금요일 오후 12:29
받는 사람: Sam Altman <삭제됨>
저는 이것이 YC로부터 독립적이어야 한다고 생각합니다(하지만 YC의 지원을 받아야 합니다). 자회사 같은 느낌이 들지는 않을 겁니다.

또한 구조가 최적이지 않은 듯합니다. 특히 YC 주식과 비영리 단체의 급여는 인센티브의 정렬을 흐릿하게 만듭니다. 아마도 표준 C 법인과 평행한 비영리 단체를 갖는 것이 더 나을 것입니다.

2015년 11월 20일 오전 11시 48분, Sam Altman <redacted>이 다음과 같이 썼습니다.

엘론–

계획은 당신, 나, 그리고 일리아를 델라웨어 비영리 단체인 YC AI의 이사회에 앉히는 것입니다. 또한 이사회의 다수결 투표로 두 명의 외부인을 선출할 계획이라고 밝힐 것입니다.

인류의 안전을 위협할 수 있는 모든 기술은 공개하려면 이사회의 동의를 받아야 한다는 내용을 규정에 명시하고, 연구자들의 고용 계약서에 이를 명시할 것입니다.

높은 수준에서 보면, 그게 당신에게 효과가 있나요?

저희 GC <삭제됨> 에게 참조로 보냅니다 . 사무실에 그 사람과 함께 세부 사항을 작업할 수 있는 사람이 있나요?

샘
```

**2015년 12월: OpenAI 공개 발표**  
OpenAI가 세상에 처음 소개되었습니다.

**2017년 초: AGI 개발을 위해 수십억 달러의 컴퓨팅 비용이 필요하다는 점을 깨닫다**  
2017년, 경쟁적인 비디오 게임 **Dota**를 위한 AI 개발에서 진전을 이루며, 초기 예상보다 훨씬 더 많은 컴퓨팅 리소스가 필요하다는 사실을 발견했습니다.

2017년 6월 13일, 엘론은 이메일에 이렇게 답변했습니다:  
"좋습니다. 컴퓨팅 파워가 제약이 되지 않도록 가장 저렴한 방법을 찾아봅시다."

2017년 7월 12일, 일리야(Ilya)는 다음과 같이 강조했습니다:  
"매년 하드웨어 지출을 기하급수적으로 늘려야 하지만, AGI는 궁극적으로 100억 달러 이하의 하드웨어로 구축될 수 있다는 이유가 있습니다."

```
Re: 후속 생각
보낸 사람: Elon Musk <삭제됨>
날짜: 2016년 2월 19일 금요일 오전 12시 5분
받는 사람: Ilya Sutskever <삭제됨>
참조: Greg Brockman <삭제됨>, Sam Altman <삭제됨>
솔직히 말해서, 제가 놀란 건 AI 커뮤니티가 개념을 파악하는 데 이렇게 오랜 시간이 걸린다는 것입니다. 그렇게 어려운 일은 아닌 것 같습니다. 많은 수의 딥 넷을 고수준으로 연결하는 것이 올바른 접근 방식인 것 같거나 적어도 올바른 접근 방식의 핵심 부분인 것 같습니다. █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █

DeepMind가 딥마인드를 만들 확률은 매년 증가합니다. 2~3년 안에 50%를 넘지 못할 수도 있지만, 10%는 넘을 가능성이 큽니다. 그들의 리소스를 고려하면 미친 짓은 아닌 것 같습니다.

어쨌든 저는 경쟁자를 과소평가하는 것보다 과대평가하는 것이 훨씬 낫다는 것을 알게 되었습니다.

이것은 우리가 서둘러 나가서 약한 인재를 고용해야 한다는 것을 의미하지 않습니다. 저는 그렇게 해서는 아무런 좋은 성과도 얻을 수 없다는 데 동의합니다. 우리가 해야 할 일은 세계 최고의 인재를 찾기 위한 노력을 배가하고, 그들을 데려오기 위해 필요한 모든 것을 하고, 회사에 긴박감을 불어넣는 것입니다.

OpenAI가 앞으로 6~9개월 안에 의미 있는 성과를 거두어 우리가 진짜라는 것을 보여주는 것이 중요할 것입니다. 엄청난 돌파구가 될 필요는 없지만 전 세계의 핵심 인재가 주목하고 주목하기에 충분할 것입니다.

█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​

보낸 사람: Ilya Sutskever <삭제됨>
날짜: 2016년 2월 19일 금요일 오전 10시 28분
받는 사람: Elon Musk <삭제됨>
참조: Greg Brockman <삭제됨>, Sam Altman <삭제됨>
몇 가지 요점:

"개념"을 해결하면 AI를 얻을 수 있다는 것은 아닙니다. 해결해야 할 다른 문제로는 비지도 학습, 전이 학습, 평생 학습이 있습니다. 우리는 현재 언어에서도 꽤 형편이 나쁩니다. 이러한 문제가 앞으로 몇 년 안에 상당한 진전을 보지 못할 것이라는 것은 아니지만, 우리와 완전한 인간 수준의 AI 사이에 단 하나의 문제만 있는 것은 아닙니다.
우리는 핵심 아이디어가 부족해서 오늘날 AI를 만들 수 없습니다(컴퓨터도 너무 느릴 수 있지만, 우리는 알 수 없습니다). 강력한 아이디어는 최고의 사람들이 만들어냅니다. 대규모 클러스터는 도움이 되고, 얻을 만한 가치가 있지만, 덜 중요한 역할을 합니다.
우리는 앞으로 6~9개월 안에 관례적으로 의미 있는 결과를 얻을 수 있을 것입니다. 우리가 이미 가지고 있는 사람들이 매우 훌륭하기 때문입니다. 현장을 바꿀 수 있는 결과를 얻는 것은 더 어렵고 위험하며 더 오래 걸릴 것입니다. 하지만 우리는 그에 대한 비합리적이지 않은 계획도 가지고 있습니다.
```

```
2주마다 업데이트
3개의 이메일
보낸 사람: Ilya Sutskever <삭제됨>
날짜: 2017년 6월 12일 월요일 오후 10시 39분
받는 사람: Greg Brockman <삭제됨>, <삭제됨>, Elon Musk <삭제됨>
이것은 우리의 2주마다 업데이트되는 첫 번째입니다. 목표는 여러분에게 최신 소식을 전하고 여러분의 방문을 더 잘 활용할 수 있도록 돕는 것입니다.

계산:

컴퓨팅은 두 가지 방식으로 사용됩니다. 대규모 실험을 빠르게 실행하는 데 사용되거나, 많은 실험을 병렬로 실행하는 데 사용됩니다.
95%의 진전은 대규모 실험을 빠르게 실행하는 능력에서 비롯됩니다. 많은 실험을 실행하는 유용성은 훨씬 덜 유용합니다.
예전에는 대규모 클러스터를 사용하면 더 많은 실험을 실행하는 데 도움이 되었지만, 단일 대규모 실험을 빠르게 실행하는 데는 도움이 되지 않았습니다.
이런 이유로 학술 연구실은 구글과 경쟁할 수 있었습니다. 구글의 유일한 장점은 많은 실험을 수행할 수 있는 능력이었기 때문입니다. 이는 큰 장점이 아닙니다.
최근, 100개의 GPU와 100개의 CPU를 결합하여 단일 머신에서 가능한 것보다 100배 더 큰 실험을 실행하면서도 비슷한 시간이 소요되는 것이 가능해졌습니다. 이는 여러 그룹의 작업 덕분에 가능해졌습니다. 그 결과, 경쟁력을 갖추는 데 필요한 최소 클러스터는 이전보다 10~100배 더 커졌습니다.
현재 모든 Dota 실험은 1000개 이상의 코어를 사용하며, 이는 작은 1대1 변형과 매우 작은 신경망 정책에만 적용됩니다. 1대1 변형에서 이기기 위해서는 더 많은 컴퓨팅이 필요합니다. 전체 5대5 게임에서 이기기 위해서는 더 적은 실험을 실행해야 하며, 각 실험은 최소한 10배 이상 더 큽니다(아마 더 많을 수도 있습니다!).
TLDR: 중요한 것은 실험의 규모와 속도입니다. 예전에는 큰 클러스터로는 누구도 더 큰 실험을 빠르게 실행할 수 없었습니다. 오늘날 큰 클러스터를 사용하면 100배 더 빠르게 큰 실험을 실행할 수 있습니다.
이론적으로라도 프로젝트를 완수하려면 다음 1~2개월 안에 GPU 수를 10배로 늘려야 합니다(CPU는 충분합니다). 구체적인 내용은 대면 회의에서 논의하겠습니다.
도타 2:

우리는 1달 안에 1대1 버전의 게임을 풀 것입니다 . 게임 팬들은 1대1에 대해 상당히 신경을 씁니다.
이제 *단일 실험*이 수천 개의 코어를 사용하는 지점에 도달했으며, 더 많은 분산 컴퓨팅을 추가하면 성능이 향상됩니다.
우리 봇이 꽤 똑똑한 짓을 하는 멋진 영상을 소개합니다: https://www.youtube.com/watch?v=Y-vxbREX5ck&feature=youtu.be&t=99.
새로운 게임에 대한 빠른 학습:

인프라 공사가 진행 중입니다.
우리는 여러 가지 기준을 구현했습니다
근본적으로, 우리는 현재 원하는 위치에 있지 않으며, 이를 바로잡기 위한 조치를 취하고 있습니다.
로봇공학:

현재 상태: HER 알고리즘( https://www.youtube.com/watch?v=Dz_HuzgMzxo )은 이전에는 해결 불가능했던 많은 저차원 로봇 작업을 매우 빠르게 해결하는 법을 배울 수 있습니다. 명확하지 않고 간단하며 효과적입니다.
6개월 안에 우리는 다음 중 하나 이상을 달성할 것입니다: 한 손으로 루빅 큐브 맞추기, 펜 돌리기( https://www.youtube.com/watch?v=dDavyRnEPrI ), 중국 공 돌리기( https://www.youtube.com/watch?v=M9N1duIl4Fc ) HER 알고리즘과 sim2real 방식[예: https://blog.openai.com/spam-detection-in-the-physical-world/ ]을 사용합니다.
위의 내용은 로봇 손에 배포됩니다: [Google Drive 링크] [이 비디오는 알고리즘 제어가 아닌 인간이 제어합니다. 비디오를 보려면 OpenAI 계정에 로그인해야 합니다].
AGI의 핵심 경로로서의 셀프 플레이:

다중 에이전트 환경에서의 셀프 플레이는 마법과도 같습니다. 에이전트를 환경에 배치하면 아무리 똑똑하든(또는 똑똑하지 않든) 환경은 에이전트에게 정확한 수준의 도전을 제공하며, 이는 경쟁자를 따돌려야만 극복할 수 있습니다. 예를 들어, 어린이 그룹이 있다면 서로의 회사가 도전적일 것입니다. 비슷한 지능을 가진 초지능 집단의 경우도 마찬가지입니다. 따라서 셀프 플레이에 대한 "해결책"은 제한 없이 점점 더 지능적으로 되는 것입니다.
셀프 플레이는 우리가 "무에서 유를" 얻을 수 있게 해줍니다. 경쟁 게임의 규칙은 간단할 수 있지만, 이 게임을 플레이하기 위한 최상의 전략은 엄청나게 복잡할 수 있습니다. [동기 부여 예: https://www.youtube.com/watch?v=u2T77mQmJYI ].
레슬링과 같은 경쟁적인 싸움을 통해 매우 뛰어난 손재주를 개발하기 위해 시뮬레이션에서 에이전트를 훈련합니다. 우리가 투쟁하도록 훈련시킨 개미 모양의 로봇의 비디오는 다음과 같습니다: <삭제됨>
셀프 플레이에 대한 현재 작업: 에이전트가 언어를 개발하는 법을 배우게 하기 [ https://blog.openai.com/learning-to-cooperate-compete-and-communicate/ 의 gif ]. 에이전트는 "일"을 하고 있지만 아직 진행 중인 작업입니다.
우리는 몇 가지 더 멋진 작은 프로젝트를 가지고 있습니다. 상당한 결과를 낼 때마다 업데이트를 발표할 것입니다.

보낸 사람: Elon Musk <삭제됨>
날짜: 2017년 6월 12일 월요일 오후 10시 52분
받는 사람: Ilya Sutskever <삭제됨>
참조: Greg Brockman <삭제됨>, <삭제됨>
고맙습니다. 정말 좋은 업데이트네요.

보낸 사람: Elon Musk <삭제됨>
날짜: 2017년 6월 13일 화요일 오전 10:24
받는 사람: Ilya Sutskever <삭제됨>
참조: Greg Brockman <삭제됨>, <삭제됨>
좋습니다. 컴퓨팅 파워가 제약이 되지 않도록 보장하는 가장 저렴한 방법을 알아봅시다…
```

```
AGI 구축 사업
보낸 사람: Ilya Sutskever <삭제됨>
날짜: 수요일, 7월 12, 2017 오후 1:36
받는 사람: Elon Musk <삭제됨>, Greg Brockman <삭제됨>
우리는 보통 똑똑한 사람들이 오랫동안 실패로 끝나기 때문에 문제가 어렵다고 판단합니다. AI에 대해서도 이것이 사실이라고 생각하기 쉽습니다. 그러나 지난 5년간의 진전은 AI에 대한 가장 초기의 가장 단순한 아이디어인 신경망이 항상 옳았으며, 이를 작동시키려면 최신 하드웨어가 필요하다는 것을 보여주었습니다.

역사적으로 AI 혁신은 꾸준히 7~10일 동안 훈련하는 모델에서 발생했습니다. 즉, 하드웨어가 잠재적 AI 혁신의 표면을 정의한다는 의미입니다. 이는 AI보다 인간 심리에 대한 진술입니다. 실험에 이보다 더 오랜 시간이 걸리면 모든 상태를 머릿속에 두고 반복하고 개선하기 어렵습니다. 실험이 더 짧으면 더 큰 모델을 사용하게 됩니다.

AI의 발전이 하드웨어 게임인 것은 아니고, 물리학이 입자 가속기 게임인 것도 아닙니다. 하지만 컴퓨터가 너무 느리다면 아무리 똑똑해도 AGI로 이어지지 않습니다. 입자 가속기가 너무 작다면 우주가 어떻게 돌아가는지 알아낼 기회가 없는 것과 마찬가지입니다. 충분히 빠른 컴퓨터는 필수적인 요소이며, 과거의 모든 실패는 AGI에 비해 컴퓨터가 너무 느려서 발생했을 수 있습니다.

아주 최근까지는 많은 GPU를 함께 사용하여 더 빠른 실험을 실행할 방법이 없었기 때문에 학계는 산업과 동일한 "효과적인 컴퓨팅"을 사용했습니다. 하지만 올해 초에 Google은 분류기의 아키텍처를 최적화하는 데 일반적인 것보다 두 배 더 많은 컴퓨팅을 사용했는데, 이는 일반적으로 많은 연구자의 시간이 필요합니다. 그리고 몇 달 전 Facebook은 고대역폭 상호 연결을 갖춘 특수 구성 클러스터가 제공된 경우 최대 256개 GPU로 선형에 가까운 속도로 대규모 ImageNet 모델을 훈련하는 방법을 보여주는 논문을 발표했습니다.

작년에 Google Brain은 다른 누구보다 10배나 더 많은 GPU를 보유하고 있어서 인상적인 성과를 냈습니다. Brain은 약 100k GPU를 보유하고 있고, FAIR은 약 15~20k GPU를 보유하고 있으며, DeepMind는 질문하는 연구자 한 명당 50개를 할당하고 AlphaGo를 위해 Brain에서 5k GPU를 임대했습니다. 사람들이 Google Brain에서 신경망을 실행하면 DeepMind의 모든 사람의 할당량이 소모되는 듯합니다.

우리는 여전히 AGI를 구축하는 데 필요한 몇 가지 핵심 아이디어를 놓치고 있습니다. 어떻게 하면 "사물 A"에 대한 시스템의 이해를 사용하여 "사물 B"를 학습할 수 있을까요(예: 시스템에 세는 법, 곱하는 법, 단어 문제를 푸는 법을 가르칠 수 있을까요?) 호기심 많은 시스템을 어떻게 구축할까요? 어떻게 하면 시스템이 모든 유형의 현상의 근본적인 원인을 발견하도록 훈련하여 과학자처럼 행동할 수 있을까요? 어떻게 하면 시스템이 정확히 훈련되지 않은 새로운 상황(예: 익숙한 개념을 익숙하지 않은 상황에 적용하도록 요청받는 경우)에 적응하는 시스템을 구축할 수 있을까요? 하지만 7~10일 안에 관련 실험을 실행할 수 있는 충분한 하드웨어가 제공된다면, 물리학자들이 충분히 큰 입자 가속기만 있다면 우주의 작동 방식을 빠르게 알아낼 수 있었던 것처럼, 역사는 올바른 알고리즘을 찾을 수 있음을 보여줍니다.

딥 러닝 하드웨어가 향후 4~5년 동안 매년 10배씩 빨라질 것이라는 믿을 만한 이유가 있습니다. 세상은 무어의 법칙의 비교적 여유로운 속도에 익숙해져 있으며, 이 하드웨어 가속이 가져올 성능의 급격한 변화에 대비하지 못하고 있습니다. 이러한 속도 향상은 더 작은 트랜지스터나 더 빠른 클록 주기 때문이 아니라 뇌와 마찬가지로 신경망이 본질적으로 병렬화될 수 있고, 이를 활용하기 위해 새로운 고도로 병렬화된 하드웨어가 구축되고 있기 때문입니다.

다음 3년 안에 로봇공학은 완전히 해결되어야 하고, AI는 오랫동안 입증되지 않은 정리를 해결해야 하며, AI가 프로그래밍 대회에서 꾸준히 우승해야 하며, 설득력 있는 챗봇이 있어야 합니다(튜링 테스트에 통과하는 사람은 아무도 없어야 합니다). 4년 안에 각각의 야간 실험은 적절한 알고리즘이 주어지면 AGI에 깨어날 수 있는 실제 가능성이 있을 만큼 많은 컴퓨팅 용량을 사용할 수 있을 것입니다. 그리고 알고리즘을 알아내는 것은 경쟁적인 멀티에이전트 시뮬레이션에서 이 컴퓨팅을 실험한 지 2~4년 후에 실제로 이루어질 것입니다.

안전한 AGI를 구축하는 사업을 하려면 OpenAI가 다음 사항을 갖춰야 합니다.

매년 최고의 AI 결과를 얻습니다. 특히 하드웨어가 기하급수적으로 향상됨에 따라 극적으로 더 나은 결과를 얻을 것입니다. DOTA와 루빅 큐브 프로젝트는 현재 수준의 컴퓨팅에 대해 인상적인 결과를 얻을 것입니다. 내년 프로젝트는 훨씬 더 극단적일 것이고, 현실적인 것은 주로 어떤 컴퓨팅에 액세스할 수 있는지에 달려 있습니다.
GPU 클러스터를 600개 GPU에서 5000개 GPU로 최대한 빨리 늘리세요. 상한으로, 이를 위해서는 내년에 1,200만 달러의 자본 지출과 5~600만 달러의 운영 비용이 필요합니다. 매년 하드웨어 지출을 기하급수적으로 늘려야 하지만, AGI는 궁극적으로 100억 달러 미만의 하드웨어로 구축할 수 있다고 믿을 만한 이유가 있습니다.
직원 수를 늘립니다. 55명(2017년 7월)에서 80명(2018년 1월)으로, 120명(2019년 1월)으로, 200명(2020년 1월)으로 늘립니다. 우리는 현재 팀을 구성하는 방법을 배웠고, 지금은 아이디어를 시도하는 똑똑한 사람들의 수로 인해 병목 현상이 발생합니다.
압도적인 하드웨어 우위를 확보하세요. <삭제됨> 이 2년 안에 만들 수 있다고 말한 4칩 카드는 사실상 TPU 3.0이며(충분한 양이 주어진다면) 컴퓨팅 측면에서 Google과 거의 동등한 위치에 설 수 있을 것입니다. Cerebras 설계는 이 둘보다 훨씬 앞서 있으며, 만약 이것이 진짜라면 이것에 대한 독점적 접근 권한을 갖는다면 경쟁에서 훨씬 앞서 나갈 수 있을 것입니다. 더 많은 실사를 거친다면 이를 수행하는 방법에 대한 구조적 아이디어가 있으며, 전화로 논의하는 것이 가장 좋습니다.
2/3/4는 궁극적으로 많은 자본이 필요할 것입니다. 자금을 확보할 수 있다면 AGI가 탄생하는 초기 조건을 설정할 수 있는 실질적인 기회가 있습니다. 자금 지원 필요성이 증가하면 결과의 규모도 증가합니다. 관련 자금을 확보하기 위한 옵션을 논의해야 합니다. 이는 우리의 직접적인 통제 밖에 있는 가장 큰 부분이기 때문입니다.

이번 주 진행 상황:

우리는 1대1 테스트 플레이어 중 최고를 이겼습니다(그는 북미 1대1에서 30위 안에 들었고, 1대1 플레이어 중 최고를 30% 정도 이겼습니다). 하지만 봇은 이상하게 플레이함으로써 악용될 수도 있습니다. 우리는 이런 악용을 이해하고 단속하기 위해 노력하고 있습니다.
토요일에 방영된 첫 경기로, 최고 테스트 플레이어를 이긴 첫 경기를 소개합니다: https://www.youtube.com/watch?v=FBoUHay7XBI&feature=youtu.be&t=345
훈련을 하루 더 할수록 봇은 더 강해지고 악용하기가 더 어려워집니다.
로봇이 루빅큐브를 푸는 데 한 걸음 더 다가갔다.
인간이 원격으로 조종하는 개선된 큐브 시뮬레이션: <삭제됨 >.
적대적 사례에 대한 우리의 방어는 ImageNet에서 효과를 발휘하기 시작했습니다.
우리는 8월 말까지 적대적 예제 문제를 완전히 해결할 것입니다.
█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​

█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​

█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █
```

## 2017년 여름: 우리와 Elon은 영리 목적의 사업이 OpenAI의 사명을 발전시키는 다음 단계라는 데 동의했습니다.

2017년 7월 13일, Greg는 Elon과 OpenAI의 연락 담당자로 활동하던 Shivon Zilis에게 그날 Elon과의 회의에서 하드웨어 스타트업과 합병하는 아이디어를 제안했던 내용을 요약한 메모를 보냈습니다. "구조에 대한 이야기로 바뀌었습니다(그는 처음에는 비영리 단체가 확실히 옳았지만 지금은 그렇지 않을 수도 있다고 말했습니다. ilya와 저는 여러 가지 이유로 이에 동의합니다)."

![](https://blog.kakaocdn.net/dna/cRu2uW/btsLlZ9PfhG/AAAAAAAAAAAAAAAAAAAAAIHhenFazx-YgMhDzOpJTmneNVTLTaHMVYhnC6rsl9_V/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=Z3lZOFHcNguROzuV2NV95KTBgwo%3D)

2017년 7월 21일, 엘론은 중국이 2020년까지 AI 연구 시설에서 미국과 맞먹고, 2030년까지 AI에서 세계적 리더가 되어 농업과 제조업, 국토 안보와 감시 노력을 지원하겠다는 계획에 대한 기사를 전달했습니다. 엘론은 "그들은 우리가 개발한 것을 얻기 위해 무엇이든 할 것입니다. 아마도 진로를 바꿀 또 다른 이유가 될 것입니다."라고 말했습니다.

그렉은 동의하며 2018년부터는 "AI 연구 + 하드웨어 수익"이 경로가 되어야 한다고 말했습니다. 엘론은 "토요일이나 일요일에 이야기합시다. 제가 당신에게 보여주고 싶은 임시 게임 플랜이 있습니다."라고 답했습니다.

```
베이징, 2030년까지 AI를 중국에서 만들고 싶어 - NYTimes.com
보낸 사람: Elon Musk <삭제됨>
날짜: 2017년 7월 21일 금요일 오전 3시 34분
받는 사람: Greg Brockman <삭제됨>, Ilya Sutskever <삭제됨>
그들은 우리가 개발한 것을 얻기 위해 무엇이든 할 것입니다. 아마도 진로를 바꾸는 또 다른 이유가 될 것입니다.

[뉴스기사 바로가기]

보낸 사람: Greg Brockman <삭제됨>
날짜: 2017년 7월 21일 금요일 오후 1시 18분
받는 사람: Elon Musk <삭제됨>
참조: Ilya Sutskever <삭제됨>
100% 동의합니다. 우리는 경로가 다음과 같아야 한다고 생각합니다.

AI 연구 비영리 단체(2017년 말까지)
AI 연구 + 하드웨어 수익화(2018년 시작)
정부 프로젝트 (언제: ??)
█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █

-gdb

보낸 사람: Elon Musk <삭제됨>
날짜: 2017년 7월 21일 금요일 오후 1시 18분
받는 사람: Greg Brockman <삭제됨>
참조: Ilya Sutskever <삭제됨>, <삭제됨>
토요일이나 일요일에 이야기합시다. 저는 당신에게 실행하고 싶은 임시 게임 계획이 있습니다.
```

2017년 8월 11일, 우리 AI는 Dota 1v1에서 세계 최고의 플레이어를 이겼습니다. 그날 밤, Elon은 "OpenAI의 다음 단계를 밟을 때가 되었습니다. 이것이 트리거 이벤트입니다."라고 말했습니다.

```
내일 오후
보낸 사람: Elon Musk <삭제됨>
날짜: 2017년 8월 11일 금요일 오후 9시 17분
받는 사람: Greg Brockman <삭제됨>, Ilya Sutskever <삭제됨>, Sam Altman <삭제됨>
참조: <삭제됨>, Shivon Zilis <삭제됨>
내일 오후 에 만나 거나 컨퍼런스 전화 를 할 수 있나요 ?​​​​​​​​​​​​​​​​​​​​​

OpenAI의 다음 단계를 만들 시간입니다. 이것은 트리거 이벤트입니다.
```

## 2017년 가을: 일론은 영리기업의 지분 대부분과 절대적 통제권, CEO가 되기를 요구했습니다.

다음 6주 동안 우리는 영리 목적의 조건에 대해 협상했습니다.

일론은 지분의 대부분을 요구했습니다. 2017년 9월 4일, 시본은 그렉에게 보낸 메시지에서 "그리고 그는 지분이 50-60 사이이므로 지분의 대부분을 차지하는 것은 무의미하다는 점에서 협상의 여지가 없는 것처럼 들렸습니다."라고 썼습니다. 한 통화에서 일론은 개인적으로 지분에 관심이 없지만 화성 도시를 위해 800억 달러를 축적해야 한다고 말했습니다.

![](https://blog.kakaocdn.net/dna/lhqDA/btsLliPByfA/AAAAAAAAAAAAAAAAAAAAAE7rD5bpJJsV12dtoHudXSF2sq-NB4simd5X9fuCHNTA/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=daigNA3xFPEYQxWKzNayDTQIQGU%3D)

2017년 9월 12일, 엘론은 자신이 "회사의 초기 통제권을 확실히 갖겠다"는 이사회 구조를 제시했습니다.

```
Re: 현재 상태
보낸 사람: Elon Musk <삭제됨>
날짜: 수요일, 9월 13, 2017 오전 12:40
받는 사람: Ilya Sutskever <삭제됨>
참조: Greg Brockman <삭제됨>
좋은 생각입니다. 세 개의 보통주 자리(당신, Greg, Sam)는 보통주 주주에 의해 선출되어야 합니다. 그들은 사실상 당신의 자리가 될 것이지만, 시간이 지나면서 보통주 주주의 엄청난 비율의 신뢰를 잃거나 선택에 따라 회사에서 물러나는 경우는 그렇지 않습니다.

저는 우선 A 투자 라운드(저의 압도적 다수)가 4개(3개가 아님)의 자리를 임명할 권리가 있어야 한다고 생각합니다. 저는 그들을 즉시 임명할 것으로 기대하지는 않지만, 제가 말했듯이 저는 회사에 대한 초기 통제권을 확실히 가질 것입니다. 하지만 이는 빠르게 바뀔 것입니다.

대략적인 목표는 12명으로 구성된 이사회를 구성하는 것입니다(이 이사회가 정말로 세계의 운명을 결정하게 된다면 아마 16명에 가까워질 것입니다). 각 이사회 구성원이 기술에 대한 깊은 이해, 최소한 AI에 대한 기본적인 이해, 그리고 강하고 상식적인 도덕관을 갖추는 것입니다.

Series A 4와 Common 3을 제외하고, 새로운 주요 투자자/동맹사마다 이사회 멤버가 있을 가능성이 큽니다. 그러나 특정 개별 새로운 이사회 멤버는 기존 이사회 멤버 한 명을 제외한 모든 멤버가 동의하는 경우에만 추가할 수 있습니다. 이사회 멤버를 제거하는 것도 마찬가지입니다.

투자자와 관련이 없는 독립적인 이사회 구성원도 추가하고 싶습니다. 동일한 규칙이 적용됩니다. 기존 이사 중 한 명을 제외한 모든 이사가 추가 또는 제거되어야 합니다.

저는 엄청 피곤하고 상황을 복잡하게 만들고 싶지 않지만, 대략적으로 맞는 것 같습니다. 16명으로 구성된 이사회 수준에서 우리는 7/16의 투표권을 가지고, 저는 25%의 영향력을 가질 것입니다. 이것이 제가 편안하게 느끼는 최소 수준입니다. 제게는 그게 맞는 것 같습니다. 우리가 이사회에 합류하도록 요청한 다른 모든 사람들이 정말로 우리에게 반대한다면, 우리는 아마 져야 할 것입니다.

언급했듯이, 이사회에 대한 제 경험(훌륭하고 똑똑한 사람들로 구성되어 있다고 가정할 때)은 이사회가 합리적이고 합리적이라는 것입니다. 개별 이사회 투표가 핵심이 되는 진정한 하드코어 전투는 기본적으로 절대 없으므로 이것은 거의 확실히(그렇기를 바랍니다) 논쟁의 여지가 없는 문제가 될 것입니다.

마무리로, 저는 여러분과 주식과 이사회에 대한 토론의 질에 정말 감명을 받았습니다. 저는 이것에 대해 정말 좋은 예감이 듭니다.

위의 내용이 타당한 것 같으면 알려주세요.

엘론
```

일론은 또한 자신이 CEO가 되어야 한다고 말했습니다.

## 2017년 9월: 엘론은 "Open Artificial Intelligence Technologies, Inc."라는 공익 기업을 설립했습니다.

일론은 그의 재산 관리자인 재러드 버첼에게 공익법인인 "Open Artificial Intelligence Technologies, Inc"(SpaceX의 공식 명칭인 "Space Exploration Technologies Corporation"과 유사)를 만들도록 지시했습니다. 이 회사는 2017년 9월 15일에 등록되었습니다.

![](https://blog.kakaocdn.net/dna/xj4kp/btsLmq0aGMB/AAAAAAAAAAAAAAAAAAAAAJ5zurmF6-rSefrGXxs9AZOgbyS2qEd4Dwizc5PQaGKL/img.webp?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=2fPA%2BvxQKhRYSkAfta2KobHFw4s%3D)

2017년 9월 15일 일론 머스크가 OpenAI의 미래 구조로 제안한 공익 기업.

![](https://blog.kakaocdn.net/dna/cYcKtl/btsLl10XhzD/AAAAAAAAAAAAAAAAAAAAAJFjeJJUrcidoGE8qkMmqyTTOT6DbbjxE5yBdrAV95IJ/img.webp?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=zz01r90QOWV3ol0EfRTQhN6JWN4%3D)

## 2017년 9월: 우리는 엘론의 조건을 거부했습니다. 그에게 OpenAI와 그 기술에 대한 일방적인 통제권을 주는 것은 사명에 어긋나기 때문입니다.

우리는 엘론의 조건을 수락하는 데 가까이 다가갔습니다. 우리가 그에게 말했듯이, "우리는 정말 당신과 함께 일하고 싶습니다. 우리는 힘을 합치면 임무에서 성공할 가능성이 가장 크다고 믿습니다."

하지만 우리는 그의 제안이 임무와 양립할 수 없다고 생각하며, "현재 구조는 AGI에 대한 일방적인 절대적 통제로 끝나는 경로를 제공합니다. 최종 AGI를 통제하고 싶지 않다고 말했지만, 이 협상에서 절대적 통제가 당신에게 매우 중요하다는 것을 보여주었습니다."라고 말했습니다. 우리가 Elon에게 말했듯이, "OpenAI의 목표는 미래를 좋게 만들고 AGI 독재를 피하는 것입니다."

우리는 "따라서 회사가 AGI를 향해 진정한 진전을 이룰 때, 현재의 반대 의도에도 불구하고 귀하가 회사에 대한 절대적인 통제권을 유지하기로 선택할까봐 우려합니다."라고 결론지었습니다.

```
솔직한 생각
4개의 이메일
보낸 사람: Ilya Sutskever <삭제됨>
날짜: 수요일, 9월 20, 2017 오후 2:08
받는 사람: Elon Musk <삭제됨>, Sam Altman <삭제됨>, Greg Brockman <삭제됨>
일론, 샘,

이 과정은 Greg와 내가 참여한 가장 큰 위험 대화였고, 프로젝트가 성공한다면, 그것은 세계가 본 가장 큰 위험 대화가 될 것입니다. 또한 그것은 우리 모두에게 매우 개인적인 대화였습니다.

어제 우리는 마지막 약속(비청탁 계약 포함)을 하려고 고민하던 중 실수를 했다는 것을 깨달았습니다. 우리는 두 분 모두에게 제기하지 않은 중요한 우려 사항이 몇 가지 있습니다. 우리는 두려웠기 때문에 제기하지 않았습니다. 우리는 관계를 해칠까 두려웠고, 당신이 우리를 덜 생각할까 두려웠고, 파트너로서 당신을 잃을까 두려웠습니다.

우리의 우려가 해결 불가능할 가능성이 있습니다. 우리는 그것이 사실이 아니기를 바라지만, 지금 모두 논의하지 않으면 확실히 실패할 것이라는 것을 알고 있습니다. 그리고 우리는 모든 것을 해결하고 함께 일할 수 있기를 바랍니다.

엘론

우리는 정말 여러분과 함께 일하고 싶습니다. 우리는 힘을 합치면 임무에서 성공할 가능성이 가장 크다고 믿습니다. 우리의 상승세는 가장 큽니다. 의심의 여지가 없습니다. 여러분과 함께 일하고 싶은 우리의 열망은 너무나 커서 우리는 형평성, 개인적 통제를 포기하고, 우리 자신을 쉽게 해고할 수 있는 존재로 만드는 것을 기꺼이 합니다. 여러분과 함께 일하는 데 필요한 모든 것을
말입니다. 하지만 우리는 통제가 세상에 미치는 영향에 대해 생각하는 데 부주의했다는 것을 깨달았습니다. 너무 오만해 보였기 때문에 우리는 성공의 영향을 진지하게 고려하지 않았습니다.

현재 구조는 AGI에 대한 일방적 절대적 통제로 귀결되는 경로를 제공합니다. 귀하는 최종 AGI를 통제하고 싶지 않다고 말씀하셨지만, 이 협상에서 귀하는 절대적 통제가 귀하에게 매우 중요하다는 것을 우리에게 보여주셨습니다.
예를 들어, 당신은 모든 사람이 당신이 책임자라는 것을 알 수 있도록 새로운 회사의 CEO가 되어야 한다고 말했지만, 동시에 당신은 CEO가 되는 것을 싫어하고 CEO가 되고 싶지 않다고 말했습니다.
따라서 우리는 회사가 AGI를 향해 진정한 진전을 이룰 때, 현재의 반대 의도에도 불구하고 회사에 대한 절대적 통제권을 유지하기로 선택할까봐 우려합니다. 우리는 우리가 떠날 수 있는 능력이 가장 큰 힘이라는 당신의 진술에 동의하지 않습니다. 회사가 실제로 AGI로 나아가면 회사가 어떤 개인보다 훨씬 더 중요해질 것이기 때문입니다.
OpenAI의 목표는 미래를 좋게 만들고 AGI 독재를 피하는 것입니다. 당신은 데미스가 AGI 독재를 만들 수 있다고 우려하고 있습니다. 우리도 마찬가지입니다. 따라서 당신이 원한다면 독재자가 될 수 있는 구조를 만드는 것은 나쁜 생각입니다. 특히 우리가 이 가능성을 피하는 다른 구조를 만들 수 있다는 점을 감안할 때 더욱 그렇습니다.
몇 가지 작은 우려 사항이 있지만, 여기에 언급하는 것이 유용하다고 생각합니다.

Cerebras를 매수하기로 결정한다면, 저는 Tesla를 통해 이루어질 것이라고 강하게 생각합니다. 하지만 OpenAI 내부에서도 할 수 있는데 왜 이런 식으로 할까요? 구체적으로, 우려되는 점은 Tesla가 주주에게 주주 수익을 극대화할 의무가 있는데, 이는 OpenAI의 사명과 맞지 않는다는 것입니다. 따라서 전반적인 결과는 OpenAI에 최적이지 않을 수 있습니다.
우리는 비영리 단체인 OpenAI가 성공한 것은 여러분과 샘이 모두 참여했기 때문이라고 믿습니다. 샘은 여러분에 대한 진정한 견제자 역할을 했고, 이는 매우 유익했습니다. 적어도 지금까지 그렉과 저는 여러분에 대한 견제자가 되는 데 훨씬 더 나쁩니다. 우리는 샘이 자신의 입장을 고수하는 동안 장기적인 AGI 통제 문제를 덮어버릴 준비가 되어 있었던 이번 협상에서도 이것이 입증되었다고 생각합니다.
샘:

Greg와 제가 막혔을 때, 당신은 항상 깊고 정확한 답을 가지고 있었습니다. 당신은 이 문제에 대한 전진 방안에 대해 매우 깊고 철저하게 생각해 왔습니다. Greg와 저는 기술적 실행을 이해하지만, 구조적 결정이 다음 달, 1년 또는 5년 동안 어떻게 전개될지 모릅니다.
하지만 우리는 이 과정 내내 당신의 판단을 전적으로 신뢰할 수 없었습니다. 왜냐하면 우리는 당신의 비용 함수를 이해하지 못하기 때문입니다.

우리는 CEO 직함이 당신에게 왜 그렇게 중요한지 이해할 수 없습니다. 당신이 말한 이유가 바뀌었고, 그것이 무엇에 의해 움직이는지 정말 이해하기 어렵습니다.
AGI가 정말로 당신의 주요 동기인가요? 그것이 당신의 정치적 목표와 어떻게 연결되나요? 시간이 지나면서 당신의 사고 과정은 어떻게 바뀌었나요?
그렉과 일리아:

이 협상에서 우리도 상당한 실패를 겪었고, 여기서 그 중 일부를 나열해 보겠습니다(일론과 샘, 여러분은 추가할 말이 많을 거라고 확신합니다…):

이 협상 중에 우리는 2~3년 후의 재정적 수익이라는 생각이 우리의 결정을 이끌도록 내버려 두었다는 것을 깨달았습니다. 이것이 우리가 통제를 강요하지 않은 이유입니다. 우리는 우리의 자본이 충분히 좋다고 생각했기 때문에 왜 걱정해야 합니까? 하지만 이런 태도는 잘못된 것입니다. AI 전문가들이 AGI를 만들 수 있다고 믿지 않기 때문에 AI 안전이 문제가 아니라고 생각하는 태도와 마찬가지입니다. 우리는 협상 중에 우리의 모든 진실을 말하지 않았습니다. 우리는 변명할 수 있지만, 그것은 과정에 해로웠고, 그 결과 샘과 엘론을 모두 잃을 수도 있습니다.
여기에는 우리가 만나서 이야기하는 것이 매우 중요하다고 생각하는 충분한 짐이 있습니다. 그렇지 않으면 우리의 협력은 성공하지 못할 것입니다. 오늘 우리 넷이 모두 만날 수 있을까요? 우리 모두가 진실을 말하고 문제를 해결한다면, 우리가 만들 회사는 겪게 될 매우 강력한 힘을 견뎌낼 가능성이 훨씬 더 높아질 것입니다.

그렉 & 일리아

보낸 사람: Elon Musk <삭제됨>
날짜: 수요일, 9월 20, 2017 오후 2:17
받는 사람: Ilya Sutskever <삭제됨>
참조: 샘 알트먼 <삭제됨>, 그렉 브록먼 <삭제됨>, <삭제됨>, 시본 질리스 <삭제됨>
여러분, 이제 그만해요. 이게 마지막 일격이에요.

혼자서 무언가를 하든 비영리 단체로서 OpenAI를 계속하든. 당신이 머물기로 확고히 약속할 때까지는 더 이상 OpenAI에 자금을 지원하지 않을 거야. 아니면 나는 당신이 스타트업을 만들 수 있도록 기본적으로 무료 자금을 제공하는 바보일 뿐이야.

토론은 끝났습니다.

보낸 사람: Elon Musk <삭제됨>
날짜: 수요일, 9월 20, 2017 오후 2:17
받는 사람: Ilya Sutskever <삭제됨>
참조: 샘 알트먼 <삭제됨>, 그렉 브록먼 <삭제됨>, <삭제됨>, 시본 질리스 <삭제됨>
분명히 말해서, 이것은 이전에 논의된 것을 받아들이라는 최후통첩이 아닙니다. 그것은 더 이상 논의 대상이 아닙니다.

보낸 사람: Sam Altman <삭제됨>
날짜: 수요일, 9월 20, 2017 오후 2:17
받는 사람: Elon Musk <삭제됨>, Ilya Sutskever <삭제됨>
참조: Greg Brockman <삭제됨>, <삭제됨>, Shivon Zilis <삭제됨>
저는 비영리 구조에 대한 열정을 갖고 있습니다!
```

엘론은 "논의는 끝났습니다"라고 답했고 "분명히 말해서, 이것은 이전에 논의된 것을 받아들이라는 최후통첩이 아닙니다. 그것은 더 이상 논의 대상이 아닙니다."라고 말했습니다.

## 2018년 1월: 엘론은 테슬라와 합병하지 않는 한 OpenAI는 확실히 실패할 것이라고 말했습니다.

협상이 결렬된 후, 엘론은 [우리가 테슬라로 분사할 것을 제안했습니다 .](https://openai.com/index/openai-elon-musk/)우리는 즉시 10억 달러의 예산을 갖게 될 것이고, 거기에서 기하급수적으로 증가할 것입니다.

하지만 우리 팀은 테슬라에서 일하고 싶어하지 않았습니다. 우리는 그 다음 몇 달을 사명을 달성하는 데 필요한 자본을 조달할 다른 방법을 찾는 데 보냈습니다.

2018년 1월 31일, 엘론은 "OpenAI는 Google에 비해 확실히 실패할 길에 있습니다. 분명히 즉각적이고 극적인 조치가 필요하거나 Google을 제외한 모든 사람이 무관심한 존재로 전락할 것입니다."라고 말했습니다.

그렉은 그에게 "제 생각에는 최고의 미래는 OpenAI의 대규모 확장에서 나올 것입니다. 우리의 목표와 사명은 근본적으로 옳으며, AGI가 가까워짐에 따라 그것은 점점 더 초강대국이 될 것입니다."라고 말했습니다.

```
Fwd: 오늘날 최고의 AI 기관
보낸 사람: Elon Musk <삭제됨>
날짜: 수요일, 1월 31, 2018 오후 2:02
받는 사람: Greg Brockman <삭제됨>, Ilya Sutskever <삭제됨>, Sam Altman <삭제됨>
참조: <삭제됨> <삭제됨>, Shivon Zilis <삭제됨>
OpenAI는 Google에 비해 확실히 실패할 길에 있습니다. 분명히 즉각적이고 극적인 조치가 필요하거나 Google을 제외한 모든 사람이 무관심하게 될 것입니다.

저는 ICO 접근 방식을 고려했고 이를 지지하지 않을 것입니다. 제 생각에, 이는 OpenAI와 ICO와 관련된 모든 사람의 신뢰를 크게 잃게 될 것입니다. 무언가가 너무 좋아서 사실이 아닌 것처럼 보인다면, 그것은 사실이 아닙니다. 제 생각에, 이것은 현명하지 못한 전환이었습니다.

내가 생각할 수 있는 유일한 길은 OpenAI의 대규모 확장과 Tesla AI의 대규모 확장입니다. 아마도 둘 다 동시에. 전자는 기부금을 크게 늘리고 매우 신뢰할 수 있는 사람들이 이사회에 합류해야 합니다. 현재 이사회 상황은 매우 약합니다.

내일 우리가 이야기할 시간을 정하겠습니다. 분명히 말해서, 저는 여러분의 능력과 업적에 대해 많은 존경심을 가지고 있지만, 일이 처리된 방식에는 만족하지 않습니다. 그래서 최근 몇 달 동안 OpenAI와 교류하는 데 어려움을 겪었습니다. 문제를 해결하고 제 참여가 크게 증가하거나 그렇지 않으면 거의 0으로 떨어지고 공개적으로 제 관계를 줄일 것입니다. 제 영향력과 시간에 대한 인식이 현실과 일치하지 않는 상황에 처하지 않을 것입니다.

보낸 사람: Greg Brockman <삭제됨>
날짜: 수요일, 1월 31, 2018 오후 10:56
받는 사람: Elon Musk <삭제됨>
참조: Ilya Sutskever <삭제됨>, Sam Altman <삭제됨>, <삭제됨>, Shivon Zilis <삭제됨>
안녕 엘론,

사려 깊은 메모에 감사드립니다. 저는 항상 큰 그림에 집중하는 당신의 모습에 감명을 받았고, 목표를 달성하기 위해 궤적을 바꿔야 한다는 데 전적으로 동의합니다. 내일 이야기합시다. 오후 4시나 그 이후에 가능하면 언제든요.

저는 최고의 미래는 OpenAI의 대규모 확장에서 비롯될 것이라고 생각합니다. 우리의 목표와 사명은 근본적으로 옳으며, AGI가 가까워짐에 따라 그것은 점점 더 초강대국이 될 것입니다.

모금 활동

우리의 모금 대화는 다음과 같은 사실을 보여줍니다.

Ilya와 저는 AGI가 앞으로 10년 이내에 실제로 실현될 수 있다고 평판 있는 사람들을 설득할 수 있습니다.
그 사람들로부터 기부에 대한 욕구가 있습니다.
그 사람들의 투자에 대한 열망은 매우 큽니다.
저는 ICO 아이디어에 대한 당신의 결정을 존중합니다. 그것은 우리의 사고방식의 진화와 일치합니다. 샘 알트먼은 공모에 의존하지 않는 모금 구조를 연구해 왔고, 우리는 당신의 피드백을 듣고 싶습니다.

우리가 이야기한 사람들 중에서, 현재 이사회 멤버들에게 제가 가장 추천하는 사람들은 다음과 같습니다. 또한 이 목록에 없는 최고의 선택에 대한 제안도 듣고 싶습니다. 그들에게 어떻게 접근할지 알아낼 수 있습니다.

<삭제됨>
<삭제됨>
<삭제됨>
<삭제됨>
<삭제됨>
<삭제됨>
다음 3년
다음 3년 동안 우리는 3가지를 만들어야 합니다.

맞춤형 AI 하드웨어(예: <삭제됨> 컴퓨터)
대규모 AI 데이터 센터(아마도 여러 차례의 회전)
알고리즘 개발, 공개 데모, 안전을 혼합한 최고의 소프트웨어 팀
우리는 맞춤형 AI 하드웨어와 AI 데이터 센터에 대해 가장 많이 이야기했습니다. 소프트웨어 측면에서 우리는 Dota와 AlphaGo에서 검증된 신뢰할 수 있는 경로(경쟁적인 멀티 에이전트 환경에서의 셀프 플레이)를 가지고 있습니다. 또한 우리는 오늘날의 딥 러닝에서 인간의 경험 수준에서 학습하는 데 장벽이 되는 작지만 한정된 수의 한계를 파악했습니다. 그리고 우리는 앞으로 3년 안에 안전을 해결하는 궤도에 독특하게 올라섰다고 믿습니다(적어도 대략적으로는).
우리는 이런 방식으로 인원을 늘리고 싶습니다.

2017년 초: ~40
2018년 말 : 100
2019년 말 : 300
2020년 말 : 900
█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █

도덕적 우위
우리의 가장 큰 도구는 도덕적 우위입니다. 이를 유지하려면 다음을 수행해야 합니다.

비영리 단체로 남기 위해 최선을 다하십시오. AI는 사회 구조를 뒤흔들 것이고, 우리의 수탁 의무는 인류에 대한 것이어야 합니다.
다른 기관에서 발견한 무화과 잎보다는 안전/통제 문제에 점점 더 많은 노력을 기울이세요. 모두가 죽는다면 누가 이기든 상관없습니다. 이와 관련하여, 우리는 "죽는 것보다 붉은 것이 낫다"는 전망을 전달해야 합니다. 우리는 안전한 AGI를 구축하려고 노력하고 있으며, 그렇게 하기 위한 치열한 경쟁에서 세계를 파괴할 의향이 없습니다.
신뢰할 수 있고 편견 없는 정책 조언을 제공하기 위해 정부와 협력하세요. 정부가 █ █ █ █ █ █ █ █ █ █ █ █ █ 와 같은 회사의 권장 사항을 신뢰하지 않는다는 말을 자주 듣습니다 .
연구 커뮤니티에 공공의 이익을 제공하고, 모범을 통해 다른 참여자들이 정직하고 개방적인 태도를 유지하도록 하는 장소로 인식됩니다.
지난 2년 동안
저는 당신이 지난 2년 동안 우리의 실행을 자원에 비해 어떻게 평가하는지 듣고 싶습니다. 제 생각에는:

지난 5년 동안 두 가지 주요 작동 시스템 데모가 있었습니다. AlphaZero[DeepMind]와 Dota 1v1[OpenAI]입니다. (실무자들 사이에서 인기 있는 "역량"의 획기적인 발전이 많이 있는데, 그 중 최고라고 말하고 싶은 것은 다음과 같습니다. ProgressiveGAN[NVIDIA], 비지도 번역[Facebook], WaveNet[DeepMind], Atari/DQN[DeepMind], 기계 번역[Google의 Ilya - 현재 OpenAI에 근무], 생성적 적대 신경망[대학원의 Ian Goodfellow - 현재 Google에 근무], 변분 자동 인코더[대학원의 Durk - 현재 OpenAI에 근무], AlexNet[대학원의 Ilya - 현재 OpenAI에 근무].) 우리는 이 축에서 좋은 벤치마킹을 합니다.
우리는 2016년에 매우 빠르게 성장했고, 2017년에는 작동하는 관리 구조로 반복했습니다. 우리는 이제 리소스가 주어지면 대규모로 확장할 준비가 되었습니다. 우리는 현재 보상으로 사람들을 잃고 있지만, 거의 보상으로만 잃고 있습니다. 저는 초창기에 했던 채용 스타일을 다시 시작했고, 그 결과를 넘어설 수 있다고 믿습니다.
우리는 해당 분야에서 가장 재능 있는 팀을 보유하고 있으며, 그에 대한 명성도 갖고 있습니다.
우리는 논문 쓰기를 장려하지 않으므로 논문 수락은 우리가 최적화하는 척도가 아닙니다. Andrej가 보낸 ICLR 차트의 경우, 저는 우리의 (수락된 논문)/(논문을 제출하는 사람)이 해당 분야에서 가장 높을 것으로 예상합니다.
- GDB를
```

엘론은 곧 OpenAI에서 사임하기로 결정했습니다.

## 2018년 2월: Elon이 OpenAI 공동의장직에서 사임

2018년 2월 20일, 엘론은 팀원들과 작별 인사를 했습니다. 그는 우리가 매년 수십억 달러를 모으는 길을 따라가야 한다고 말했습니다. 그는 테슬라에서 고급 AI 연구를 추진할 것이라고 말했는데, 테슬라가 이 수준의 자금을 얻을 수 있는 유일한 수단이라고 믿었습니다.

## 2018년 12월: Elon은 우리에게 "연간 수십억 달러를 즉시 모으거나 잊어버리라"고 말했습니다.

2018년 12월 17일, 우리는 엘론에게 진행 상황에 대한 업데이트를 보냈고 "Google에서 Microsoft로 컴퓨팅을 이전하는 거래(자체 데이터 센터 외에도)"에 대해 말했습니다. 우리는 또한 장기적인 모금 계획에 대해 이야기하자고 제안했습니다. 그는 "좋은 생각입니다"라고 답했습니다.

```
Re: OpenAI 업데이트
––––– 전달된 메시지 –––––
보낸 사람: Elon Musk <삭제됨>
날짜: 월, 17 Dec 2018 at 15:47
받는 사람: Sam Altman <삭제됨>
좋은 것 같아요

아마 수요일 저녁에 SF에서 만날 수 있을 것 같아

2018년 12월 17일 오후 3시 42분, Sam Altman <redacted>이 다음과 같이 썼습니다:

안녕, 엘론–

내년 1분기에, 우리는 제한 없는 게임에서 큰 상금을 걸고 경쟁하고자 하는 프로 팀과 함께 최종 Dota 토너먼트를 할 계획입니다. 그 후, 우리는 모델 없는 RL을 완료라고 부르고, 팀의 일부는 모델 기반 RL로 1대1 Dota를 다시 해결하는 작업을 할 것입니다.

또한 Q1에서 여러 로봇 손 데모를 출시할 계획입니다. 루빅 큐브, 펜 트릭, 중국식 볼 회전. 새로운 작업에 대한 학습 속도는 매우 빠를 것입니다. 올해 말에 두 손을 두 팔에 장착해보고 무슨 일이 일어나는지 보겠습니다...

우리는 언어에 있어서도 빠르게 진전을 이루고 있습니다. 내년에는 단편 소설과 좋은 대화 봇을 만들어낼 수 있기를 바랍니다.

█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ 이러한 비지도 학습을 사용하여 어려운 작업을 수행할 수 있는 모델을 구축할 수 있다는 것이 목표입니다. 예를 들어, 사람이 하지 않는 이미지 분류 실수를 절대 하지 않는 것입니다. 이는 일정 수준의 개념적 이해가 필요하다는 것을 의미합니다.

또한, 우리는 다중 에이전트 환경에서도 좋은 진전을 이루고 있으며, 이제는 여러 에이전트가 협력하여 간단한 구조를 만들고 레이저 태그 게임을 하는 등의 작업을 하고 있습니다.

마지막으로, 저는 우리의 컴퓨팅 역량을 Google에서 Microsoft로(그리고 우리의 자체 데이터 센터로) 이전하는 거래를 진행하고 있습니다.

자금 조달에 대해서도 이야기하고 싶습니다(공격적인 성장을 하더라도 향후 2년 정도는 충분한 자금이 있을 겁니다). 그리고 하드웨어 개발에 대한 의견도 도움이 된다면 말씀드리겠습니다. 이메일에는 두 가지 모두 전달하고 싶지 않지만 다음에 Pioneer에 오실 때는 어떨까요?

샘
```

2018년 12월 26일, 엘론은 "수억을 모으는 것만으로는 충분하지 않을 것입니다. 이것은 매년 수십억이 즉시 필요하거나 잊어버려야 합니다."라는 이메일을 보냈습니다.

```
나는 반복해야 한다고 느낀다
보낸 사람: Elon Musk <삭제됨>
날짜: 수요일, 12월 26, 2018 오후 12:07
받는 사람: Ilya Sutskever <삭제됨>, Greg Brockman <삭제됨>
참조: 샘 알트먼 <삭제됨>, 시본 질리스 <삭제됨>
실행과 리소스에 극적인 변화가 없이 OpenAI가 DeepMind/Google과 관련이 있을 가능성에 대한 제 평가는 0%입니다. 1%가 아닙니다. 그렇지 않았으면 좋겠습니다.

수억을 모으는 것조차 충분하지 않을 것입니다. 이것은 매년 수십억이 즉시 필요하거나 잊어버려야 합니다.

불행히도, 인류의 미래는 <redacted> 의 손에 달려 있습니다 .
[기사 링크]

█ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █​​ █ █ █ █ █

OpenAI는 Bezos와 Blue Origin을 떠올리게 합니다. 그들은 SpaceX에 절망적으로 뒤처지고 있고 점점 더 나빠지고 있지만 Bezos의 자존심은 그들이 그렇지 않다고 미친 듯이 생각하게 합니다!

내가 틀렸으면 좋겠다.
엘론
```

## 2019년 3월: 비영리 단체인 OpenAI LP가 관리하는 수익 제한이 있는 OpenAI LP의 공개 발표

[우리는 Elon에게 OpenAI LP 발표 블로그 게시물](https://openai.com/index/openai-lp/) 의 사전 사본을 보냈습니다 . Elon의 유일한 피드백은 "OpenAI의 영리 부문에 대한 재정적 관심이 없다는 것을 명확히 밝혀주십시오."였습니다.

지난 몇 년 동안 우리는 엘론에게 OpenAI LP의 지분을 제안했지만 그는 거부했습니다.

![](https://blog.kakaocdn.net/dna/KRnd9/btsLnGHMnBX/AAAAAAAAAAAAAAAAAAAAAFeUHQE6jycDOwLiq3ktxIxA14w70WFuS_VlkdtRRhWD/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=s%2FSM0z7DXVEsbLemGFp8WwOhzfk%3D)
![](https://blog.kakaocdn.net/dna/drCxWF/btsLnOr7i2D/AAAAAAAAAAAAAAAAAAAAALHiRh5F4U6zNMHZ5NK1Bq5CISTg7hapNq_ae7Gj5wnB/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=9EimKt7L31OCxGzKsg0RSVwR2Yk%3D)

Sam Altman(파란색/오른쪽)과 Shivon Zilis(회색/왼쪽) 간의 iMessage 대화

## 2023년 3월: Elon이 OpenAI 경쟁자 xAI를 시작했습니다.

2023년 3월 9일, 엘론은 OpenAI의 직접적인 경쟁자인 공익 기업인 xAI를 설립했습니다.

![](https://blog.kakaocdn.net/dna/C4hlF/btsLlQYJlpX/AAAAAAAAAAAAAAAAAAAAAFBAnIP58rAGyd18hHXd6QuERbc-1hYv2wqP18XuamEM/img.webp?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1772290799&allow_ip=&allow_referer=&signature=SvLp2DQ6AsHDUqVjRGyUUIlY8uU%3D)

[2023년 3월 22일, 엘론은 공개서한](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) 에 공동 서명했습니다 [.](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)[(새 창에서 열립니다)](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)GPT-4보다 강력한 훈련 시스템을 일시 중단할 것을 촉구합니다. 당시에는 OpenAI만이 GPT-4 수준의 시스템을 가지고 있었기 때문에 이는 OpenAI만이 개발을 중단해야 한다는 주장이었습니다.
