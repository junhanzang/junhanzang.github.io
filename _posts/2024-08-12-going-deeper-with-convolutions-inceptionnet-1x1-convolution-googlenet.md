---
title: "Going Deeper with Convolutions (InceptionNet, 1x1 convolution, GoogleNet)"
date: 2024-08-12 21:22:53
categories:
  - 인공지능
---

<https://arxiv.org/abs/1409.4842>

[Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)

요약

우리는 Inception이라는 코드명을 가진 심층 합성곱 신경망 아키텍처를 제안합니다. 이 아키텍처는 2014년 ImageNet 대규모 시각 인식 챌린지(ILSVRC14)에서 분류 및 검출의 새로운 최고 성능을 달성하는 데 기여했습니다. 이 아키텍처의 주요 특징은 네트워크 내부의 컴퓨팅 자원을 보다 효율적으로 활용할 수 있다는 점입니다. 이는 네트워크의 깊이와 너비를 늘리면서도 계산 비용을 일정하게 유지할 수 있는 세심한 설계를 통해 이루어졌습니다. 품질 최적화를 위해, 아키텍처 결정은 헤비안 원리와 다중 스케일 처리에 대한 직관을 기반으로 하였습니다. ILSVRC14에 제출된 특정 구현 예는 GoogLeNet이라 불리며, 22층 깊이의 네트워크로, 분류 및 검출 맥락에서 그 품질이 평가되었습니다.

### 1. 서론

지난 3년 동안, 특히 심층 학습, 더 구체적으로는 합성곱 신경망(convolutional networks) [10]의 발전 덕분에 이미지 인식과 객체 검출의 품질이 급격히 향상되었습니다. 고무적인 소식은 이러한 진전이 단순히 더 강력한 하드웨어, 더 큰 데이터셋, 그리고 더 큰 모델의 결과가 아니라, 주로 새로운 아이디어, 알고리즘, 그리고 개선된 네트워크 아키텍처의 결과라는 점입니다. 예를 들어, ILSVRC 2014 대회의 상위 참가자들은 검출 목적으로 동일한 대회의 분류 데이터셋 외에는 새로운 데이터 소스를 사용하지 않았습니다. 우리의 GoogLeNet은 ILSVRC 2014 대회에 제출되었으며, 2년 전 Krizhevsky 등 [9]이 제안한 우승 아키텍처보다 12배 적은 파라미터를 사용하면서도 훨씬 더 정확했습니다. 객체 검출에서의 가장 큰 성과는 단순히 심층 네트워크나 더 큰 모델을 사용한 것만이 아니라, 심층 아키텍처와 Girshick 등 [6]의 R-CNN 알고리즘과 같은 고전적 컴퓨터 비전의 시너지를 통해 이루어졌습니다.

또 다른 중요한 요소는 모바일 및 임베디드 컴퓨팅의 지속적인 확산과 함께 알고리즘의 효율성, 특히 전력 및 메모리 사용의 중요성이 커지고 있다는 점입니다. 이 논문에서 제시된 심층 아키텍처 설계의 고려 사항에는 이러한 요소가 포함되어 있으며, 단순히 정확성 수치에만 집착하지 않았습니다. 대부분의 실험에서 모델은 추론 시 15억 개의 곱셈-덧셈 연산을 수행하는 계산 예산을 유지하도록 설계되어, 순수한 학문적 호기심에 그치지 않고 실제 세계에서 대규모 데이터셋에 대해 합리적인 비용으로 사용될 수 있도록 하였습니다.

이 논문에서는 Lin 등 [12]의 'Network in network' 논문과 "우리는 더 깊이 들어가야 한다(we need to go deeper)"는 유명한 인터넷 밈 [1]에서 이름을 따온, 'Inception'이라는 코드명을 가진 효율적인 심층 신경망 아키텍처에 초점을 맞추겠습니다. 우리 경우, '깊다(deep)'라는 단어는 두 가지 의미로 사용됩니다. 첫째, 'Inception 모듈'이라는 새로운 수준의 조직을 도입한다는 의미와, 둘째, 네트워크 깊이가 증가한다는 보다 직접적인 의미에서입니다. 일반적으로 Inception 모델은 [12]의 논리적 귀결로 볼 수 있으며, Arora 등 [2]의 이론적 작업에서 영감과 지침을 얻었습니다. 이 아키텍처의 이점은 ILSVRC 2014 분류 및 검출 챌린지에서 실험적으로 검증되었으며, 여기서 현재의 최고 수준을 크게 능가하는 성과를 보여주었습니다.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

기억 안나는 것도 많고, 확실히 예전보다 gpu가 작으니 더 컴팩트하게 설계하는 것 같기도하다

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

### 2. 관련 연구

LeNet-5 [10]부터 시작하여, 합성곱 신경망(CNN)은 일반적으로 표준 구조를 가져왔습니다. 즉, 중첩된 합성곱 층(옵션으로 대조 정규화 및 맥스 풀링이 뒤따를 수 있음)이 하나 이상의 완전 연결 층과 결합된 구조입니다. 이 기본 설계의 변형들은 이미지 분류 문헌에서 널리 퍼져 있으며, MNIST, CIFAR, 그리고 특히 ImageNet 분류 챌린지 [9, 21]에서 현재까지 최고의 결과를 도출해 왔습니다. ImageNet과 같은 대규모 데이터셋의 경우, 최근의 추세는 층의 수를 늘리거나 [12] 층의 크기를 키우고 [21, 14], 드롭아웃(dropout) [7]을 사용하여 과적합 문제를 해결하는 것입니다.

맥스 풀링 층이 정확한 공간 정보를 손실할 수 있다는 우려에도 불구하고, [9]와 같은 합성곱 네트워크 아키텍처는 로컬라이제이션 [9, 14], 객체 검출 [6, 14, 18, 5], 그리고 인간 자세 추정 [19]에도 성공적으로 적용되었습니다. 영장류 시각 피질에 대한 신경과학 모델에 영감을 받아, Serre 등 [15]은 Inception 모델과 유사하게 여러 크기의 고정된 가보(Gabor) 필터를 사용하여 다중 스케일을 처리했습니다. 그러나 [15]의 고정된 2층 깊이 모델과 달리, Inception 모델의 모든 필터는 학습됩니다. 또한, Inception 층은 여러 번 반복되며, GoogLeNet 모델의 경우 22층 깊이의 모델로 이어집니다.

Network-in-Network는 Lin 등 [12]에 의해 제안된 방법으로, 신경망의 표현 능력을 증가시키기 위한 접근법입니다. 합성곱 층에 적용될 때, 이 방법은 추가적인 1×1 합성곱 층으로 간주될 수 있으며, 보통 정류된 선형 활성화(ReLU) [9]가 뒤따릅니다. 이는 현재의 CNN 파이프라인에 쉽게 통합될 수 있습니다. 우리는 이 접근 방식을 아키텍처에서 많이 사용했습니다. 그러나 우리의 설정에서는 1×1 합성곱이 두 가지 목적을 가지고 있습니다. 가장 중요한 것은, 계산 병목 현상을 제거하여 네트워크의 크기를 제한할 수 있는 차원 축소 모듈로 주로 사용된다는 점입니다. 이를 통해 네트워크의 깊이뿐만 아니라 너비도 성능에 큰 영향을 미치지 않고 증가시킬 수 있습니다.

현재 객체 검출을 위한 주요 접근법은 Girshick 등 [6]이 제안한 합성곱 신경망을 활용한 영역(R-CNN)입니다. R-CNN은 전체 검출 문제를 두 가지 하위 문제로 분해합니다: 먼저 색상 및 슈퍼픽셀 일관성과 같은 저수준 단서를 사용하여 범주에 구애받지 않는 방식으로 잠재적 객체 제안을 도출하고, 그런 다음 CNN 분류기를 사용하여 해당 위치에서 객체 범주를 식별합니다. 이러한 두 단계 접근법은 저수준 단서를 사용한 경계 상자 세분화의 정확도와 최신 CNN의 매우 강력한 분류 능력을 활용합니다. 우리는 검출 제출물에서 유사한 파이프라인을 채택했으며, 더 높은 객체 경계 상자 회수를 위한 멀티박스 [5] 예측과 경계 상자 제안의 더 나은 범주화를 위한 앙상블 접근법과 같은 두 단계 모두에서 향상을 탐구했습니다.

### 3. 동기 및 고수준 고려 사항

심층 신경망의 성능을 향상시키는 가장 직관적인 방법은 그 크기를 증가시키는 것입니다. 여기에는 네트워크의 깊이(즉, 계층의 수)와 너비(각 계층의 유닛 수)를 모두 늘리는 것이 포함됩니다. 이는 특히 대량의 라벨링된 학습 데이터가 있는 경우, 더 높은 품질의 모델을 훈련시키는 쉬우면서도 안전한 방법입니다. 그러나 이 간단한 해결책에는 두 가지 주요 단점이 따릅니다.

첫째, 크기가 커지면 일반적으로 파라미터 수가 증가하는데, 이는 확장된 네트워크가 과적합에 더 취약해지게 만듭니다. 특히, 학습 세트에서 라벨링된 예제의 수가 제한적인 경우 과적합이 큰 문제가 될 수 있습니다. 이는 큰 병목 현상이 될 수 있는데, 특히 고품질 학습 세트를 만드는 것이 까다롭고 비용이 많이 들 수 있기 때문입니다. 전문가의 평가가 필요한 경우, ImageNet과 같은 세밀한 시각적 범주(예: 1000개 클래스의 ILSVRC 하위 집합)를 구별하기 위해 높은 품질의 학습 세트를 만드는 것은 더욱 어렵고 비용이 많이 듭니다. 이는 그림 1에서 볼 수 있습니다.

![](/assets/images/posts/249/img.png)

(a) 시베리안 허스키

![](/assets/images/posts/249/img_1.png)

(b) 에스키모 개  
그림 1: ILSVRC 2014 분류 챌린지의 1000개 클래스 중 두 개의 별개의 클래스.

또 다른 단점은 네트워크 크기를 균일하게 증가시키면 계산 자원의 사용이 극적으로 증가한다는 점입니다. 예를 들어, 심층 비전 네트워크에서 두 개의 합성곱 층이 연결되어 있을 때, 필터 수를 균일하게 증가시키면 계산량이 제곱으로 증가합니다. 추가된 용량이 비효율적으로 사용될 경우(예: 대부분의 가중치가 0에 가깝다면), 많은 계산이 낭비됩니다. 실제로 계산 예산이 항상 한정되어 있기 때문에, 결과의 품질을 높이는 것이 주요 목표라 하더라도, 무작정 크기를 늘리는 것보다 계산 자원을 효율적으로 분배하는 것이 선호됩니다.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

최근 모델들은 정말 효율적으로 배분되는지 잘 모르겠다. 확인이 필요하다.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

이 두 가지 문제를 근본적으로 해결하는 방법은 완전히 연결된 구조에서 희소하게 연결된 아키텍처로 옮겨가는 것입니다. 이는 합성곱 내에서도 적용됩니다. 생물학적 시스템을 모방하는 것 외에도, 이는 Arora 등 [2]의 획기적인 연구로 인해 더 확고한 이론적 기반을 가지게 됩니다. 그들의 주요 결과는 데이터셋의 확률 분포가 매우 큰 희소 심층 신경망으로 표현될 수 있다면, 최적의 네트워크 토폴로지는 마지막 층의 활성화 상관 통계를 분석하고 상관 관계가 높은 뉴런들을 클러스터링하여 층별로 구성될 수 있다는 것입니다. 비록 엄격한 수학적 증명은 매우 강력한 조건을 요구하지만, 이 주장이 '함께 발화하는 뉴런들은 연결된다'는 잘 알려진 헤비안 원칙과 공명한다는 사실은 이 기본 아이디어가 실질적으로 덜 엄격한 조건에서도 적용될 수 있음을 시사합니다.

그러나 오늘날의 컴퓨팅 인프라는 비균일한 희소 데이터 구조에 대한 수치 계산에 있어 매우 비효율적입니다. 비록 산술 연산의 수가 100배 줄어들더라도, 조회와 캐시 미스의 오버헤드가 너무 지배적이어서 희소 행렬로 전환하는 것이 득이 되지 않습니다. 이 격차는 점점 개선되고 있는 고도로 최적화된 수치 라이브러리의 사용으로 인해 더욱 커지고 있습니다. 이 라이브러리들은 기저의 CPU나 GPU 하드웨어의 미세한 세부 사항을 활용하여 매우 빠른 밀집 행렬 곱셈을 가능하게 합니다 [16, 9]. 또한, 비균일 희소 모델은 더 정교한 엔지니어링과 컴퓨팅 인프라를 필요로 합니다. 대부분의 현재 비전 지향 기계 학습 시스템은 합성곱을 사용함으로써 공간 영역에서 희소성을 활용합니다. 그러나 합성곱은 이전 층의 패치에 대한 밀집 연결의 집합으로 구현됩니다. ConvNet은 전통적으로 학습을 개선하고 대칭성을 깨기 위해 [11] 이후 특징 차원에서 무작위 및 희소 연결 테이블을 사용해왔지만, [9]에서 병렬 컴퓨팅을 더 잘 최적화하기 위해 다시 완전 연결로 바뀌었습니다. 구조의 균일성과 다수의 필터, 더 큰 배치 크기는 효율적인 밀집 계산을 활용할 수 있게 합니다.

이로 인해 필터 수준에서도 이론이 제안하는 대로 희소성을 활용하면서도, 밀집 행렬에 대한 계산을 활용하여 현재의 하드웨어를 최대한 활용할 수 있는 다음의 중간 단계 아키텍처가 가능할지에 대한 의문이 제기됩니다. 희소 행렬 계산에 대한 방대한 문헌(e.g. [3])은 희소 행렬을 상대적으로 밀집된 하위 행렬로 클러스터링하면 희소 행렬 곱셈에 대한 최신의 실용적인 성능을 제공하는 경향이 있다는 것을 시사합니다. 이러한 유사한 방법들이 가까운 미래에 비균일 심층 학습 아키텍처의 자동 구성에 활용될 가능성이 있다고 생각하는 것이 무리는 아닙니다.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

비균일 심층 학습 아키텍처는 Transformer 기반 모델이라고 생각하면 편하다.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

Inception 아키텍처는 첫 번째 저자가 시각 네트워크를 위해 [2]에서 암시된 희소 구조를 근사하고, 이를 밀집된, 쉽게 사용할 수 있는 구성 요소들로 덮는 복잡한 네트워크 토폴로지 구성 알고리즘의 가설적 출력을 평가하기 위한 사례 연구로 시작되었습니다. 이는 매우 투기적인 시도였지만, 정확한 토폴로지 선택에 대한 두 번의 반복만으로도 이미 [12] 기반의 참조 아키텍처에 비해 약간의 성능 향상을 확인할 수 있었습니다. 학습률, 하이퍼파라미터 및 개선된 학습 방법론을 추가로 조정한 후, 결과적인 Inception 아키텍처가 [6] 및 [5]의 기반 네트워크로서 로컬라이제이션 및 객체 검출 맥락에서 특히 유용하다는 것을 확인했습니다. 흥미롭게도, 대부분의 원래 아키텍처 선택이 의문을 제기하고 철저히 테스트되었지만, 결과적으로 최소한 지역적으로는 최적임이 드러났습니다.

하지만 주의할 점도 있습니다. 제안된 아키텍처가 컴퓨터 비전에서 성공을 거두었지만, 그 품질이 이를 구성하게 된 지도 원칙에 기인한 것인지는 여전히 의문입니다. 이를 확실히 하려면 훨씬 더 철저한 분석과 검증이 필요합니다. 예를 들어, 아래에 설명된 원칙에 기반한 자동화 도구가 비전 네트워크를 위한 유사하지만 더 나은 토폴로지를 찾을 수 있는지 확인하는 것이 필요합니다. 가장 설득력 있는 증거는 자동화 시스템이 다른 영역에서 비슷한 이익을 가져오는 네트워크 토폴로지를 생성하는 것일 것입니다. 동일한 알고리즘을 사용하지만, 전체 아키텍처가 매우 다르게 보이는 경우입니다. 최소한 Inception 아키텍처의 초기 성공은 이 방향으로 흥미로운 미래 작업을 위한 확고한 동기를 제공합니다.

### 4. 아키텍처 세부 사항

Inception 아키텍처의 주요 아이디어는 합성곱 비전 네트워크에서 최적의 로컬 희소 구조를 어떻게 쉽게 이용할 수 있는 밀집된 구성 요소들로 근사하고 덮을 수 있는지를 찾는 데 기반합니다. 번역 불변성을 가정하면 네트워크는 합성곱 빌딩 블록으로 구성될 것입니다. 우리가 해야 할 일은 최적의 로컬 구조를 찾고 이를 공간적으로 반복하는 것입니다. Arora 등 [2]은 마지막 층의 상관 통계를 분석하여 높은 상관 관계를 가진 유닛 그룹으로 클러스터링하는 층별 구성 방법을 제안합니다. 이러한 클러스터들이 다음 층의 유닛을 형성하고, 이전 층의 유닛과 연결됩니다. 우리는 이전 층의 각 유닛이 입력 이미지의 일부 영역에 해당하고, 이 유닛들이 필터 뱅크로 그룹화된다고 가정합니다. 하위 층(입력에 가까운 층)에서는 상관된 유닛들이 로컬 영역에 집중될 것입니다. 이는 다음 층에서 1×1 합성곱으로 덮을 수 있는 여러 클러스터가 하나의 영역에 집중된다는 것을 의미합니다 [12]. 그러나 더 큰 패치를 대상으로 하는 합성곱으로 덮을 수 있는, 더 넓게 분포된 클러스터가 적은 수로 존재할 수 있으며, 점점 더 넓은 영역에 걸친 패치의 수는 감소할 것입니다. 패치 정렬 문제를 피하기 위해 현재의 Inception 아키텍처 구현은 1×1, 3×3 및 5×5 필터 크기로 제한되지만, 이 결정은 필요성보다는 편의성에 기반한 것입니다. 또한 제안된 아키텍처는 이러한 모든 층의 출력을 하나의 출력 벡터로 결합하여 다음 단계의 입력을 형성하는 방식으로 결합한 것입니다. 추가적으로, 풀링 연산이 현재 최신 합성곱 네트워크의 성공에 필수적이었기 때문에, 각 단계에서 대체 병렬 풀링 경로를 추가하면 추가적인 유익한 효과가 있을 것이라는 점도 제안됩니다 (그림 2(a) 참조).

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 300">
<!-- 첫 번째 층의 특징 맵들 -->
<g transform="translate(10, 10)">
<rect width="120" height="120" fill="#ffcccc" stroke="#000" />
<text x="60" y="-5" text-anchor="middle" font-size="12">첫 번째 층 특징 맵들</text>
<rect x="10" y="10" width="30" height="30" fill="#ff9999" stroke="#000" />
<rect x="45" y="10" width="30" height="30" fill="#ff8888" stroke="#000" />
<rect x="80" y="10" width="30" height="30" fill="#ff7777" stroke="#000" />
<rect x="10" y="45" width="30" height="30" fill="#ff6666" stroke="#000" />
<rect x="45" y="45" width="30" height="30" fill="#ff5555" stroke="#000" />
<rect x="80" y="45" width="30" height="30" fill="#ff4444" stroke="#000" />
<rect x="10" y="80" width="30" height="30" fill="#ff3333" stroke="#000" />
<rect x="45" y="80" width="30" height="30" fill="#ff2222" stroke="#000" />
<rect x="80" y="80" width="30" height="30" fill="#ff1111" stroke="#000" />
</g>
<!-- 화살표 -->
<line x1="140" y1="70" x2="220" y2="70" stroke="#000" stroke-width="2" marker-end="url(#arrowhead)" />
<text x="180" y="60" text-anchor="middle" font-size="12">1x1 합성곱</text>
<!-- 1x1 합성곱 과정 -->
<g transform="translate(230, 10)">
<rect width="120" height="120" fill="#ccffcc" stroke="#000" />
<text x="60" y="-5" text-anchor="middle" font-size="12">1x1 합성곱 과정</text>
<rect x="10" y="10" width="30" height="30" fill="#99ff99" stroke="#000" />
<rect x="45" y="10" width="30" height="30" fill="#88ff88" stroke="#000" />
<rect x="80" y="10" width="30" height="30" fill="#77ff77" stroke="#000" />
<rect x="10" y="45" width="30" height="30" fill="#66ff66" stroke="#000" />
<rect x="45" y="45" width="30" height="30" fill="#55ff55" stroke="#000" />
<rect x="80" y="45" width="30" height="30" fill="#44ff44" stroke="#000" />
<rect x="10" y="80" width="30" height="30" fill="#33ff33" stroke="#000" />
<rect x="45" y="80" width="30" height="30" fill="#22ff22" stroke="#000" />
<rect x="80" y="80" width="30" height="30" fill="#11ff11" stroke="#000" />
</g>
<!-- 화살표 -->
<line x1="360" y1="70" x2="440" y2="70" stroke="#000" stroke-width="2" marker-end="url(#arrowhead)" />
<!-- 두 번째 층의 결과 특징 맵 -->
<g transform="translate(450, 10)">
<rect width="120" height="120" fill="#cce6ff" stroke="#000" />
<text x="60" y="-5" text-anchor="middle" font-size="12">두 번째 층 특징 맵</text>
<rect x="10" y="10" width="100" height="100" fill="#99ccff" stroke="#000" />
</g>
<!-- 설명 -->
<text x="300" y="250" font-size="12" text-anchor="middle">
<tspan x="300" dy="0">1x1 합성곱은 각 위치에서 모든 채널의 정보를</tspan>
<tspan x="300" dy="20">결합하여 새로운 특징을 만듭니다.</tspan>
<tspan x="300" dy="40">이는 채널 간의 상관관계를 학습하는 데 도움이 됩니다.</tspan>
</text>
</svg>

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

이러한 "Inception 모듈"이 서로 쌓일 때, 출력 상관 통계는 변화할 것입니다. 더 높은 추상화 수준의 특징들이 더 높은 층에서 포착됨에 따라 공간적 집중도는 감소할 것으로 예상되며, 이는 3×3 및 5×5 합성곱의 비율이 더 높은 층으로 이동할수록 증가해야 함을 시사합니다.

위의 모듈에서, 최소한 이 순진한 형태에서는, 5×5 합성곱의 수가 많아지면 많은 수의 필터를 가진 합성곱 층 위에서 계산 비용이 매우 높아질 수 있습니다. 이 문제는 풀링 유닛이 추가되면 더욱 두드러집니다. 풀링 층의 출력 필터 수는 이전 단계의 필터 수와 같아지기 때문입니다. 풀링 층의 출력을 합성곱 층의 출력과 병합하면 단계별로 출력 수가 필연적으로 증가하게 됩니다. 이 아키텍처가 최적의 희소 구조를 커버할 수 있을지라도, 매우 비효율적으로 수행되어 몇 단계 내에 계산이 폭발적으로 증가할 것입니다.

![](/assets/images/posts/249/img_2.png)

그림 2(a): Inception 모듈, 기본 버전그림

![](/assets/images/posts/249/img_3.png)

그림 2(b): 차원 축소가 적용된 Inception 모듈

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 400">
<!-- 입력 텐서 -->
<g transform="translate(50, 50)">
<path d="M0,0 L200,0 L250,50 L50,50 Z" fill="#ffcccc" stroke="#000"/>
<path d="M200,0 L250,50 L250,250 L200,200 Z" fill="#ffaaaa" stroke="#000"/>
<path d="M0,0 L200,0 L200,200 L0,200 Z" fill="#ff8888" stroke="#000"/>
<path d="M0,200 L50,250 L250,250 L200,200 Z" fill="#ff6666" stroke="#000"/>
<line x1="0" y1="50" x2="200" y2="50" stroke="#000" stroke-dasharray="5,5"/>
<line x1="0" y1="100" x2="200" y2="100" stroke="#000" stroke-dasharray="5,5"/>
<line x1="0" y1="150" x2="200" y2="150" stroke="#000" stroke-dasharray="5,5"/>
<text x="125" y="280" text-anchor="middle" font-size="14">입력 텐서 (H x W x 64)</text>
</g>
<!-- 1x1 합성곱 필터 -->
<g transform="translate(350, 100)">
<rect x="0" y="0" width="50" height="200" fill="#ccffcc" stroke="#000"/>
<line x1="0" y1="50" x2="50" y2="50" stroke="#000" stroke-dasharray="5,5"/>
<line x1="0" y1="100" x2="50" y2="100" stroke="#000" stroke-dasharray="5,5"/>
<line x1="0" y1="150" x2="50" y2="150" stroke="#000" stroke-dasharray="5,5"/>
<text x="25" y="230" text-anchor="middle" font-size="14">1x1 합성곱 필터</text>
<text x="25" y="250" text-anchor="middle" font-size="14">(1 x 1 x 64 x 32)</text>
</g>
<!-- 화살표 -->
<path d="M320,150 L340,150 L340,140 L360,160 L340,180 L340,170 L320,170 Z" fill="#000"/>
<!-- 출력 텐서 -->
<g transform="translate(500, 100)">
<path d="M0,0 L150,0 L200,50 L50,50 Z" fill="#cce6ff" stroke="#000"/>
<path d="M150,0 L200,50 L200,200 L150,150 Z" fill="#99ccff" stroke="#000"/>
<path d="M0,0 L150,0 L150,150 L0,150 Z" fill="#66b3ff" stroke="#000"/>
<path d="M0,150 L50,200 L200,200 L150,150 Z" fill="#3399ff" stroke="#000"/>
<line x1="0" y1="50" x2="150" y2="50" stroke="#000" stroke-dasharray="5,5"/>
<line x1="0" y1="100" x2="150" y2="100" stroke="#000" stroke-dasharray="5,5"/>
<text x="100" y="230" text-anchor="middle" font-size="14">출력 텐서 (H x W x 32)</text>
</g>
</svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 400">
<!-- 입력 채널 -->
<g transform="translate(50, 50)">
<rect x="0" y="0" width="200" height="30" fill="#ffcccc" stroke="#000"/>
<rect x="0" y="40" width="200" height="30" fill="#ffaaaa" stroke="#000"/>
<rect x="0" y="80" width="200" height="30" fill="#ff8888" stroke="#000"/>
<text x="100" y="140" text-anchor="middle" font-size="14">입력 채널 (64개)</text>
</g>
<!-- 가중치 -->
<g transform="translate(300, 50)">
<rect x="0" y="0" width="30" height="110" fill="#ccffcc" stroke="#000"/>
<rect x="40" y="0" width="30" height="110" fill="#aaffaa" stroke="#000"/>
<rect x="80" y="0" width="30" height="110" fill="#88ff88" stroke="#000"/>
<text x="55" y="140" text-anchor="middle" font-size="14">가중치 (32개 세트)</text>
</g>
<!-- 화살표 -->
<path d="M400,100 L420,100 L420,90 L440,110 L420,130 L420,120 L400,120 Z" fill="#000"/>
<!-- 출력 채널 -->
<g transform="translate(460, 50)">
<rect x="0" y="0" width="200" height="30" fill="#cce6ff" stroke="#000"/>
<rect x="0" y="40" width="200" height="30" fill="#99ccff" stroke="#000"/>
<rect x="0" y="80" width="200" height="30" fill="#66b3ff" stroke="#000"/>
<text x="100" y="140" text-anchor="middle" font-size="14">출력 채널 (32개)</text>
</g>
<!-- 수식 -->
<text x="400" y="200" text-anchor="middle" font-size="16">
<tspan x="400" dy="0">y[i] = Σ(w[i][j] \* x[j]) + b[i]</tspan>
<tspan x="400" dy="25">i = 0 to 31, j = 0 to 63</tspan>
</text>
<!-- 설명 -->
<text x="400" y="280" text-anchor="middle" font-size="14">
<tspan x="400" dy="0">각 출력 채널 값은 모든 입력 채널 값의</tspan>
<tspan x="400" dy="20">가중치 합으로 계산됩니다.</tspan>
<tspan x="400" dy="40">이 과정에서 채널 간 상관관계가 학습됩니다.</tspan>
</text>
</svg>

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

이로 인해 제안된 아키텍처의 두 번째 아이디어가 나오게 되었습니다: 계산 요구 사항이 과도하게 증가할 경우, 차원 축소와 투영을 신중하게 적용하는 것입니다. 이는 임베딩의 성공에 기반을 두고 있습니다. 심지어 저차원 임베딩도 비교적 큰 이미지 패치에 대한 많은 정보를 포함할 수 있습니다. 그러나 임베딩은 정보를 밀집된, 압축된 형태로 표현하며, 압축된 정보는 모델링하기가 더 어렵습니다. 우리는 가능한 많은 부분에서 표현을 희소하게 유지하고 (Arora 등 [2]의 조건이 요구하는 대로) 신호를 대량으로 집계해야 할 때만 압축하고자 합니다. 즉, 1×1 합성곱을 사용하여 비용이 많이 드는 3×3 및 5×5 합성곱 이전에 차원을 축소합니다. 축소뿐만 아니라, 이 과정에서는 정류된 선형 활성화 함수(ReLU)도 사용되어 이중 목적으로 활용됩니다. 최종 결과는 그림 2(b)에 묘사되어 있습니다.

일반적으로, Inception 네트워크는 위에서 설명한 유형의 모듈들을 서로 쌓아올린 네트워크로, 가끔씩 스트라이드 2의 맥스 풀링 층을 포함하여 그리드의 해상도를 절반으로 줄입니다. 기술적인 이유(훈련 중 메모리 효율성)로 인해, 하위 층을 전통적인 합성곱 방식으로 유지하면서 Inception 모듈을 더 높은 층에서만 사용하기 시작하는 것이 유리하다고 판단되었습니다. 이는 엄격히 필요하지는 않으며, 현재 구현에서의 몇 가지 인프라 비효율성을 반영한 것입니다.

이 아키텍처의 주요 이점 중 하나는 계산 복잡도가 통제되지 않고 급격히 증가하지 않으면서도 각 단계에서 유닛 수를 크게 증가시킬 수 있다는 점입니다. 차원 축소의 보편적인 사용은 마지막 단계에서 다음 층으로 전달되는 많은 수의 입력 필터를 보호하면서, 먼저 차원을 축소한 다음 큰 패치 크기로 이들을 합성곱하는 방식을 가능하게 합니다. 이 설계의 또 다른 실용적인 이점은 시각적 정보가 다양한 스케일에서 처리된 후 다음 단계에서 여러 스케일에서 동시에 특징을 추상화할 수 있도록 집계되어야 한다는 직관에 부합한다는 점입니다.

계산 자원의 향상된 사용은 각 단계의 너비와 단계 수를 모두 증가시키면서도 계산상의 문제를 일으키지 않게 해줍니다. Inception 아키텍처를 활용하는 또 다른 방법은 약간 성능이 떨어지지만 계산 비용이 더 저렴한 버전을 만드는 것입니다. 우리는 포함된 다양한 조정 요소들이 계산 자원을 통제된 방식으로 균형 있게 조정할 수 있게 해주며, 이를 통해 Inception 아키텍처가 아닌 비슷한 성능의 네트워크보다 2-3배 빠른 네트워크를 만들 수 있다는 것을 발견했습니다. 그러나 이는 현재로서는 신중한 수동 설계가 필요합니다.

### 5. GoogLeNet

우리는 ILSVRC14 대회에서 팀명으로 GoogLeNet을 선택했습니다. 이 이름은 Yann LeCun의 선구적인 LeNet-5 네트워크 [10]에 대한 경의를 표하기 위함입니다. 또한 우리는 GoogLeNet이라는 이름을 대회에 제출한 Inception 아키텍처의 특정 구현을 지칭하는 데 사용합니다. 우리는 더 깊고 넓은 Inception 네트워크도 사용했으며, 그 품질은 약간 떨어졌지만 이를 앙상블에 추가하는 것이 결과를 약간 개선하는 데 도움이 되었습니다. 그러나 실험 결과, 정확한 아키텍처 매개변수의 영향은 상대적으로 미미하다는 것을 알게 되었으므로 그 네트워크의 세부 사항은 생략합니다. 여기서는 가장 성공적인 특정 인스턴스(GoogLeNet이라 명명된)를 데모 목적으로 표 1에 설명하였습니다. 동일한 토폴로지(다른 샘플링 방법으로 훈련됨)가 앙상블의 7개 모델 중 6개에 사용되었습니다.

![](/assets/images/posts/249/img_4.png)

표 1에서 GoogLeNet의 Inception 아키텍처 구현에 대한 세부 정보를 설명

모든 합성곱 연산, Inception 모듈 내의 합성곱을 포함하여, 정류된 선형 활성화 함수를 사용합니다. 네트워크에서 수용 영역의 크기는 224×224이며, RGB 색상 채널을 사용하고 평균을 뺀 값을 입력으로 받습니다. "3×3 축소"와 "5×5 축소"는 3×3 및 5×5 합성곱 이전에 사용되는 1×1 필터의 수를 나타냅니다. 풀링 프로젝션 열에서는 내장된 맥스 풀링 후 투영 층의 1×1 필터 수를 확인할 수 있습니다. 이러한 모든 축소/투영 층도 정류된 선형 활성화를 사용합니다.

이 네트워크는 계산 효율성과 실용성을 염두에 두고 설계되었으며, 개별 장치, 특히 메모리 풋프린트가 낮은 장치에서도 추론을 실행할 수 있도록 설계되었습니다. 이 네트워크는 파라미터가 있는 층만 계산하면 22층 깊이이며(풀링을 포함하면 27층), 네트워크를 구성하는 전체 층(독립적인 빌딩 블록)의 수는 약 100개입니다. 그러나 이 숫자는 사용된 머신러닝 인프라 시스템에 따라 달라질 수 있습니다. 분류기 전에 평균 풀링을 사용하는 것은 [12]에 기반을 두고 있지만, 우리는 추가적인 선형 층을 사용하여 구현이 다릅니다. 이는 다른 라벨 세트에 네트워크를 쉽게 적응시키고 미세 조정할 수 있도록 해주지만, 이는 주로 편의성을 위한 것이며 큰 영향을 미치지는 않을 것으로 예상됩니다. 완전 연결 층에서 평균 풀링으로 전환하면 top-1 정확도가 약 0.6% 향상된 것으로 나타났지만, 완전 연결 층을 제거한 후에도 드롭아웃의 사용은 여전히 필수적이었습니다.

네트워크의 깊이가 비교적 깊기 때문에, 모든 층을 통해 효과적으로 그래디언트를 역전파하는 능력이 우려되었습니다. 흥미로운 통찰 중 하나는 이 작업에서 비교적 얕은 네트워크의 강력한 성능이 네트워크 중간 층에서 생성된 특징들이 매우 차별화되어야 한다는 것을 시사한다는 점입니다. 이러한 중간 층에 연결된 보조 분류기를 추가함으로써, 분류기의 하위 단계에서 차별화를 촉진하고, 역전파되는 그래디언트 신호를 증가시키며, 추가적인 정규화를 제공할 수 있습니다. 이러한 분류기는 Inception (4a) 및 (4d) 모듈의 출력 위에 배치된 작은 합성곱 네트워크의 형태를 띠고 있습니다. 훈련 중에는 이들의 손실이 네트워크의 총 손실에 할인된 가중치(보조 분류기의 손실 가중치는 0.3)로 추가됩니다. 추론 시에는 이러한 보조 네트워크는 폐기됩니다.

보조 분류기를 포함한 부가적인 네트워크의 정확한 구조는 다음과 같습니다:

- 5×5 필터 크기와 스트라이드 3을 가진 평균 풀링 층으로, (4a) 단계에서는 4×4×512 출력, (4d) 단계에서는 4×4×528 출력을 생성합니다.
- 128개의 필터를 가진 1×1 합성곱 층으로 차원을 축소하고, 정류된 선형 활성화를 적용합니다.
- 1024개의 유닛을 가진 완전 연결 층과 정류된 선형 활성화.
- 출력의 70%를 드롭하는 드롭아웃 층.
- 선형 층과 소프트맥스 손실을 가진 분류기(메인 분류기와 동일한 1000개의 클래스를 예측하지만, 추론 시 제거됨).

결과적인 네트워크의 개략적인 모습은 그림 3에 나타나 있습니다.

![](/assets/images/posts/249/img_5.png)

그림 3이 GoogLeNet 네트워크의 모든 주요 요소들을 포함한 완전한 모습

### 6. 훈련 방법론

우리의 네트워크는 DistBelief [4] 분산 머신러닝 시스템을 사용하여 적절한 모델 및 데이터 병렬성을 활용해 훈련되었습니다. 우리는 CPU 기반 구현만을 사용했지만, 대략적인 추정에 따르면 GoogLeNet 네트워크는 몇 개의 고급 GPU를 사용하여 일주일 내로 수렴하도록 훈련될 수 있을 것입니다. 주요 제한 요소는 메모리 사용량이었습니다. 훈련에는 0.9 모멘텀 [17]을 사용한 비동기 확률적 경사 하강법과 고정된 학습률 스케줄(매 8 에포크마다 학습률을 4%씩 감소)을 사용했습니다. Polyak 평균화 [13]가 최종 모델을 생성하는 데 사용되었으며, 이 모델이 추론 시 사용되었습니다.

대회에 이르는 몇 달 동안 이미지 샘플링 방법이 상당히 변화했고, 이미 수렴한 모델도 때때로 하이퍼파라미터(예: 드롭아웃 및 학습률)를 변경하면서 다른 옵션으로 재훈련되었습니다. 따라서 이러한 네트워크를 훈련시키는 가장 효과적인 단일 방법에 대한 명확한 지침을 제공하기는 어렵습니다. 상황을 더욱 복잡하게 만든 것은 일부 모델은 상대적으로 작은 크롭으로 주로 훈련되었고, 다른 모델은 [8]에서 영감을 받아 더 큰 크롭으로 훈련되었다는 점입니다. 그럼에도 불구하고, 대회 후에 매우 효과적으로 검증된 방법 중 하나는 이미지 크기의 8%에서 100% 사이의 크기로 균등하게 분포된 다양한 크기의 패치를 샘플링하고, 가로 세로 비율을 3:4에서 4:3 사이에서 무작위로 선택하는 것이 포함되었습니다. 또한, Andrew Howard [8]의 광학 왜곡 기법이 어느 정도 과적합을 방지하는 데 유용하다는 것을 발견했습니다. 추가적으로, 상대적으로 늦게 다른 하이퍼파라미터 변경과 함께 무작위 보간 방법(양선형, 영역, 최근접 이웃 및 삼차원 보간을 동등한 확률로)을 사용하기 시작했기 때문에, 최종 결과에 이러한 방법의 사용이 긍정적으로 영향을 미쳤는지 명확하게 말할 수는 없었습니다.

### 7. ILSVRC 2014 분류 챌린지 설정 및 결과

ILSVRC 2014 분류 챌린지는 이미지를 Imagenet 계층 구조의 1000개 리프 노드 카테고리 중 하나로 분류하는 작업을 포함합니다. 훈련에 약 120만 개의 이미지가 사용되며, 검증용으로 5만 개, 테스트용으로 10만 개의 이미지가 제공됩니다. 각 이미지는 하나의 정답 카테고리와 연관되어 있으며, 성능은 가장 높은 점수를 얻은 분류기의 예측에 기반하여 측정됩니다. 일반적으로 두 가지 숫자가 보고됩니다: 첫 번째로 예측된 클래스와 정답을 비교하는 top-1 정확도와, 첫 번째로 예측된 5개 클래스와 정답을 비교하는 top-5 오류율입니다. 이미지가 상위 5개의 예측 중 하나와 일치하면, 그 순위에 상관없이 올바르게 분류된 것으로 간주됩니다. 이 챌린지에서는 순위를 매길 때 top-5 오류율을 사용합니다.

우리는 훈련에 외부 데이터를 사용하지 않고 이 챌린지에 참여했습니다. 이 논문에서 언급된 훈련 기법 외에도, 더 높은 성능을 얻기 위해 테스트 중에 몇 가지 기법을 채택했습니다. 아래에 이를 설명합니다.

1. 동일한 GoogLeNet 모델의 7가지 버전을 독립적으로 훈련시켰으며(더 넓은 버전을 포함), 이를 앙상블 예측에 사용했습니다. 이 모델들은 동일한 초기화(실수로 동일한 초기 가중치를 포함한)와 학습률 정책으로 훈련되었으며, 샘플링 방법론과 입력 이미지를 보는 무작위 순서에서만 차이가 있습니다.
2. 테스트 중에는 Krizhevsky 등 [9]의 접근 방식보다 더 공격적인 크롭 방식을 채택했습니다. 구체적으로, 이미지를 4가지 크기로 조정하고, 짧은 차원(높이 또는 너비)을 각각 256, 288, 320, 352로 맞추고, 이러한 조정된 이미지의 왼쪽, 중앙, 오른쪽 사각형을 취합니다(세로 이미지의 경우 상단, 중앙 및 하단 사각형을 사용). 각 사각형에서 4개의 모서리와 중앙 224×224 크롭 및 224×224로 조정된 사각형을 취하며, 그들의 반전된 버전도 포함됩니다. 이로 인해 이미지당 144개의 크롭(4×3×6×2)이 생성됩니다. 유사한 접근 방식이 Andrew Howard [8]에 의해 전년도 참가작에서 사용되었으며, 우리는 이 방법이 제안된 방식보다 성능이 약간 떨어진다는 것을 경험적으로 확인했습니다. 이렇게 공격적인 크롭이 실제 응용에서는 필요하지 않을 수 있으며, 일정 수 이상의 크롭을 추가하는 이점이 점점 줄어들기 때문입니다(이후에 자세히 설명할 것입니다).
3. 최종 예측은 여러 크롭과 모든 개별 분류기에서의 소프트맥스 확률을 평균내어 구합니다. 우리의 실험에서는 크롭 간의 최대 풀링과 분류기 간의 평균을 포함한 대체 접근 방식을 검토했으나, 단순한 평균 방식이 더 나은 성능을 보였습니다.

이 논문의 나머지 부분에서는 최종 제출의 전체 성능에 기여하는 여러 요소를 분석합니다.

우리가 챌린지에서 최종 제출한 결과는 검증 데이터와 테스트 데이터에서 모두 6.67%의 top-5 오류율을 기록하며, 참가자 중 1위를 차지했습니다. 이는 2012년의 SuperVision 접근 방식에 비해 상대적으로 56.5%의 오류율 감소이며, 전년도 최고의 접근 방식(Clarifai)에 비해 약 40%의 감소를 나타냅니다. 두 접근 방식 모두 분류기 훈련에 외부 데이터를 사용했습니다. 아래 표는 최고 성능을 기록한 접근 방식들의 통계를 보여줍니다.

또한, 다음 표에서 이미지 예측 시 사용된 모델 수와 크롭 수를 다양하게 조절하여 여러 테스트 선택의 성능을 분석하고 보고합니다. 모델 하나를 사용할 때는 검증 데이터에서 가장 낮은 top-1 오류율을 기록한 모델을 선택했습니다. 모든 수치는 테스트 데이터 통계에 과적합되지 않도록 검증 데이터셋에서 보고되었습니다.

![](/assets/images/posts/249/img_6.png)

Table 2: 분류 성능

![](/assets/images/posts/249/img_7.png)

Table 3: GoogLeNet 분류 성능 분석

### 8. ILSVRC 2014 검출 챌린지 설정 및 결과

ILSVRC 검출 작업은 이미지 내의 200개 가능한 클래스 중 객체 주위에 경계 상자를 생성하는 것입니다. 검출된 객체는 해당 클래스가 정답과 일치하고, 경계 상자가 최소 50% 이상 겹치는 경우(자카드 지수 사용) 올바른 것으로 간주됩니다. 과도한 검출은 오탐(true positives)으로 간주되어 패널티를 받습니다. 분류 작업과 달리, 각 이미지에는 여러 개의 객체가 있을 수도 있고 없을 수도 있으며, 이들의 크기는 크기도 다양합니다. 결과는 평균 정밀도(mAP)로 보고됩니다.

GoogLeNet의 검출 접근 방식은 [6]의 R-CNN과 유사하지만, 영역 분류기로 Inception 모델을 추가했습니다. 또한, 영역 제안 단계는 Selective Search [20] 접근 방식을 멀티박스 [5] 예측과 결합하여 객체 경계 상자 회수를 높임으로써 개선되었습니다. 오탐을 줄이기 위해 슈퍼픽셀 크기를 2배로 늘렸습니다. 이로 인해 Selective Search 알고리즘에서 제안된 영역 수가 절반으로 줄어들었습니다. 우리는 멀티박스 [5]에서 제안된 200개의 영역 제안을 다시 추가하여, 총 제안 수를 [6]에서 사용한 것의 약 60%로 줄였지만, 커버리지는 92%에서 93%로 증가했습니다. 커버리지를 높이면서 제안 수를 줄인 전반적인 효과는 단일 모델의 평균 정밀도를 1% 향상시켰습니다. 마지막으로, 각 영역을 분류할 때 6개의 ConvNet 앙상블을 사용하여 정확도를 40%에서 43.9%로 개선했습니다. R-CNN과 달리, 우리는 시간 부족으로 경계 상자 회귀를 사용하지 않았습니다.

우리는 먼저 최고의 검출 결과를 보고하고, 검출 작업의 첫 번째 에디션 이후의 진전을 보여줍니다. 2013년 결과와 비교하여 정확도가 거의 두 배로 향상되었습니다. 상위 성과 팀들은 모두 합성곱 신경망을 사용합니다. 우리는 표 4에서 공식 점수와 각 팀의 공통 전략(외부 데이터 사용, 앙상블 모델 또는 컨텍스트 모델)을 보고합니다. 외부 데이터는 일반적으로 모델을 사전 학습하기 위한 ILSVRC12 분류 데이터로, 이후 검출 데이터로 세부 조정됩니다. 일부 팀은 로컬라이제이션 데이터를 사용했다고 언급하기도 합니다. 로컬라이제이션 작업의 경계 상자 중 상당 부분이 검출 데이터셋에 포함되지 않았기 때문에, 분류가 사전 학습에 사용되는 것과 같은 방식으로 일반적인 경계 상자 회귀기를 이 데이터로 사전 학습할 수 있습니다. GoogLeNet은 사전 학습을 위해 로컬라이제이션 데이터를 사용하지 않았습니다.

표 5에서는 단일 모델만 사용한 결과를 비교합니다. 최고의 성과를 낸 모델은 Deep Insight 팀의 모델로, 놀랍게도 3개의 모델을 앙상블해도 0.3점밖에 향상되지 않았습니다. 반면, GoogLeNet은 앙상블을 사용하여 훨씬 더 강력한 결과를 얻었습니다.

![](/assets/images/posts/249/img_8.png)

Table 4: 검출 성능

![](/assets/images/posts/249/img_9.png)

Table 5: 단일 모델 검출 성능

### 9. 결론

우리의 결과는 예상되는 최적의 희소 구조를 쉽게 이용할 수 있는 밀집된 빌딩 블록으로 근사화하는 것이 컴퓨터 비전을 위한 신경망을 개선하는 데 실효성 있는 방법이라는 강력한 증거를 제시하는 것 같습니다. 이 방법의 주요 장점은 얕고 덜 넓은 네트워크에 비해 계산 요구 사항의 약간의 증가만으로도 품질이 크게 향상된다는 점입니다. 또한, 우리의 검출 작업이 맥락을 활용하거나 경계 상자 회귀를 수행하지 않았음에도 불구하고 경쟁력 있는 성과를 거두었으며, 이는 Inception 아키텍처의 강력함을 더욱 입증하는 증거가 됩니다. 유사한 깊이와 너비의 훨씬 더 비싼 네트워크로도 유사한 품질의 결과를 얻을 수 있을 것으로 예상되지만, 우리의 접근 방식은 희소한 아키텍처로 전환하는 것이 실현 가능하고 유용한 아이디어라는 강력한 증거를 제공합니다. 이는 [2]에 기반하여 자동화된 방식으로 희소하고 더 정제된 구조를 만드는 방향으로 유망한 미래 연구를 시사합니다.

### 10. 감사의 말씀

우리는 [2]에 대해 유익한 논의를 나누어 준 Sanjeev Arora와 Aditya Bhaskara에게 감사의 말씀을 전하고 싶습니다. 또한, DistBelief [4] 팀, 특히 Rajat Monga, Jon Shlens, Alex Krizhevsky, Jeff Dean, Ilya Sutskever, Andrea Frome에게 그들의 지원에 대해 감사드립니다. 또한, Tom Duerig와 Ning Ye에게 광학 왜곡에 대한 도움을 준 것에 대해 감사드립니다. 우리의 연구는 Chuck Rosenberg와 Hartwig Adam의 지원 없이는 가능하지 않았을 것입니다.

[1409.4842v1.pdf

1.16MB](./file/1409.4842v1.pdf)
